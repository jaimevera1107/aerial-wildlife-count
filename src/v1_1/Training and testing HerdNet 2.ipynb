{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849dc23c-aa30-4327-b90a-582e076de5f6",
   "metadata": {},
   "source": [
    "# Step 1 - Training and testing HerdNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a26bc-706b-412e-84d6-ad0106154396",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca17cc3-b202-4718-afcc-ed7c09aaf727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "from IPython.display import clear_output\n",
    "from google.colab import drive\n",
    "\n",
    "class GoogleDriveConnector:\n",
    "    \"\"\"\n",
    "    GoogleDriveConnector\n",
    "    --------------------\n",
    "    Clase para montar Google Drive en un entorno de Google Colab.\n",
    "    \n",
    "    Propósito\n",
    "    ---------\n",
    "    Permite establecer una conexión con Google Drive desde Colab de forma\n",
    "    controlada, con validación de parámetros, registro de eventos (logging)\n",
    "    y limpieza visual del entorno tras la conexión.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    mount_path : str\n",
    "        Ruta local donde se montará Google Drive (por defecto '/content/drive').\n",
    "    verbose : bool, opcional\n",
    "        Si es True, se habilita el registro mediante logging. Si es False,\n",
    "        no se muestra ninguna salida ni registro (por defecto True).\n",
    "    \n",
    "    Métodos\n",
    "    -------\n",
    "    mount_drive():\n",
    "        Monta Google Drive y registra el proceso.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, mount_path: str = \"/content/drive\", verbose: bool = True):\n",
    "        \"\"\"\n",
    "        Inicializa la clase configurando el logger y validando la ruta de montaje.\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        mount_path : str\n",
    "            Ruta donde se montará Google Drive.\n",
    "        verbose : bool\n",
    "            Determina si se habilita el registro de eventos.\n",
    "        \n",
    "        Excepciones\n",
    "        -----------\n",
    "        ValueError:\n",
    "            Si 'mount_path' no es una cadena válida o está vacía.\n",
    "        \"\"\"\n",
    "        # Validar tipo y contenido del parámetro\n",
    "        if not isinstance(mount_path, str) or not mount_path.strip():\n",
    "            raise ValueError(\"El parámetro 'mount_path' debe ser una cadena no vacía.\")\n",
    "        \n",
    "        # Asignar atributos de instancia\n",
    "        self.mount_path = mount_path\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        # Configurar logger si está habilitado\n",
    "        self.logger = logging.getLogger(\"GoogleDriveConnector\")\n",
    "        if self.verbose:\n",
    "            self.logger.setLevel(logging.INFO)\n",
    "            if not self.logger.handlers:\n",
    "                handler = logging.StreamHandler()\n",
    "                formatter = logging.Formatter(\n",
    "                    \"[%(asctime)s] [%(levelname)s] %(message)s\",\n",
    "                    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "                )\n",
    "                handler.setFormatter(formatter)\n",
    "                self.logger.addHandler(handler)\n",
    "            self.logger.propagate = False\n",
    "        else:\n",
    "            self.logger.disabled = True\n",
    "    \n",
    "    def mount_drive(self) -> None:\n",
    "        \"\"\"\n",
    "        Monta Google Drive en el entorno actual de Google Colab.\n",
    "        \n",
    "        Retorno\n",
    "        -------\n",
    "        None\n",
    "        \n",
    "        Excepciones\n",
    "        -----------\n",
    "        RuntimeError:\n",
    "            Si ocurre un error durante el proceso de montaje.\n",
    "        \"\"\"\n",
    "        # Registrar inicio del proceso de conexión\n",
    "        if self.verbose:\n",
    "            self.logger.info(\"Iniciando conexión con Google Drive...\")\n",
    "        \n",
    "        # Nueva verificación: evitar conflicto si la ruta ya tiene archivos\n",
    "        if os.path.exists(self.mount_path) and os.listdir(self.mount_path):\n",
    "            if self.verbose:\n",
    "                self.logger.warning(\n",
    "                    f\"La ruta '{self.mount_path}' ya contiene archivos. \"\n",
    "                    \"Se asume que Google Drive ya está montado.\"\n",
    "                )\n",
    "            return\n",
    "        \n",
    "        try:\n",
    "            # Montar Google Drive\n",
    "            drive.mount(self.mount_path)\n",
    "            \n",
    "            # Limpiar salida visual del entorno\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Confirmar éxito del proceso\n",
    "            if self.verbose:\n",
    "                self.logger.info(\"Google Drive montado correctamente.\")\n",
    "            else:\n",
    "                print(\"Google Drive montado correctamente.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            # Manejar y registrar errores\n",
    "            if self.verbose:\n",
    "                self.logger.error(f\"Error al montar Google Drive: {e}\", exc_info=True)\n",
    "            raise RuntimeError(f\"No se pudo montar Google Drive: {e}\") from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2833dccc-db05-442e-a9a7-2bbc82f10db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectar a Google Drive\n",
    "CONNECTOR = GoogleDriveConnector(\n",
    "    mount_path=\"/content/drive\",\n",
    "    verbose=True,\n",
    ")\n",
    "CONNECTOR.mount_drive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10233929-68dc-4e82-913f-bb11b3522e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class ConfiguradorHerdNet:\n",
    "    \"\"\"\n",
    "    Clase para configurar automáticamente el entorno de HerdNet,\n",
    "    compatible tanto con Google Colab como con entornos locales.\n",
    "    \n",
    "    Propósito\n",
    "    ---------\n",
    "    Reproduce la instalación de HerdNet con detección de entorno,\n",
    "    manejo de errores y registro de eventos mediante logging.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    base_dir : str, opcional\n",
    "        Ruta donde se clonará el repositorio HerdNet.\n",
    "        Por defecto: '/content/HerdNet' si se ejecuta en Colab,\n",
    "        o './HerdNet' si se ejecuta localmente.\n",
    "    verbose : bool, opcional\n",
    "        Si es True, muestra información detallada del proceso.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir: str = None, verbose: bool = True):\n",
    "        \"\"\"Inicializa el configurador y detecta el entorno de ejecución.\"\"\"\n",
    "        \n",
    "        # Detectar si se ejecuta en Colab\n",
    "        self.is_colab = \"google.colab\" in sys.modules\n",
    "        \n",
    "        # Definir ruta base según entorno\n",
    "        self.base_dir = Path(base_dir or (\"/content/HerdNet\" if self.is_colab else \"./HerdNet\"))\n",
    "        \n",
    "        # Configurar logging estándar\n",
    "        logging.basicConfig(\n",
    "            level=logging.INFO,\n",
    "            format=\"[%(asctime)s] [%(levelname)s] %(message)s\",\n",
    "            datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "            force=True\n",
    "        )\n",
    "        self.logger = logging.getLogger(\"ConfiguradorHerdNet\")\n",
    "        \n",
    "        # Control de verbosidad\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    def _run_command(self, command: str):\n",
    "        \"\"\"\n",
    "        Ejecuta un comando del sistema de forma segura.\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        command : str\n",
    "            Comando del sistema a ejecutar.\n",
    "        \n",
    "        Excepciones\n",
    "        -----------\n",
    "        subprocess.CalledProcessError\n",
    "            Si el comando devuelve un error de ejecución.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                command,\n",
    "                shell=True,\n",
    "                check=True,\n",
    "                text=True,\n",
    "                stdout=subprocess.PIPE,\n",
    "                stderr=subprocess.PIPE\n",
    "            )\n",
    "            if self.verbose and result.stdout.strip():\n",
    "                self.logger.info(result.stdout.strip())\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.logger.error(f\"Error ejecutando comando: {command}\")\n",
    "            if e.stderr.strip():\n",
    "                self.logger.error(e.stderr.strip())\n",
    "            raise\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    def verificar_gpu(self):\n",
    "        \"\"\"Verifica la disponibilidad de una GPU mediante nvidia-smi.\"\"\"\n",
    "        self.logger.info(\"Verificando GPU disponible...\")\n",
    "        try:\n",
    "            self._run_command(\"nvidia-smi\")\n",
    "        except Exception:\n",
    "            self.logger.warning(\"No se pudo verificar GPU. Puede que no exista o no esté disponible.\")\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    def instalar_dependencias(self):\n",
    "        \"\"\"\n",
    "        Instala las dependencias necesarias según el entorno detectado.\n",
    "        \n",
    "        En Colab se instalan versiones recientes compatibles.\n",
    "        En local se instalan las versiones exactas del paper HerdNet.\n",
    "        \"\"\"\n",
    "        if self.is_colab:\n",
    "            self.logger.info(\"Entorno detectado: Google Colab\")\n",
    "            self.logger.info(\"Instalando dependencias compatibles con Colab...\")\n",
    "            deps = (\n",
    "                \"albumentations fiftyone hydra-core opencv-python pandas pillow \"\n",
    "                \"scikit-image scikit-learn scipy wandb\"\n",
    "            )\n",
    "        else:\n",
    "            self.logger.info(\"Entorno detectado: Local\")\n",
    "            self.logger.info(\"Instalando dependencias exactas del paper HerdNet...\")\n",
    "            deps = (\n",
    "                \"albumentations==1.0.3 fiftyone==0.14.3 hydra-core==1.1.0 \"\n",
    "                \"opencv-python==4.5.1.48 pandas==1.2.3 pillow==8.2.0 \"\n",
    "                \"scikit-image==0.18.1 scikit-learn==1.0.2 scipy==1.6.2 wandb==0.10.33\"\n",
    "            )\n",
    "        \n",
    "        cmd = f\"{sys.executable} -m pip install {deps} -q\"\n",
    "        try:\n",
    "            self._run_command(cmd)\n",
    "        except Exception as e:\n",
    "            self.logger.warning(f\"Fallo parcial en instalación de dependencias: {e}\")\n",
    "            self.logger.warning(\"Continuando con el proceso...\")\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    def clonar_repo(self):\n",
    "        \"\"\"Clona e instala el repositorio HerdNet desde GitHub.\"\"\"\n",
    "        self.logger.info(\"Clonando repositorio HerdNet original...\")\n",
    "        if self.base_dir.exists():\n",
    "            self.logger.info(\"El repositorio ya existe. Se omite la clonación.\")\n",
    "        else:\n",
    "            self._run_command(f\"git clone https://github.com/Alexandre-Delplanque/HerdNet {self.base_dir}\")\n",
    "        \n",
    "        self._run_command(f\"cd {self.base_dir} && {sys.executable} setup.py install -q\")\n",
    "        sys.path.append(str(self.base_dir))\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    def limpiar_salida(self):\n",
    "        \"\"\"Limpia la salida si se ejecuta en Google Colab.\"\"\"\n",
    "        if self.is_colab:\n",
    "            clear_output(wait=True)\n",
    "    \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    def configurar(self):\n",
    "        \"\"\"\n",
    "        Ejecuta el flujo completo de configuración del entorno HerdNet.\n",
    "        \n",
    "        Incluye:\n",
    "        - Verificación de GPU\n",
    "        - Instalación de dependencias\n",
    "        - Clonación del repositorio\n",
    "        - Instalación local\n",
    "        - Limpieza de salida (solo en Colab)\n",
    "        \"\"\"\n",
    "        self.logger.info(\"Iniciando configuración del entorno HerdNet...\")\n",
    "        try:\n",
    "            self.verificar_gpu()\n",
    "            self.instalar_dependencias()\n",
    "            self.clonar_repo()\n",
    "            self.limpiar_salida()\n",
    "            self.logger.info(\"Instalación completada correctamente y entorno listo.\")\n",
    "            print(\"Instalación completada correctamente y entorno listo.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error durante la configuración: {e}\")\n",
    "            raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952cb3b-f5e0-4c16-8612-e5e57911bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instsalación de librerías y clonación de animaloc\n",
    "configurador = ConfiguradorHerdNet(verbose=True)\n",
    "configurador.configurar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5f7699-d7e6-4768-a922-8b5731d08fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animaloc.utils.seed import set_seed\n",
    "\n",
    "class FijadorSemilla:\n",
    "    \"\"\"\n",
    "    FijadorSemilla\n",
    "    --------------\n",
    "    Establece una semilla aleatoria determinística para los módulos de Python,\n",
    "    NumPy y PyTorch, garantizando la reproducibilidad de los experimentos.\n",
    "    \n",
    "    Propósito\n",
    "    ---------\n",
    "    Proporcionar una interfaz unificada para fijar el valor de la semilla que\n",
    "    utilizan los generadores aleatorios del entorno.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    seed : int\n",
    "        Valor entero que se usará como semilla global.\n",
    "    \n",
    "    Ejemplo\n",
    "    -------\n",
    "    >>> fijador = FijadorSemilla(seed=9292)\n",
    "    >>> fijador.aplicar()\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed: int = 9292):\n",
    "        # Guarda el valor de la semilla\n",
    "        self.seed = seed\n",
    "    \n",
    "    def aplicar(self):\n",
    "        \"\"\"\n",
    "        Aplica la semilla determinística en Python, NumPy y PyTorch.\n",
    "        \n",
    "        Retorno\n",
    "        -------\n",
    "        None\n",
    "            El método no devuelve ningún valor; solo fija la semilla global.\n",
    "        \"\"\"\n",
    "        # Fija la semilla de manera reproducible\n",
    "        set_seed(self.seed)\n",
    "        \n",
    "        # Imprime confirmación\n",
    "        print(f\"Semilla aleatoria fijada en {self.seed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cfd022-bf15-48cd-be93-4eff90c2a362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fijar semilla global\n",
    "fijador = FijadorSemilla(seed=9292)\n",
    "fijador.aplicar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd591026-f003-4880-9e45-f058773c1464",
   "metadata": {},
   "source": [
    "# Create datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104cad9-e813-4ff0-9502-d9a6c8e2e040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data of Delplanque et al. (2021)\n",
    "!gdown 1CcTAZZJdwrBfCPJtVH6VBU3luGKIN9st -O /content/data.zip\n",
    "!unzip -oq /content/data.zip -d /content\n",
    "\n",
    "# URL: https://drive.google.com/uc?id=1CcTAZZJdwrBfCPJtVH6VBU3luGKIN9st\n",
    "\n",
    "# Create validation patches using the patcher tool (for demo)\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "\n",
    "mkdir('/content/data/val_patches')\n",
    "\n",
    "!python /content/HerdNet/tools/patcher.py /content/data/val 512 512 0 /content/data/val_patches -csv /content/data/val.csv -min 0.0 -all False\n",
    "\n",
    "#!cp -r /content/data/val_patches /content/drive/MyDrive/HerdNet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326bf29c-b2ad-42c8-beb5-d2dcae50614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from animaloc.datasets import CSVDataset\n",
    "from animaloc.data.transforms import MultiTransformsWrapper, DownSample, PointsToMask, FIDT\n",
    "\n",
    "class HerdNetDatasetsBuilder:\n",
    "    \"\"\"\n",
    "    Clase para construir los datasets de entrenamiento, validación y prueba\n",
    "    utilizados por el modelo HerdNet.\n",
    "    \n",
    "    Esta clase encapsula la configuración de transformaciones de Albumentations\n",
    "    y las transformaciones finales requeridas por el modelo.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    train_csv : str\n",
    "        Ruta al archivo CSV de entrenamiento.\n",
    "    train_root : str\n",
    "        Carpeta raíz donde se encuentran las imágenes de entrenamiento.\n",
    "    val_csv : str\n",
    "        Ruta al archivo CSV de validación.\n",
    "    val_root : str\n",
    "        Carpeta raíz de las imágenes de validación.\n",
    "    test_csv : str\n",
    "        Ruta al archivo CSV de prueba.\n",
    "    test_root : str\n",
    "        Carpeta raíz de las imágenes de prueba.\n",
    "    patch_size : int, opcional\n",
    "        Tamaño del parche utilizado. Por defecto es 512.\n",
    "    num_classes : int, opcional\n",
    "        Número total de clases (incluye fondo). Por defecto es 7.\n",
    "    down_ratio : int, opcional\n",
    "        Factor de reducción espacial. Por defecto es 2.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    tuple\n",
    "        Una tupla con tres objetos:\n",
    "        (train_dataset, val_dataset, test_dataset)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_csv: str,\n",
    "        train_root: str,\n",
    "        val_csv: str,\n",
    "        val_root: str,\n",
    "        test_csv: str,\n",
    "        test_root: str,\n",
    "        patch_size: int = 512,\n",
    "        num_classes: int = 7,\n",
    "        down_ratio: int = 2,\n",
    "    ):\n",
    "        # Se guardan las rutas y parámetros como atributos\n",
    "        self.train_csv = train_csv\n",
    "        self.train_root = train_root\n",
    "        self.val_csv = val_csv\n",
    "        self.val_root = val_root\n",
    "        self.test_csv = test_csv\n",
    "        self.test_root = test_root\n",
    "        self.patch_size = patch_size\n",
    "        self.num_classes = num_classes\n",
    "        self.down_ratio = down_ratio\n",
    "    \n",
    "    def build(self):\n",
    "        \"\"\"\n",
    "        Construye los datasets de entrenamiento, validación y prueba.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        tuple\n",
    "            (train_dataset, val_dataset, test_dataset)\n",
    "        \"\"\"\n",
    "        # Dataset de entrenamiento con transformaciones de aumento\n",
    "        train_dataset = CSVDataset(\n",
    "            csv_file=self.train_csv,\n",
    "            root_dir=self.train_root,\n",
    "            albu_transforms=[\n",
    "                A.VerticalFlip(p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.RandomRotate90(p=0.5),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.2),\n",
    "                A.Blur(blur_limit=15, p=0.2),\n",
    "                A.Normalize(p=1.0),\n",
    "            ],\n",
    "            end_transforms=[\n",
    "                MultiTransformsWrapper([\n",
    "                    FIDT(num_classes=self.num_classes, down_ratio=self.down_ratio),\n",
    "                    PointsToMask(\n",
    "                        radius=2,\n",
    "                        num_classes=self.num_classes,\n",
    "                        squeeze=True,\n",
    "                        down_ratio=int(self.patch_size // 16),\n",
    "                    ),\n",
    "                ])\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # Dataset de validación\n",
    "        val_dataset = CSVDataset(\n",
    "            csv_file=self.val_csv,\n",
    "            root_dir=self.val_root,\n",
    "            albu_transforms=[A.Normalize(p=1.0)],\n",
    "            end_transforms=[DownSample(down_ratio=self.down_ratio, anno_type=\"point\")],\n",
    "        )\n",
    "        \n",
    "        # Dataset de prueba\n",
    "        test_dataset = CSVDataset(\n",
    "            csv_file=self.test_csv,\n",
    "            root_dir=self.test_root,\n",
    "            albu_transforms=[A.Normalize(p=1.0)],\n",
    "            end_transforms=[DownSample(down_ratio=self.down_ratio, anno_type=\"point\")],\n",
    "        )\n",
    "        \n",
    "        # Retorna los tres datasets sin imprimir nada\n",
    "        return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Crear instancia de la clase\n",
    "builder = HerdNetDatasetsBuilder(\n",
    "    train_csv='/content/data/train_patches.csv',\n",
    "    train_root='/content/data/train_patches',\n",
    "    val_csv='/content/data/val_patches/gt.csv',\n",
    "    val_root='/content/data/val_patches',\n",
    "    test_csv='/content/data/test.csv',\n",
    "    test_root='/content/data/test'\n",
    ")\n",
    "\n",
    "# Construir los datasets\n",
    "train_dataset, val_dataset, test_dataset = builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d50f21-4416-445d-8058-252b1f10bf4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size = 4, shuffle = True)\n",
    "val_dataloader = DataLoader(dataset = val_dataset, batch_size = 1, shuffle = False)\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size = 1, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0516da2f-ae52-4771-ac48-5bc517976cab",
   "metadata": {},
   "source": [
    "# Define HerdNet for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822e2969-2248-425c-85fe-43a9f8cd9f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animaloc.models import HerdNet\n",
    "from torch import Tensor\n",
    "from animaloc.models import LossWrapper\n",
    "from animaloc.train.losses import FocalLoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "herdnet = HerdNet(pretrained=False, num_classes=num_classes, down_ratio=down_ratio).cuda()\n",
    "\n",
    "weight = Tensor([0.1, 1.0, 2.0, 1.0, 6.0, 12.0, 1.0]).cuda()\n",
    "\n",
    "losses = [\n",
    "    {'loss': FocalLoss(reduction='mean'), 'idx': 0, 'idy': 0, 'lambda': 1.0, 'name': 'focal_loss'},\n",
    "    {'loss': CrossEntropyLoss(reduction='mean', weight=weight), 'idx': 1, 'idy': 1, 'lambda': 1.0, 'name': 'ce_loss'}\n",
    "]\n",
    "\n",
    "herdnet = LossWrapper(herdnet, losses=losses)\n",
    "\n",
    "# URL (DLA): http://dl.yf.io/dla/models/imagenet/dla34-ba72cf86.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186d677b-ef43-46fc-897e-df312e8f255f",
   "metadata": {},
   "source": [
    "# Create the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f099794-6de8-49f7-bbb7-25ab2dc3d962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from animaloc.train import Trainer\n",
    "from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "\n",
    "work_dir = '/content/drive/MyDrive/HerdNet/output'\n",
    "mkdir(work_dir)\n",
    "\n",
    "lr = 1e-4 \n",
    "weight_decay = 1e-3\n",
    "epochs = 100\n",
    "\n",
    "optimizer = Adam(params=herdnet.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "metrics = PointsMetrics(radius=20, num_classes=num_classes)\n",
    "\n",
    "stitcher = HerdNetStitcher(\n",
    "    model=herdnet,\n",
    "    size=(patch_size,patch_size),\n",
    "    overlap=160,\n",
    "    down_ratio=down_ratio,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "evaluator = HerdNetEvaluator(\n",
    "    model=herdnet,\n",
    "    dataloader=val_dataloader,\n",
    "    metrics=metrics,\n",
    "    stitcher=stitcher,\n",
    "    work_dir=work_dir,\n",
    "    header='validation'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=herdnet,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=epochs,\n",
    "    evaluator=evaluator,\n",
    "    work_dir=work_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03df08af-54e8-4f86-89c2-aa83365a70f4",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bf6a83-f93b-4a23-852f-e5884a26a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.start(warmup_iters=100, checkpoints='best', select='max', validate_on='f1_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0fafec-4312-47d4-b9e1-02c5f8e659e8",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160055d7-17c2-4cd1-956a-51fe1397b804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5f340-f8cd-4796-aef5-24262b50c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "test_dir = \"/content/drive/MyDrive/HerdNet/test_p1\"\n",
    "mkdir(test_dir)\n",
    "\n",
    "from animaloc.models import HerdNet\n",
    "from torch import Tensor\n",
    "from animaloc.models import LossWrapper\n",
    "from animaloc.train.losses import FocalLoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "num_classes = 7\n",
    "down_ratio = 2\n",
    "\n",
    "herdnet = HerdNet(pretrained=False, num_classes=num_classes, down_ratio=down_ratio).cuda()\n",
    "\n",
    "weight = Tensor([0.1, 1.0, 2.0, 1.0, 6.0, 12.0, 1.0]).cuda()\n",
    "\n",
    "losses = [\n",
    "    {'loss': FocalLoss(reduction='mean'), 'idx': 0, 'idy': 0, 'lambda': 1.0, 'name': 'focal_loss'},\n",
    "    {'loss': CrossEntropyLoss(reduction='mean', weight=weight), 'idx': 1, 'idy': 1, 'lambda': 1.0, 'name': 'ce_loss'}\n",
    "]\n",
    "\n",
    "herdnet = LossWrapper(herdnet, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e2be74-61aa-43f4-b169-83b9a65ab7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained parameters\n",
    "from animaloc.models import load_model\n",
    "\n",
    "herdnet = load_model(herdnet, pth_path=\"/content/drive/MyDrive/HerdNet/fase_1/output/best_model.pth\")\n",
    "\n",
    "from torch.optim import Adam\n",
    "from animaloc.train import Trainer\n",
    "from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-3\n",
    "epochs = 100\n",
    "num_classes = 7\n",
    "patch_size = 512\n",
    "down_ratio = 2\n",
    "\n",
    "optimizer = Adam(params=herdnet.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "metrics = PointsMetrics(radius=20, num_classes=num_classes)\n",
    "\n",
    "stitcher = HerdNetStitcher(\n",
    "    model=herdnet,\n",
    "    size=(patch_size,patch_size),\n",
    "    overlap=160,\n",
    "    down_ratio=down_ratio,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "# Create an Evaluator\n",
    "test_evaluator = HerdNetEvaluator(\n",
    "    model=herdnet,\n",
    "    dataloader=test_dataloader,\n",
    "    metrics=metrics,\n",
    "    stitcher=stitcher,\n",
    "    work_dir=test_dir,\n",
    "    header='test'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=herdnet,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=epochs,\n",
    "    evaluator=test_evaluator,\n",
    "    work_dir=test_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cce033-f8fe-406a-8a80-991545c9d4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Got processor for keypoints, but no transform to process it\")\n",
    "\n",
    "test_f1_score = test_evaluator.evaluate(returns='f1_score')\n",
    "\n",
    "# Print global F1 score (%)\n",
    "print(f\"F1 score = {test_f1_score * 100:0.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a44a7cc-627a-43f7-8c18-875dc5738361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the detections\n",
    "detections = test_evaluator.results\n",
    "detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f222fbf9-8ba4-453e-8e74-3eeaba92142f",
   "metadata": {},
   "source": [
    "# Inferir sobre train (no patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43c068-8746-4dcf-81b1-aac136735443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from animaloc.data.transforms import DownSample\n",
    "from animaloc.models import HerdNet, LossWrapper\n",
    "from animaloc.eval import HerdNetStitcher, HerdNetEvaluator\n",
    "from animaloc.eval.metrics import PointsMetrics\n",
    "from animaloc.datasets import CSVDataset\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "from animaloc.vizual import draw_points, draw_text\n",
    "\n",
    "def infer_herdnet(\n",
    "    model_path,\n",
    "    images_dir,\n",
    "    output_dir,\n",
    "    patch_size=512,\n",
    "    overlap=160,\n",
    "    down_ratio=2,\n",
    "    device=\"cuda\",\n",
    "    up=True,\n",
    "    reduction=\"mean\",\n",
    "    class_map=None,\n",
    "    draw_results=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run inference with HerdNet model and export detections and visualizations.\n",
    "    \n",
    "    Replicates and extends the original infer.py by Alexandre Delplanque.\n",
    "    \"\"\"\n",
    "    mkdir(output_dir)\n",
    "    \n",
    "    print(f\"[INFO] Loading model from: {model_path}\")\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 1. Construcción del modelo\n",
    "    num_classes = 7  # 6 especies + fondo\n",
    "    model = HerdNet(num_classes=num_classes, down_ratio=down_ratio, pretrained=False)\n",
    "    model = LossWrapper(model, [])\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    if \"model_state_dict\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"[INFO] Model loaded successfully.\")\n",
    "    \n",
    "    # 2. Crear DataLoader con imágenes completas\n",
    "    img_names = [i for i in os.listdir(images_dir) if i.lower().endswith(('.jpg', '.jpeg'))]\n",
    "    df = pd.DataFrame({'images': img_names, 'x': [0]*len(img_names), 'y': [0]*len(img_names), 'labels': [1]*len(img_names)})\n",
    "    \n",
    "    albu_transforms = [A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]\n",
    "    end_transforms = [DownSample(down_ratio=down_ratio, anno_type='point')]\n",
    "    \n",
    "    dataset = CSVDataset(\n",
    "        csv_file=df,\n",
    "        root_dir=images_dir,\n",
    "        albu_transforms=albu_transforms,\n",
    "        end_transforms=end_transforms\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    \n",
    "    # 3. Configurar stitcher y evaluator\n",
    "    stitcher = HerdNetStitcher(\n",
    "        model=model,\n",
    "        size=(patch_size, patch_size),\n",
    "        overlap=overlap,\n",
    "        down_ratio=down_ratio,\n",
    "        up=up,\n",
    "        reduction=reduction,\n",
    "        device_name=device,\n",
    "    )\n",
    "    \n",
    "    metrics = PointsMetrics(5, num_classes=num_classes)\n",
    "    \n",
    "    evaluator = HerdNetEvaluator(\n",
    "        model=model,\n",
    "        dataloader=dataloader,\n",
    "        metrics=metrics,\n",
    "        lmds_kwargs=dict(kernel_size=(3,3), adapt_ts=0.2, neg_ts=0.1),\n",
    "        device_name=device,\n",
    "        print_freq=10,\n",
    "        stitcher=stitcher,\n",
    "        work_dir=output_dir,\n",
    "        header='[INFERENCE]'\n",
    "    )\n",
    "    \n",
    "    # 4. Ejecutar inferencia\n",
    "    print(\"[INFO] Starting inference ...\")\n",
    "    evaluator.evaluate(wandb_flag=False, viz=False, log_meters=False)\n",
    "    \n",
    "    detections = evaluator.detections\n",
    "    detections.dropna(inplace=True)\n",
    "    \n",
    "    # 5. Asignar nombres de especies\n",
    "    if class_map is None:\n",
    "        class_map = {\n",
    "            1: 'buffalo', 2: 'elephant', 3: 'kob',\n",
    "            4: 'topi', 5: 'warthog', 6: 'waterbuck'\n",
    "        }\n",
    "    \n",
    "    detections['species'] = detections['labels'].map(class_map)\n",
    "    \n",
    "    # 6. Guardar CSV\n",
    "    csv_path = Path(output_dir) / \"detections.csv\"\n",
    "    detections.to_csv(csv_path, index=False)\n",
    "    print(f\"[INFO] Saved detections to: {csv_path}\")\n",
    "    \n",
    "    # 7. Exportar visualizaciones (opcional)\n",
    "    if draw_results and not detections.empty:\n",
    "        print(\"[INFO] Exporting plots and thumbnails ...\")\n",
    "        dest_plots = Path(output_dir) / \"plots\"\n",
    "        dest_thumbs = Path(output_dir) / \"thumbnails\"\n",
    "        mkdir(dest_plots)\n",
    "        mkdir(dest_thumbs)\n",
    "        \n",
    "        for img_name in tqdm(detections['images'].unique(), desc=\"Drawing\"):\n",
    "            img_path = os.path.join(images_dir, img_name)\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_cpy = img.copy()\n",
    "            \n",
    "            pts = list(detections[detections['images'] == img_name][['y', 'x']].to_records(index=False))\n",
    "            pts = [(y, x) for y, x in pts]\n",
    "            \n",
    "            output = draw_points(img, pts, color='red', size=10)\n",
    "            output.save(dest_plots / img_name, quality=95)\n",
    "            \n",
    "            sp_score = list(detections[detections['images'] == img_name][['species','scores']].to_records(index=False))\n",
    "            \n",
    "            for i, ((y, x), (sp, score)) in enumerate(zip(pts, sp_score)):\n",
    "                off = 128\n",
    "                coords = (x - off, y - off, x + off, y + off)\n",
    "                thumbnail = img_cpy.crop(coords)\n",
    "                score = round(score * 100, 0)\n",
    "                thumbnail = draw_text(thumbnail, f\"{sp} | {score}%\", position=(10,5), font_size=20)\n",
    "                thumbnail.save(dest_thumbs / f\"{img_name[:-4]}_{i}.JPG\")\n",
    "    \n",
    "    # 8. Resumen final\n",
    "    print(\"\\n[INFO] Detection summary per species:\")\n",
    "    if not detections.empty:\n",
    "        for sp, count in detections['species'].value_counts().items():\n",
    "            print(f\"  - {sp}: {count}\")\n",
    "        print(f\"  Total detections: {len(detections)}\")\n",
    "    else:\n",
    "        print(\"  No detections found.\")\n",
    "    \n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03422ef-5565-4b48-982c-f149852fde76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"/content/drive/MyDrive/HerdNet/fase_1/best_model.pth\"\n",
    "IMAGES_DIR = \"/content/data/train\"\n",
    "OUTPUT_DIR = f\"/content/drive/MyDrive/HerdNet/fase_1/infer_train_{datetime.now().strftime('%Y%m%d')}\"\n",
    "\n",
    "detecciones = infer_herdnet(\n",
    "    model_path=MODEL_PATH,\n",
    "    images_dir=IMAGES_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    patch_size=512,\n",
    "    overlap=160,\n",
    "    down_ratio=2,\n",
    "    device=\"cuda\",\n",
    "    draw_results=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a7f8a9-4e9a-4cb0-ad56-e2d865e4d3ef",
   "metadata": {},
   "source": [
    "# Generar HNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55972f03-619a-4757-98cb-5aae2627bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "class HardNegativePatchMiner:\n",
    "    \"\"\"\n",
    "    Clase para realizar minería de Hard Negative Patches (HNP) a partir de las detecciones\n",
    "    y el conjunto de ground truth.\n",
    "    \n",
    "    Identifica falsos positivos comparando las predicciones del modelo con los puntos reales\n",
    "    de cada imagen, considerando un radio de tolerancia. Las detecciones que no coinciden\n",
    "    con ningún punto real dentro de dicho radio se consideran candidatos HNP.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    detections_path : str\n",
    "        Ruta al archivo CSV con las detecciones del modelo.\n",
    "    groundtruth_path : str\n",
    "        Ruta al archivo CSV con las anotaciones reales (ground truth).\n",
    "    output_path : str\n",
    "        Ruta donde se guardará el archivo CSV con los candidatos HNP.\n",
    "    radius : int, opcional\n",
    "        Radio máximo de tolerancia para considerar una detección como válida. Por defecto es 20.\n",
    "    score_threshold : float, opcional\n",
    "        Umbral mínimo de confianza para conservar detecciones. Por defecto es 0.95.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con los registros de Hard Negative Patches (HNP).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        detections_path: str,\n",
    "        groundtruth_path: str,\n",
    "        output_path: str,\n",
    "        radius: int = 20,\n",
    "        score_threshold: float = 0.95,\n",
    "    ):\n",
    "        # Se guardan los parámetros de entrada\n",
    "        self.detections_path = detections_path\n",
    "        self.groundtruth_path = groundtruth_path\n",
    "        self.output_path = output_path\n",
    "        self.radius = radius\n",
    "        self.score_threshold = score_threshold\n",
    "    \n",
    "    def mine(self):\n",
    "        \"\"\"\n",
    "        Ejecuta el proceso de minería de Hard Negative Patches (HNP).\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame con los registros de HNP encontrados.\n",
    "        \"\"\"\n",
    "        # Cargar detecciones y ground truth\n",
    "        det = pd.read_csv(self.detections_path)\n",
    "        gt = pd.read_csv(self.groundtruth_path)\n",
    "        \n",
    "        # Asegurar consistencia en los nombres de las imágenes\n",
    "        det[\"images\"] = det[\"images\"].astype(str)\n",
    "        gt[\"images\"] = gt[\"images\"].astype(str)\n",
    "        \n",
    "        # Filtrar detecciones por umbral de confianza\n",
    "        det = det[det[\"scores\"] >= self.score_threshold].reset_index(drop=True)\n",
    "        \n",
    "        # Lista donde se acumulan los registros de falsos positivos\n",
    "        hnp_records = []\n",
    "        \n",
    "        # Evaluar imagen por imagen\n",
    "        for img_name in tqdm(det[\"images\"].unique(), desc=\"Mining HNPs\"):\n",
    "            preds = det[det[\"images\"] == img_name]\n",
    "            gts = gt[gt[\"images\"] == img_name]\n",
    "            \n",
    "            # Si no existe ground truth, todas las predicciones son falsos positivos\n",
    "            if gts.empty:\n",
    "                for _, row in preds.iterrows():\n",
    "                    hnp_records.append(row)\n",
    "                continue\n",
    "            \n",
    "            # Coordenadas reales\n",
    "            gt_points = gts[[\"x\", \"y\"]].to_numpy()\n",
    "            \n",
    "            # Comparar cada predicción\n",
    "            for _, row in preds.iterrows():\n",
    "                px, py = row[\"x\"], row[\"y\"]\n",
    "                distances = np.sqrt(((gt_points[:, 0] - px) ** 2) + ((gt_points[:, 1] - py) ** 2))\n",
    "                \n",
    "                # Si todas las distancias son mayores al radio, es falso positivo\n",
    "                if np.all(distances > self.radius):\n",
    "                    hnp_records.append(row)\n",
    "        \n",
    "        # Crear DataFrame de resultados\n",
    "        hnp_df = pd.DataFrame(hnp_records)\n",
    "        \n",
    "        # Crear carpeta destino\n",
    "        Path(self.output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Guardar resultados\n",
    "        hnp_df.to_csv(self.output_path, index=False)\n",
    "        \n",
    "        # Retornar el DataFrame\n",
    "        return hnp_df\n",
    "\n",
    "class HardNegativePatchMinerV2:\n",
    "    \"\"\"\n",
    "    Versión mejorada del minero de Hard Negative Patches.\n",
    "    \n",
    "    Mejoras:\n",
    "    - Filtrado por percentiles de confianza en lugar de umbral fijo\n",
    "    - Balanceo por clase para evitar sesgos\n",
    "    - Filtrado de duplicados cercanos\n",
    "    - Análisis de distribución espacial\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    detections_path : str\n",
    "        Ruta al archivo CSV con las detecciones del modelo.\n",
    "    groundtruth_path : str\n",
    "        Ruta al archivo CSV con las anotaciones reales (ground truth).\n",
    "    output_path : str\n",
    "        Ruta donde se guardará el archivo CSV con los candidatos HNP.\n",
    "    radius : int, opcional\n",
    "        Radio máximo de tolerancia para considerar una detección como válida. Por defecto es 20.\n",
    "    score_percentile : float, opcional\n",
    "        Percentil de confianza para filtrar detecciones. Por defecto es 0.7 (top 30%).\n",
    "    max_samples_per_image : int, opcional\n",
    "        Máximo número de HNPs por imagen. Por defecto es 10.\n",
    "    min_distance_between_hnp : int, opcional\n",
    "        Distancia mínima entre HNPs para evitar redundancia. Por defecto es 100.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con los registros de Hard Negative Patches (HNP).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        detections_path: str,\n",
    "        groundtruth_path: str,\n",
    "        output_path: str,\n",
    "        radius: int = 20,\n",
    "        score_percentile: float = 0.7,\n",
    "        max_samples_per_image: int = 10,\n",
    "        min_distance_between_hnp: int = 100,\n",
    "    ):\n",
    "        self.detections_path = detections_path\n",
    "        self.groundtruth_path = groundtruth_path\n",
    "        self.output_path = output_path\n",
    "        self.radius = radius\n",
    "        self.score_percentile = score_percentile\n",
    "        self.max_samples_per_image = max_samples_per_image\n",
    "        self.min_distance_between_hnp = min_distance_between_hnp\n",
    "    \n",
    "    def _is_far_from_existing(self, x, y, existing_points, min_dist):\n",
    "        \"\"\"Verifica si un punto está suficientemente lejos de los existentes.\"\"\"\n",
    "        if not existing_points:\n",
    "            return True\n",
    "        existing_array = np.array(existing_points)\n",
    "        distances = np.sqrt((existing_array[:, 0] - x)**2 + (existing_array[:, 1] - y)**2)\n",
    "        return np.all(distances > min_dist)\n",
    "    \n",
    "    def mine(self):\n",
    "        \"\"\"\n",
    "        Ejecuta el minado mejorado de HNPs.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame con los registros de HNP encontrados.\n",
    "        \"\"\"\n",
    "        # Cargar datos\n",
    "        det = pd.read_csv(self.detections_path)\n",
    "        gt = pd.read_csv(self.groundtruth_path)\n",
    "        \n",
    "        det[\"images\"] = det[\"images\"].astype(str)\n",
    "        gt[\"images\"] = gt[\"images\"].astype(str)\n",
    "        \n",
    "        # Calcular umbral dinámico basado en percentiles\n",
    "        score_threshold = det[\"scores\"].quantile(self.score_percentile)\n",
    "        print(f\"[INFO] Umbral de confianza calculado (percentil {self.score_percentile*100}%): {score_threshold:.3f}\")\n",
    "        \n",
    "        # Filtrar por umbral\n",
    "        det = det[det[\"scores\"] >= score_threshold].reset_index(drop=True)\n",
    "        \n",
    "        hnp_records = []\n",
    "        stats = {\"total_candidates\": 0, \"filtered_by_distance\": 0, \"filtered_by_max_samples\": 0}\n",
    "        \n",
    "        for img_name in tqdm(det[\"images\"].unique(), desc=\"Mining HNPs v2\"):\n",
    "            preds = det[det[\"images\"] == img_name]\n",
    "            gts = gt[gt[\"images\"] == img_name]\n",
    "            \n",
    "            image_hnps = []\n",
    "            existing_hnp_coords = []\n",
    "            \n",
    "            # Si no hay GT, todas son FP\n",
    "            if gts.empty:\n",
    "                for _, row in preds.iterrows():\n",
    "                    if len(image_hnps) >= self.max_samples_per_image:\n",
    "                        stats[\"filtered_by_max_samples\"] += 1\n",
    "                        continue\n",
    "                    \n",
    "                    x, y = row[\"x\"], row[\"y\"]\n",
    "                    if self._is_far_from_existing(x, y, existing_hnp_coords, self.min_distance_between_hnp):\n",
    "                        image_hnps.append(row)\n",
    "                        existing_hnp_coords.append((x, y))\n",
    "                        stats[\"total_candidates\"] += 1\n",
    "                    else:\n",
    "                        stats[\"filtered_by_distance\"] += 1\n",
    "                continue\n",
    "            \n",
    "            gt_points = gts[[\"x\", \"y\"]].to_numpy()\n",
    "            \n",
    "            # Ordenar predicciones por confianza (descendente)\n",
    "            preds_sorted = preds.sort_values(\"scores\", ascending=False)\n",
    "            \n",
    "            for _, row in preds_sorted.iterrows():\n",
    "                if len(image_hnps) >= self.max_samples_per_image:\n",
    "                    stats[\"filtered_by_max_samples\"] += 1\n",
    "                    continue\n",
    "                \n",
    "                px, py = row[\"x\"], row[\"y\"]\n",
    "                distances = np.sqrt((gt_points[:, 0] - px)**2 + (gt_points[:, 1] - py)**2)\n",
    "                \n",
    "                # Si es falso positivo\n",
    "                if np.all(distances > self.radius):\n",
    "                    # Verificar distancia con otros HNPs\n",
    "                    if self._is_far_from_existing(px, py, existing_hnp_coords, self.min_distance_between_hnp):\n",
    "                        image_hnps.append(row)\n",
    "                        existing_hnp_coords.append((px, py))\n",
    "                        stats[\"total_candidates\"] += 1\n",
    "                    else:\n",
    "                        stats[\"filtered_by_distance\"] += 1\n",
    "            \n",
    "            hnp_records.extend(image_hnps)\n",
    "        \n",
    "        hnp_df = pd.DataFrame(hnp_records)\n",
    "        \n",
    "        # Estadísticas\n",
    "        print(f\"\\n[INFO] Estadísticas de minado:\")\n",
    "        print(f\"  - Candidatos totales: {stats['total_candidates']}\")\n",
    "        print(f\"  - Filtrados por distancia: {stats['filtered_by_distance']}\")\n",
    "        print(f\"  - Filtrados por máximo/imagen: {stats['filtered_by_max_samples']}\")\n",
    "        print(f\"  - HNPs finales: {len(hnp_df)}\")\n",
    "        \n",
    "        # Guardar\n",
    "        Path(self.output_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        hnp_df.to_csv(self.output_path, index=False)\n",
    "        \n",
    "        return hnp_df\n",
    "\n",
    "# Usar la versión mejorada\n",
    "miner = HardNegativePatchMinerV2(\n",
    "    detections_path=\"/content/drive/MyDrive/HerdNet/fase_1/infer_train_20251101/detections.csv\",\n",
    "    groundtruth_path=\"/content/data/train.csv\",\n",
    "    output_path=\"/content/data/hnp_candidates.csv\",\n",
    "    radius=20,\n",
    "    score_percentile=0.6,\n",
    "    max_samples_per_image=15,\n",
    "    min_distance_between_hnp=80\n",
    ")\n",
    "\n",
    "hnp_df = miner.mine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2c420-4c17-4f3b-bf35-4011f994dac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "class HNPPatchesExtractor:\n",
    "    \"\"\"\n",
    "    Clase para extraer parches de Hard Negative Patches (HNP) a partir de un\n",
    "    archivo CSV con coordenadas de detecciones falsas positivas.\n",
    "    \n",
    "    Crea imágenes recortadas centradas en las coordenadas de cada detección,\n",
    "    guardándolas en una carpeta destino junto con un archivo CSV que registra\n",
    "    los metadatos de cada parche generado.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    hnp_csv : str\n",
    "        Ruta al archivo CSV con las detecciones HNP.\n",
    "    images_root : str\n",
    "        Carpeta raíz donde se encuentran las imágenes originales.\n",
    "    output_dir : str\n",
    "        Carpeta destino donde se guardarán los parches generados.\n",
    "    patch_size : int, opcional\n",
    "        Tamaño del parche cuadrado a recortar. Por defecto es 512 píxeles.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con los registros de los parches generados, incluyendo\n",
    "        nombre del archivo, coordenadas (x, y) y etiqueta (labels = 0).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        hnp_csv: str,\n",
    "        images_root: str,\n",
    "        output_dir: str,\n",
    "        patch_size: int = 512,\n",
    "    ):\n",
    "        # Se guardan los parámetros como atributos\n",
    "        self.hnp_csv = hnp_csv\n",
    "        self.images_root = images_root\n",
    "        self.output_dir = output_dir\n",
    "        self.patch_size = patch_size\n",
    "    \n",
    "    def extract(self):\n",
    "        \"\"\"\n",
    "        Ejecuta la extracción de parches HNP y genera el archivo CSV de salida.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame con los metadatos de los parches generados.\n",
    "        \"\"\"\n",
    "        # Crear carpeta de salida si no existe\n",
    "        Path(self.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Cargar el archivo CSV con las detecciones negativas\n",
    "        hnp_df = pd.read_csv(self.hnp_csv)\n",
    "        \n",
    "        # Lista para almacenar los registros de salida\n",
    "        records = []\n",
    "        \n",
    "        half = self.patch_size // 2\n",
    "        \n",
    "        # Iterar sobre cada detección y extraer parches\n",
    "        for idx, row in tqdm(hnp_df.iterrows(), total=len(hnp_df), desc=\"Extracting patches\"):\n",
    "            img_name = row[\"images\"]\n",
    "            img_path = os.path.join(self.images_root, img_name)\n",
    "            \n",
    "            # Omitir si la imagen no existe\n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Abrir imagen y obtener dimensiones\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                w, h = img.size\n",
    "                \n",
    "                # Coordenadas del centro de la detección\n",
    "                x, y = int(row[\"x\"]), int(row[\"y\"])\n",
    "                \n",
    "                # Calcular límites del parche (centrado)\n",
    "                left = max(0, x - half)\n",
    "                upper = max(0, y - half)\n",
    "                right = min(w, x + half)\n",
    "                lower = min(h, y + half)\n",
    "                \n",
    "                # Extraer y guardar el parche\n",
    "                patch = img.crop((left, upper, right, lower))\n",
    "                patch_name = f\"{Path(img_name).stem}_hnp_{idx:05d}.JPG\"\n",
    "                patch.save(os.path.join(self.output_dir, patch_name), quality=95)\n",
    "                \n",
    "                # Registrar metadatos\n",
    "                records.append({\"images\": patch_name, \"x\": x, \"y\": y, \"labels\": 0})\n",
    "            \n",
    "            except Exception:\n",
    "                # Se ignoran errores de lectura o recorte\n",
    "                continue\n",
    "        \n",
    "        # Guardar CSV final con los registros\n",
    "        hnp_patches_csv = os.path.join(self.output_dir, \"hnp_patches.csv\")\n",
    "        pd.DataFrame(records).to_csv(hnp_patches_csv, index=False)\n",
    "        \n",
    "        # Retornar los registros\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "extractor = HNPPatchesExtractor(\n",
    "    hnp_csv=\"/content/data/hnp_candidates.csv\",\n",
    "    images_root=\"/content/data/train\",\n",
    "    output_dir=\"/content/data/hnp_patches\",\n",
    "    patch_size=512\n",
    ")\n",
    "\n",
    "hnp_patches_df = extractor.extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098133d4-d01c-4730-9f20-a5ca5d14cd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "class TrainPatchesMerger:\n",
    "    \"\"\"\n",
    "    Clase para combinar los parches originales de entrenamiento con los parches\n",
    "    negativos (Hard Negative Patches, HNP) en una única carpeta consolidada.\n",
    "    \n",
    "    Copia todos los archivos .JPG desde las carpetas de entrenamiento y HNP hacia\n",
    "    una carpeta final de parches fusionados.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    train_patches_dir : str o Path\n",
    "        Carpeta que contiene los parches de entrenamiento originales.\n",
    "    hnp_patches_dir : str o Path\n",
    "        Carpeta que contiene los parches negativos (HNP).\n",
    "    merged_dir : str o Path\n",
    "        Carpeta donde se guardarán los parches fusionados.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    tuple\n",
    "        Una tupla con:\n",
    "        - total_patches (int): número total de parches copiados.\n",
    "        - merged_dir (Path): ruta de la carpeta consolidada.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, train_patches_dir, hnp_patches_dir, merged_dir):\n",
    "        # Se convierten las rutas a objetos Path para operaciones consistentes\n",
    "        self.train_patches_dir = Path(train_patches_dir)\n",
    "        self.hnp_patches_dir = Path(hnp_patches_dir)\n",
    "        self.merged_dir = Path(merged_dir)\n",
    "    \n",
    "    def merge(self):\n",
    "        \"\"\"\n",
    "        Ejecuta la fusión de parches de entrenamiento y negativos.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        tuple\n",
    "            (total_patches, merged_dir)\n",
    "        \"\"\"\n",
    "        # Crear la carpeta de salida si no existe\n",
    "        self.merged_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Copiar los parches de entrenamiento originales\n",
    "        for img in self.train_patches_dir.glob(\"*.JPG\"):\n",
    "            shutil.copy(img, self.merged_dir / img.name)\n",
    "        \n",
    "        # Copiar los parches negativos\n",
    "        for img in self.hnp_patches_dir.glob(\"*.JPG\"):\n",
    "            shutil.copy(img, self.merged_dir / img.name)\n",
    "        \n",
    "        # Contar el total de archivos copiados\n",
    "        total_patches = len(list(self.merged_dir.glob(\"*.JPG\")))\n",
    "        \n",
    "        # Retornar resultados\n",
    "        return total_patches, self.merged_dir\n",
    "\n",
    "merger = TrainPatchesMerger(\n",
    "    train_patches_dir=\"/content/data/train_patches\",\n",
    "    hnp_patches_dir=\"/content/data/hnp_patches\",\n",
    "    merged_dir=\"/content/data/merged_train_patches\"\n",
    ")\n",
    "\n",
    "total_patches, merged_path = merger.merge()\n",
    "\n",
    "class BalancedPatchSampler:\n",
    "    \"\"\"\n",
    "    Balancea el dataset considerando clases positivas y negativas.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    csv_path : str\n",
    "        Ruta al archivo CSV con todos los parches.\n",
    "    target_ratio : float, opcional\n",
    "        Proporción deseada de HNPs respecto al total. Por defecto es 0.3.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame balanceado con parches positivos y negativos.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, csv_path, target_ratio=0.3):\n",
    "        self.csv_path = csv_path\n",
    "        self.target_ratio = target_ratio\n",
    "    \n",
    "    def balance(self, output_path):\n",
    "        \"\"\"\n",
    "        Crea un CSV balanceado.\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        output_path : str\n",
    "            Ruta donde se guardará el CSV balanceado.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        pd.DataFrame\n",
    "            DataFrame balanceado.\n",
    "        \"\"\"\n",
    "        df = pd.read_csv(self.csv_path)\n",
    "        \n",
    "        # Separar positivos y negativos\n",
    "        positives = df[df['labels'] != 0]\n",
    "        negatives = df[df['labels'] == 0]\n",
    "        \n",
    "        print(f\"[INFO] Parches originales:\")\n",
    "        print(f\"  - Positivos: {len(positives)}\")\n",
    "        print(f\"  - Negativos (HNP): {len(negatives)}\")\n",
    "        \n",
    "        # Calcular cantidad objetivo de negativos\n",
    "        n_positives = len(positives)\n",
    "        n_negatives_target = int(n_positives * self.target_ratio / (1 - self.target_ratio))\n",
    "        \n",
    "        # Subsamplear negativos si hay demasiados\n",
    "        if len(negatives) > n_negatives_target:\n",
    "            negatives = negatives.sample(n=n_negatives_target, random_state=9292)\n",
    "            print(f\"[INFO] Negativos reducidos a: {len(negatives)}\")\n",
    "        \n",
    "        # Combinar\n",
    "        balanced_df = pd.concat([positives, negatives], ignore_index=True)\n",
    "        balanced_df = balanced_df.sample(frac=1, random_state=9292).reset_index(drop=True)\n",
    "        \n",
    "        print(f\"[INFO] Dataset balanceado final: {len(balanced_df)} parches\")\n",
    "        print(f\"  - Proporción HNP: {len(negatives)/len(balanced_df)*100:.1f}%\")\n",
    "        \n",
    "        balanced_df.to_csv(output_path, index=False)\n",
    "        return balanced_df\n",
    "\n",
    "# Aplicar balanceo ANTES de crear el dataset de Fase 2\n",
    "balancer = BalancedPatchSampler(\n",
    "    csv_path=\"/content/data/train_patches.csv\",\n",
    "    target_ratio=0.25\n",
    ")\n",
    "\n",
    "balanced_csv = balancer.balance(\"/content/data/train_patches_balanced.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07d2c20-0c5c-4dc6-bcd8-6faf29cb28f3",
   "metadata": {},
   "source": [
    "# Segunda fase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89673da1-5306-4cb8-b95a-aaf74016cfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONFIGURACIÓN GENERAL - FASE 2 (HARD NEGATIVE PATCHES)\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from animaloc.models import HerdNet\n",
    "from torch import Tensor\n",
    "from animaloc.models import LossWrapper\n",
    "from animaloc.train.losses import FocalLoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from animaloc.datasets import FolderDataset, CSVDataset\n",
    "from animaloc.data.transforms import MultiTransformsWrapper, FIDT, PointsToMask, DownSample\n",
    "from animaloc.train import Trainer\n",
    "from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "\n",
    "# PARÁMETROS\n",
    "PATCH_SIZE = 512\n",
    "DOWN_RATIO = 2\n",
    "NUM_CLASSES = 7\n",
    "WORK_DIR = \"/content/drive/MyDrive/HerdNet/fase_2\"\n",
    "mkdir(WORK_DIR)\n",
    "\n",
    "# DATASETS\n",
    "from albumentations import PadIfNeeded\n",
    "\n",
    "train_dataset = FolderDataset(\n",
    "    csv_file=\"/content/data/train_patches_balanced.csv\",\n",
    "    root_dir=\"/content/data/merged_train_patches\",\n",
    "    albu_transforms=[\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, border_mode=0, p=1.0),\n",
    "        \n",
    "        # Transformaciones geométricas (mantener altas)\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.3),\n",
    "        \n",
    "        # Transformaciones de color (moderadas)\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),\n",
    "        A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.2),\n",
    "        \n",
    "        # Ruido y blur (moderados)\n",
    "        A.OneOf([\n",
    "            A.Blur(blur_limit=7, p=1.0),\n",
    "            A.GaussNoise(var_limit=(10.0, 30.0), p=1.0),\n",
    "            A.MedianBlur(blur_limit=5, p=1.0),\n",
    "        ], p=0.2),\n",
    "        \n",
    "        # Normalización (siempre)\n",
    "        A.Normalize(p=1.0)\n",
    "    ],\n",
    "    end_transforms=[MultiTransformsWrapper([\n",
    "        FIDT(num_classes=NUM_CLASSES, down_ratio=DOWN_RATIO),\n",
    "        PointsToMask(radius=2, num_classes=NUM_CLASSES, squeeze=True, down_ratio=int(PATCH_SIZE // 16))\n",
    "    ])]\n",
    ")\n",
    "\n",
    "print(f\"[INFO] Dataset de entrenamiento cargado: {len(train_dataset)} parches (positivos + HNPs)\")\n",
    "\n",
    "# Validación y test (idénticos a Fase 1)\n",
    "val_dataset = CSVDataset(\n",
    "    csv_file=\"/content/data/val_patches/gt.csv\",\n",
    "    root_dir=\"/content/data/val_patches\",\n",
    "    albu_transforms=[A.Normalize(p=1.0)],\n",
    "    end_transforms=[DownSample(down_ratio=DOWN_RATIO, anno_type=\"point\")]\n",
    ")\n",
    "\n",
    "test_dataset = CSVDataset(\n",
    "    csv_file=\"/content/data/test.csv\",\n",
    "    root_dir=\"/content/data/test\",\n",
    "    albu_transforms=[A.Normalize(p=1.0)],\n",
    "    end_transforms=[DownSample(down_ratio=DOWN_RATIO, anno_type=\"point\")]\n",
    ")\n",
    "\n",
    "\n",
    "# DATALOADERS\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b80beb-16f9-427f-bfde-5f45e3a00e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animaloc.models import HerdNet\n",
    "from torch import Tensor\n",
    "from animaloc.models import LossWrapper\n",
    "from animaloc.train.losses import FocalLoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "herdnet = HerdNet(pretrained=False, num_classes=NUM_CLASSES, down_ratio=DOWN_RATIO).cuda()\n",
    "\n",
    "weight = Tensor([0.1, 1.0, 2.0, 1.0, 6.0, 12.0, 1.0]).cuda()\n",
    "\n",
    "losses = [\n",
    "    {'loss': FocalLoss(reduction='mean'), 'idx': 0, 'idy': 0, 'lambda': 1.0, 'name': 'focal_loss'},\n",
    "    {'loss': CrossEntropyLoss(reduction='mean', weight=weight), 'idx': 1, 'idy': 1, 'lambda': 1.0, 'name': 'ce_loss'}\n",
    "]\n",
    "\n",
    "herdnet = LossWrapper(herdnet, losses=losses)\n",
    "\n",
    "# Load trained parameters\n",
    "from animaloc.models import load_model\n",
    "\n",
    "# Se interrumpió al 32 epoch. Se reanuda\n",
    "herdnet = load_model(herdnet, pth_path=\"/content/drive/MyDrive/HerdNet/fase_2/other/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d61a92a-afcb-415c-969c-126217268b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from animaloc.train import Trainer\n",
    "from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "\n",
    "work_dir = '/content/drive/MyDrive/HerdNet/fase_2/output'\n",
    "mkdir(work_dir)\n",
    "\n",
    "class EarlyStoppingCallback:\n",
    "    \"\"\"\n",
    "    Implementa early stopping basado en una métrica de validación.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    patience : int, opcional\n",
    "        Número de épocas sin mejora antes de detener. Por defecto es 10.\n",
    "    min_delta : float, opcional\n",
    "        Mejora mínima requerida para considerar progreso. Por defecto es 0.001.\n",
    "    mode : str, opcional\n",
    "        'max' para maximizar la métrica, 'min' para minimizar. Por defecto es 'max'.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, patience=10, min_delta=0.001, mode='max'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.mode = mode\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "    \n",
    "    def __call__(self, current_score):\n",
    "        \"\"\"\n",
    "        Evalúa si se debe detener el entrenamiento.\n",
    "        \n",
    "        Parámetros\n",
    "        ----------\n",
    "        current_score : float\n",
    "            Valor actual de la métrica de validación.\n",
    "        \n",
    "        Retorna\n",
    "        -------\n",
    "        bool\n",
    "            True si se debe detener el entrenamiento, False en caso contrario.\n",
    "        \"\"\"\n",
    "        if self.best_score is None:\n",
    "            self.best_score = current_score\n",
    "            return False\n",
    "        \n",
    "        if self.mode == 'max':\n",
    "            score_improved = current_score > (self.best_score + self.min_delta)\n",
    "        else:\n",
    "            score_improved = current_score < (self.best_score - self.min_delta)\n",
    "        \n",
    "        if score_improved:\n",
    "            self.best_score = current_score\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            print(f\"[EarlyStopping] No improvement for {self.counter}/{self.patience} epochs\")\n",
    "            \n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "                print(\"[EarlyStopping] Stopping training!\")\n",
    "                return True\n",
    "        \n",
    "        return False\n",
    "\n",
    "LR = 5e-5\n",
    "WEIGHT_DECAY = 0.0005\n",
    "EPOCHS = 50\n",
    "OVERLAP = 160\n",
    "RADIUS = 20\n",
    "PATCH_SIZE = 512\n",
    "PATIENCE = 15\n",
    "\n",
    "optimizer = Adam(params=herdnet.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Scheduler para reducir LR cuando la métrica se estanque\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='max', \n",
    "    factor=0.5, \n",
    "    patience=5, \n",
    "    verbose=True,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStoppingCallback(patience=PATIENCE, min_delta=0.002, mode='max')\n",
    "\n",
    "metrics = PointsMetrics(radius=RADIUS, num_classes=NUM_CLASSES)\n",
    "\n",
    "stitcher = HerdNetStitcher(\n",
    "    model=herdnet,\n",
    "    size=(PATCH_SIZE,PATCH_SIZE),\n",
    "    overlap=OVERLAP,\n",
    "    down_ratio=DOWN_RATIO,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "evaluator = HerdNetEvaluator(\n",
    "    model=herdnet,\n",
    "    dataloader=val_dataloader,\n",
    "    metrics=metrics,\n",
    "    stitcher=stitcher,\n",
    "    work_dir=work_dir,\n",
    "    header='validation'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=herdnet,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=EPOCHS,\n",
    "    evaluator=evaluator,\n",
    "    work_dir=work_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c668d876-65a1-4864-8fca-db6d8bacaa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Got processor for keypoints, but no transform to process it\")\n",
    "\n",
    "print(\"[INFO] Iniciando entrenamiento Fase 2 con scheduler y early stopping...\")\n",
    "\n",
    "# Entrenar por épocas manualmente para integrar scheduler\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Entrenar una época\n",
    "    trainer.train_epoch()\n",
    "    \n",
    "    # Validar\n",
    "    val_metrics = evaluator.evaluate(returns='f1_score', wandb_flag=False)\n",
    "    current_f1 = val_metrics if isinstance(val_metrics, float) else val_metrics.get('f1_score', 0)\n",
    "    \n",
    "    print(f\"\\n[Validation] F1-Score: {current_f1:.4f}\")\n",
    "    \n",
    "    # Actualizar scheduler\n",
    "    scheduler.step(current_f1)\n",
    "    \n",
    "    # Verificar early stopping\n",
    "    if early_stopping(current_f1):\n",
    "        print(f\"\\n[INFO] Early stopping activado en época {epoch+1}\")\n",
    "        break\n",
    "    \n",
    "    # Guardar mejor modelo\n",
    "    if current_f1 > trainer.best_score:\n",
    "        trainer.best_score = current_f1\n",
    "        trainer.save_checkpoint('best')\n",
    "        print(f\"[INFO] Nuevo mejor modelo guardado (F1: {current_f1:.4f})\")\n",
    "\n",
    "print(\"\\n[INFO] Entrenamiento completado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24354d76-0f71-4530-9f88-da1adb0b1abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp content/data content/drive/MyDrive/HerdNet/dataset -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee525eae-8031-4f12-92e9-548d7992e241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output folder\n",
    "test_dir = \"/content/drive/MyDrive/HerdNet/test_p2\"\n",
    "mkdir(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706b1d7-1fca-46f3-bdc4-674908af9ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animaloc.models import HerdNet\n",
    "from torch import Tensor\n",
    "from animaloc.models import LossWrapper\n",
    "from animaloc.train.losses import FocalLoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "num_classes = 7\n",
    "patch_size = 512\n",
    "down_ratio = 2\n",
    "\n",
    "herdnet = HerdNet(pretrained=False, num_classes=num_classes, down_ratio=down_ratio).cuda()\n",
    "\n",
    "weight = Tensor([0.1, 1.0, 2.0, 1.0, 6.0, 12.0, 1.0]).cuda()\n",
    "\n",
    "losses = [\n",
    "    {'loss': FocalLoss(reduction='mean'), 'idx': 0, 'idy': 0, 'lambda': 1.0, 'name': 'focal_loss'},\n",
    "    {'loss': CrossEntropyLoss(reduction='mean', weight=weight), 'idx': 1, 'idy': 1, 'lambda': 1.0, 'name': 'ce_loss'}\n",
    "]\n",
    "\n",
    "herdnet = LossWrapper(herdnet, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa3533-6d81-4853-83db-faba8f0ae4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained parameters\n",
    "from animaloc.models import load_model\n",
    "\n",
    "herdnet = load_model(herdnet, pth_path=\"/content/drive/MyDrive/HerdNet/fase_2/output/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7fa92e-a150-419e-afd4-bae9ede21b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from animaloc.train import Trainer\n",
    "from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-3\n",
    "epochs = 100\n",
    "num_classes = 7\n",
    "\n",
    "optimizer = Adam(params=herdnet.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "metrics = PointsMetrics(radius=20, num_classes=num_classes)\n",
    "\n",
    "stitcher = HerdNetStitcher(\n",
    "    model=herdnet,\n",
    "    size=(patch_size,patch_size),\n",
    "    overlap=160,\n",
    "    down_ratio=down_ratio,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "def evaluate_with_class_metrics(evaluator, dataloader, work_dir):\n",
    "    \"\"\"\n",
    "    Evalúa el modelo y calcula métricas por clase.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    evaluator : HerdNetEvaluator\n",
    "        Evaluador configurado del modelo.\n",
    "    dataloader : DataLoader\n",
    "        DataLoader con los datos de evaluación.\n",
    "    work_dir : str\n",
    "        Directorio de trabajo para guardar resultados.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    dict\n",
    "        Diccionario con todas las métricas calculadas.\n",
    "    \"\"\"\n",
    "    results = evaluator.evaluate(returns='all', wandb_flag=False)\n",
    "    \n",
    "    # Obtener detecciones\n",
    "    detections = evaluator.results\n",
    "    \n",
    "    # Mapeo de clases\n",
    "    class_map = {\n",
    "        1: 'buffalo', 2: 'elephant', 3: 'kob',\n",
    "        4: 'topi', 5: 'warthog', 6: 'waterbuck'\n",
    "    }\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"MÉTRICAS POR CLASE\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Métricas globales\n",
    "    global_f1 = results.get('f1_score', 0)\n",
    "    global_precision = results.get('precision', 0)\n",
    "    global_recall = results.get('recall', 0)\n",
    "    \n",
    "    print(f\"\\nGlobal:\")\n",
    "    print(f\"  F1-Score:  {global_f1*100:.2f}%\")\n",
    "    print(f\"  Precision: {global_precision*100:.2f}%\")\n",
    "    print(f\"  Recall:    {global_recall*100:.2f}%\")\n",
    "    \n",
    "    # Por clase (si están disponibles)\n",
    "    if 'labels' in detections.columns and len(detections) > 0:\n",
    "        print(f\"\\nDetecciones por especie:\")\n",
    "        for label, species in class_map.items():\n",
    "            count = len(detections[detections['labels'] == label])\n",
    "            print(f\"  {species:12s}: {count:4d}\")\n",
    "    \n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Create an Evaluator\n",
    "test_evaluator = HerdNetEvaluator(\n",
    "    model=herdnet,\n",
    "    dataloader=test_dataloader,\n",
    "    metrics=metrics,\n",
    "    stitcher=stitcher,\n",
    "    work_dir=test_dir,\n",
    "    header='test'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=herdnet,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=epochs,\n",
    "    evaluator=test_evaluator,\n",
    "    work_dir=test_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a020b-06f2-4057-bb7f-acd00f2447fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Got processor for keypoints, but no transform to process it\")\n",
    "\n",
    "final_results = evaluate_with_class_metrics(test_evaluator, test_dataloader, test_dir)\n",
    "\n",
    "test_f1_score = final_results.get('f1_score', 0)\n",
    "\n",
    "# Print global F1 score (%)\n",
    "print(f\"F1 score = {test_f1_score * 100:0.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6522565-32d5-4338-a0e0-0523b1195797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the detections\n",
    "detections = test_evaluator.results\n",
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726f1baa-f391-46eb-97ff-d5660600e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from animaloc.models import HerdNet\n",
    "from torch import Tensor\n",
    "from animaloc.models import LossWrapper\n",
    "from animaloc.train.losses import FocalLoss\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "num_classes = 7\n",
    "patch_size = 512\n",
    "down_ratio = 2\n",
    "\n",
    "herdnet = HerdNet(pretrained=False, num_classes=num_classes, down_ratio=down_ratio).cuda()\n",
    "\n",
    "weight = Tensor([0.1, 1.0, 2.0, 1.0, 6.0, 12.0, 1.0]).cuda()\n",
    "\n",
    "losses = [\n",
    "    {'loss': FocalLoss(reduction='mean'), 'idx': 0, 'idy': 0, 'lambda': 1.0, 'name': 'focal_loss'},\n",
    "    {'loss': CrossEntropyLoss(reduction='mean', weight=weight), 'idx': 1, 'idy': 1, 'lambda': 1.0, 'name': 'ce_loss'}\n",
    "]\n",
    "\n",
    "herdnet = LossWrapper(herdnet, losses=losses)\n",
    "\n",
    "# Load trained parameters\n",
    "from animaloc.models import load_model\n",
    "\n",
    "herdnet = load_model(herdnet, pth_path=\"/content/drive/MyDrive/HerdNet/fase_2/backup/best_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4618865-f17b-4e8d-a83e-01b64a8d2e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "from animaloc.train import Trainer\n",
    "from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "\n",
    "lr = 1e-4\n",
    "weight_decay = 1e-3\n",
    "epochs = 100\n",
    "num_classes = 7\n",
    "\n",
    "optimizer = Adam(params=herdnet.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "metrics = PointsMetrics(radius=20, num_classes=num_classes)\n",
    "\n",
    "stitcher = HerdNetStitcher(\n",
    "    model=herdnet,\n",
    "    size=(patch_size,patch_size),\n",
    "    overlap=160,\n",
    "    down_ratio=down_ratio,\n",
    "    reduction='mean'\n",
    ")\n",
    "\n",
    "# Create an Evaluator\n",
    "test_evaluator = HerdNetEvaluator(\n",
    "    model=herdnet,\n",
    "    dataloader=test_dataloader,\n",
    "    metrics=metrics,\n",
    "    stitcher=stitcher,\n",
    "    work_dir=test_dir,\n",
    "    header='test'\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=herdnet,\n",
    "    train_dataloader=train_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=epochs,\n",
    "    evaluator=test_evaluator,\n",
    "    work_dir=test_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420904c4-767d-4495-805c-60dd59e648c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start testing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Got processor for keypoints, but no transform to process it\")\n",
    "\n",
    "final_results = evaluate_with_class_metrics(test_evaluator, test_dataloader, test_dir)\n",
    "\n",
    "test_f1_score = final_results.get('f1_score', 0)\n",
    "\n",
    "# Print global F1 score (%)\n",
    "print(f\"F1 score = {test_f1_score * 100:0.0f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ccf1a-2a90-44fb-8f62-11c0ef63de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the detections\n",
    "detections = test_evaluator.results\n",
    "detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faae3349-bf57-4186-b6c8-b7f96162a919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040824a8-f0b4-4fd3-a71c-740deb9295ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a24d13-a66d-4047-b683-400df239326e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2b31e55-08f5-41fb-a529-2ceb26008c29",
   "metadata": {},
   "source": [
    "# Mejora implementada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362538ca-25d6-4ca0-b26d-01d37b4a41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inferir sobre train (no patches)\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from animaloc.models import HerdNet\n",
    "from animaloc.eval import HerdNetStitcher\n",
    "from animaloc.utils.useful_funcs import mkdir\n",
    "from animaloc.vizual import draw_points, draw_text\n",
    "\n",
    "\n",
    "class SimpleImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset simple para inferencia sin anotaciones.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    images_dir : str\n",
    "        Directorio con las imágenes.\n",
    "    transform : callable, opcional\n",
    "        Transformaciones de Albumentations a aplicar.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, images_dir, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg'))]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_name)\n",
    "        \n",
    "        image = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        # Convertir a tensor\n",
    "        image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
    "        \n",
    "        return {'image': image, 'name': img_name}\n",
    "\n",
    "\n",
    "def infer_herdnet(\n",
    "    model_path,\n",
    "    images_dir,\n",
    "    output_dir,\n",
    "    patch_size=512,\n",
    "    overlap=160,\n",
    "    down_ratio=2,\n",
    "    device=\"cuda\",\n",
    "    up=True,\n",
    "    reduction=\"mean\",\n",
    "    class_map=None,\n",
    "    draw_results=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Run inference with HerdNet model and export detections and visualizations.\n",
    "    \n",
    "    Versión mejorada sin dependencias innecesarias de CSVDataset y Evaluator.\n",
    "    \n",
    "    Parámetros\n",
    "    ----------\n",
    "    model_path : str\n",
    "        Ruta al modelo entrenado (.pth).\n",
    "    images_dir : str\n",
    "        Directorio con las imágenes para inferencia.\n",
    "    output_dir : str\n",
    "        Directorio de salida para resultados.\n",
    "    patch_size : int, opcional\n",
    "        Tamaño de parche para stitching. Por defecto 512.\n",
    "    overlap : int, opcional\n",
    "        Solapamiento entre parches. Por defecto 160.\n",
    "    down_ratio : int, opcional\n",
    "        Factor de reducción del modelo. Por defecto 2.\n",
    "    device : str, opcional\n",
    "        Dispositivo de cómputo. Por defecto \"cuda\".\n",
    "    up : bool, opcional\n",
    "        Si se upsamplea la salida. Por defecto True.\n",
    "    reduction : str, opcional\n",
    "        Método de reducción en solapamientos. Por defecto \"mean\".\n",
    "    class_map : dict, opcional\n",
    "        Mapeo de labels a nombres de especies.\n",
    "    draw_results : bool, opcional\n",
    "        Si se generan visualizaciones. Por defecto True.\n",
    "    \n",
    "    Retorna\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        DataFrame con todas las detecciones.\n",
    "    \"\"\"\n",
    "    mkdir(output_dir)\n",
    "    \n",
    "    print(f\"[INFO] Loading model from: {model_path}\")\n",
    "    device = torch.device(device if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 1. Construcción del modelo\n",
    "    num_classes = 7\n",
    "    model = HerdNet(num_classes=num_classes, down_ratio=down_ratio, pretrained=False)\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    \n",
    "    if \"model_state_dict\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(\"[INFO] Model loaded successfully.\")\n",
    "    \n",
    "    # 2. Crear Dataset y DataLoader\n",
    "    transform = A.Compose([\n",
    "        A.Normalize(p=1.0)\n",
    "    ])\n",
    "    \n",
    "    dataset = SimpleImageDataset(images_dir=images_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"[INFO] Found {len(dataset)} images for inference\")\n",
    "    \n",
    "    # 3. Configurar stitcher\n",
    "    stitcher = HerdNetStitcher(\n",
    "        model=model,\n",
    "        size=(patch_size, patch_size),\n",
    "        overlap=overlap,\n",
    "        down_ratio=down_ratio,\n",
    "        up=up,\n",
    "        reduction=reduction,\n",
    "        device_name=device,\n",
    "    )\n",
    "    \n",
    "    # 4. Ejecutar inferencia\n",
    "    print(\"[INFO] Starting inference...\")\n",
    "    all_detections = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Processing images\"):\n",
    "            images = batch['image'].to(device)\n",
    "            img_names = batch['name']\n",
    "            \n",
    "            # Obtener predicciones con stitcher\n",
    "            outputs = stitcher(images)\n",
    "            \n",
    "            # Procesar salidas\n",
    "            heatmaps = outputs[0]\n",
    "            class_maps = outputs[1]\n",
    "            \n",
    "            for i, img_name in enumerate(img_names):\n",
    "                heatmap = heatmaps[i].cpu().numpy()\n",
    "                class_map_pred = class_maps[i].cpu().numpy()\n",
    "                \n",
    "                # Detección de picos locales\n",
    "                from scipy.ndimage import maximum_filter\n",
    "                \n",
    "                # Aplicar filtro de máximos locales\n",
    "                kernel_size = 3\n",
    "                local_max = maximum_filter(heatmap, size=kernel_size)\n",
    "                \n",
    "                # Umbrales adaptativos\n",
    "                adapt_threshold = 0.2\n",
    "                neg_threshold = 0.1\n",
    "                \n",
    "                # Máscara de detecciones\n",
    "                detection_mask = (heatmap == local_max) & (heatmap > adapt_threshold)\n",
    "                \n",
    "                # Extraer coordenadas y scores\n",
    "                coords = np.column_stack(np.where(detection_mask))\n",
    "                \n",
    "                for coord in coords:\n",
    "                    y_pred, x_pred = coord\n",
    "                    \n",
    "                    # Escalar coordenadas al tamaño original\n",
    "                    x_scaled = int(x_pred * down_ratio)\n",
    "                    y_scaled = int(y_pred * down_ratio)\n",
    "                    \n",
    "                    score = float(heatmap[y_pred, x_pred])\n",
    "                    \n",
    "                    # Obtener clase predicha\n",
    "                    if class_map_pred.ndim == 3:\n",
    "                        label = int(np.argmax(class_map_pred[:, y_pred, x_pred]))\n",
    "                    else:\n",
    "                        label = int(class_map_pred[y_pred, x_pred])\n",
    "                    \n",
    "                    # Filtrar clase 0 (fondo)\n",
    "                    if label > 0:\n",
    "                        all_detections.append({\n",
    "                            'images': img_name,\n",
    "                            'x': x_scaled,\n",
    "                            'y': y_scaled,\n",
    "                            'labels': label,\n",
    "                            'scores': score\n",
    "                        })\n",
    "    \n",
    "    # 5. Crear DataFrame de detecciones\n",
    "    detections = pd.DataFrame(all_detections)\n",
    "    \n",
    "    if detections.empty:\n",
    "        print(\"[WARNING] No detections found!\")\n",
    "        detections = pd.DataFrame(columns=['images', 'x', 'y', 'labels', 'scores', 'species'])\n",
    "    \n",
    "    # 6. Asignar nombres de especies\n",
    "    if class_map is None:\n",
    "        class_map = {\n",
    "            1: 'buffalo', 2: 'elephant', 3: 'kob',\n",
    "            4: 'topi', 5: 'warthog', 6: 'waterbuck'\n",
    "        }\n",
    "    \n",
    "    if not detections.empty:\n",
    "        detections['species'] = detections['labels'].map(class_map)\n",
    "    \n",
    "    # 7. Guardar CSV\n",
    "    csv_path = Path(output_dir) / \"detections.csv\"\n",
    "    detections.to_csv(csv_path, index=False)\n",
    "    print(f\"[INFO] Saved detections to: {csv_path}\")\n",
    "    \n",
    "    # 8. Exportar visualizaciones (opcional)\n",
    "    if draw_results and not detections.empty:\n",
    "        print(\"[INFO] Exporting plots and thumbnails...\")\n",
    "        dest_plots = Path(output_dir) / \"plots\"\n",
    "        dest_thumbs = Path(output_dir) / \"thumbnails\"\n",
    "        mkdir(dest_plots)\n",
    "        mkdir(dest_thumbs)\n",
    "        \n",
    "        for img_name in tqdm(detections['images'].unique(), desc=\"Drawing\"):\n",
    "            img_path = os.path.join(images_dir, img_name)\n",
    "            \n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "            \n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_cpy = img.copy()\n",
    "            \n",
    "            img_detections = detections[detections['images'] == img_name]\n",
    "            pts = list(img_detections[['y', 'x']].to_records(index=False))\n",
    "            pts = [(int(y), int(x)) for y, x in pts]\n",
    "            \n",
    "            output = draw_points(img, pts, color='red', size=10)\n",
    "            output.save(dest_plots / img_name, quality=95)\n",
    "            \n",
    "            sp_score = list(img_detections[['species', 'scores']].to_records(index=False))\n",
    "            \n",
    "            for idx, ((y, x), (sp, score)) in enumerate(zip(pts, sp_score)):\n",
    "                off = 128\n",
    "                coords = (x - off, y - off, x + off, y + off)\n",
    "                \n",
    "                # Asegurar que las coordenadas estén dentro de los límites\n",
    "                w, h = img_cpy.size\n",
    "                coords = (\n",
    "                    max(0, coords[0]),\n",
    "                    max(0, coords[1]),\n",
    "                    min(w, coords[2]),\n",
    "                    min(h, coords[3])\n",
    "                )\n",
    "                \n",
    "                thumbnail = img_cpy.crop(coords)\n",
    "                score_pct = round(score * 100, 0)\n",
    "                thumbnail = draw_text(thumbnail, f\"{sp} | {score_pct}%\", position=(10, 5), font_size=20)\n",
    "                thumbnail.save(dest_thumbs / f\"{img_name[:-4]}_{idx}.JPG\")\n",
    "    \n",
    "    # 9. Resumen final\n",
    "    print(\"\\n[INFO] Detection summary per species:\")\n",
    "    if not detections.empty:\n",
    "        for sp, count in detections['species'].value_counts().items():\n",
    "            print(f\"  - {sp}: {count}\")\n",
    "        print(f\"  Total detections: {len(detections)}\")\n",
    "    else:\n",
    "        print(\"  No detections found.\")\n",
    "    \n",
    "    return detections\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "MODEL_PATH = \"/content/drive/MyDrive/HerdNet/fase_1/best_model.pth\"\n",
    "IMAGES_DIR = \"/content/data/train\"\n",
    "OUTPUT_DIR = f\"/content/drive/MyDrive/HerdNet/fase_1/infer_train_{datetime.now().strftime('%Y%m%d')}\"\n",
    "\n",
    "detecciones = infer_herdnet(\n",
    "    model_path=MODEL_PATH,\n",
    "    images_dir=IMAGES_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    patch_size=512,\n",
    "    overlap=160,\n",
    "    down_ratio=2,\n",
    "    device=\"cuda\",\n",
    "    draw_results=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa691cce-2193-4693-bf82-fbf738226a51",
   "metadata": {},
   "source": [
    "# ajustes de parámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea453d6-4b98-467e-81e7-a4bca10a802d",
   "metadata": {},
   "source": [
    "1. Fase 1 - Entrenamiento inicial:\n",
    "\n",
    "batch_size: 4 a 8 (aprovechar mejor GPU)\n",
    "epochs: 100 a 80 (suficiente con early stopping)\n",
    "warmup_iters: 100 a 200 (estabilización inicial)\n",
    "\n",
    "2. HNP Mining (HardNegativePatchMinerV2):\n",
    "\n",
    "score_percentile: 0.6 a 0.5 (capturar más FPs difíciles)\n",
    "max_samples_per_image: 15 a 12 (evitar sobrerrepresentación)\n",
    "min_distance_between_hnp: 80 a 100 (mayor diversidad espacial)\n",
    "\n",
    "3. Balanceo (BalancedPatchSampler):\n",
    "\n",
    "target_ratio: 0.25 a 0.20 (reducir HNPs al 20%, más conservador)\n",
    "\n",
    "4. Fase 2 - Data Augmentation:\n",
    "\n",
    "ShiftScaleRotate rotate_limit: 15 a 20 (mayor rotación)\n",
    "HueSaturationValue sat_shift_limit: 20 a 15 (menos saturación)\n",
    "batch_size: 16 a 12 (evitar OOM con augmentation pesado)\n",
    "\n",
    "5. Fase 2 - Optimización:\n",
    "\n",
    "LR: 5e-5 a 3e-5 (más conservador para fine-tuning)\n",
    "EPOCHS: 50 a 40 (con early stopping es suficiente)\n",
    "PATIENCE (early stopping): 15 a 12 (detener antes)\n",
    "scheduler patience: 5 a 4 (reducir LR más rápido)\n",
    "\n",
    "6. Inferencia:\n",
    "\n",
    "overlap: 160 a 192 (mejor stitching, ~37.5%)\n",
    "adapt_threshold: 0.2 a 0.3 (reducir FPs)\n",
    "kernel_size (local_max): 3 a 5 (suprimir picos cercanos)\n",
    "\n",
    "------ Others -----\n",
    "\n",
    "- FocalLoss gamma: tunear gamma para controlar hard examples; probar {0.5, 1.0, 2.0}; empezar en 1.0 y bajar a 0.5 si recall cae mucho en clases\n",
    "pequeñas.\n",
    "- Combinar losses (lambda): variar lambdas entre detecciones y mapa de clases; probar lambda_ce ∈ {0.5,1.0,2.0} manteniendo focal λ=1 para priorizar \n",
    "robustez.\n",
    "\n",
    "\n",
    "- Optimizadores alternativos: probar AdamW (mejor manejo weight decay) y RAdam para estabilidad;  y comparas. Si overfitting, AdamW suele ayudar.\n",
    "- LR schedule: además de ReduceLROnPlateau, evaluar: CosineAnnealingWarmRestarts. ranges: initial LR 3e-5–1e-4 \n",
    "\n",
    "- Memoria, batch y precisión numérica:\n",
    "- Mixed precision (AMP): activar FP16 (apex o native torch.cuda.amp) para ganar batch sin OOM y acelerar.\n",
    "\n",
    "... And more (jejeje)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f841eb-4fb7-4d58-9c35-88eb915d9133",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Fauna Detection)",
   "language": "python",
   "name": "fauna_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
