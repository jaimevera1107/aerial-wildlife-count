# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1d83hQXvLSlg2HzNaz8ZZzZnAOv-9w1QA
"""

# Commented out IPython magic to ensure Python compatibility.
# Instalar dependencias
# %pip install -q ultralytics pyyaml opencv-python pillow tqdm matplotlib seaborn pandas

# Verificar instalaci√≥n
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# ============================================================
# VARIABLES GLOBALES PARA BACKUP AUTOM√ÅTICO
# ============================================================

# Variables globales para el sistema de backup
backup_thread_running = False
backup_thread = None

print("‚úÖ Variables globales de backup inicializadas")

"""## üì¶ Importar Librer√≠as"""
import os
import sys
import yaml
import torch
import numpy as np
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from PIL import Image
import shutil
import json
from tqdm import tqdm

from ultralytics import YOLO
from google.colab import files, drive
from IPython.display import Image as IPImage, display

# Configurar matplotlib
plt.style.use('default')
sns.set_palette("husl")

print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA device: {torch.cuda.get_device_name(0)}")
    print(f"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

"""## üìÅ Configuraci√≥n de Datos"""

# ============================================================
# CONFIGURACI√ìN DE RUTAS PRINCIPALES (Unificado con HerdNet)
# ============================================================

# Definir la ruta base principal (ajustar seg√∫n el entorno: Drive o local)
BASE_DIR = Path("/content/drive/MyDrive/aerial-wildlife-count")

# ============================================================
# RUTAS DE IM√ÅGENES Y ANOTACIONES (COCO JSON) - Igual que HerdNet
# ============================================================

# Rutas de los archivos de anotaciones en formato COCO
TRAIN_ANN_FILE = BASE_DIR / "data" / "coco" / "train" / "train_annotations.json"
VAL_ANN_FILE = BASE_DIR / "data" / "coco" / "val" / "val_annotations.json"
TEST_ANN_FILE = BASE_DIR / "data" / "coco" / "test" / "test_annotations.json"

# Rutas de las carpetas de im√°genes correspondientes a cada conjunto
TRAIN_IMG_DIR = BASE_DIR / "data" / "images" / "train"
VAL_IMG_DIR = BASE_DIR / "data" / "images" / "val"
TEST_IMG_DIR = BASE_DIR / "data" / "images" / "test"

# ============================================================
# RUTAS ALTERNATIVAS (Fallback para compatibilidad)
# ============================================================

# Rutas alternativas si no existe la estructura est√°ndar
TRAIN_ANN_FILE_ALT = BASE_DIR / "data" / "groundtruth" / "json" / "big_size" / "train_big_size_A_B_E_K_WH_WB.json"
VAL_ANN_FILE_ALT = BASE_DIR / "data" / "groundtruth" / "json" / "big_size" / "val_big_size_A_B_E_K_WH_WB.json"
TEST_ANN_FILE_ALT = BASE_DIR / "data" / "groundtruth" / "json" / "big_size" / "test_big_size_A_B_E_K_WH_WB.json"

# Rutas alternativas para im√°genes
TRAIN_IMG_DIR_ALT = BASE_DIR / "data" / "train"
VAL_IMG_DIR_ALT = BASE_DIR / "data" / "val"
TEST_IMG_DIR_ALT = BASE_DIR / "data" / "test"

# ============================================================
# FUNCI√ìN PARA CONFIGURAR DATOS (Unificada con HerdNet)
# ============================================================

def setup_data():
    """Configurar datos desde Google Drive con detecci√≥n autom√°tica de estructura"""

    # Montar Google Drive
    drive.mount('/content/drive')
    print("‚úÖ Google Drive montado")

    # Verificar si existe la estructura est√°ndar (igual que HerdNet)
    if TRAIN_ANN_FILE.exists() and TRAIN_IMG_DIR.exists():
        print("‚úÖ Datos encontrados (estructura est√°ndar COCO)")
        return str(BASE_DIR), "standard"
    elif TRAIN_ANN_FILE_ALT.exists() and TRAIN_IMG_DIR_ALT.exists():
        print("‚úÖ Datos encontrados (estructura alternativa groundtruth)")
        return str(BASE_DIR), "groundtruth"
    else:
        # Buscar en ubicaciones alternativas
        drive_path = "/content/drive/MyDrive"
        possible_paths = [
            f"{drive_path}/aerial-wildlife-count",
            f"{drive_path}/datasets/aerial-wildlife-count",
            f"{drive_path}/Colab Notebooks/aerial-wildlife-count"
        ]

        for path in possible_paths:
            if os.path.exists(path):
                print(f"‚úÖ Dataset encontrado en ubicaci√≥n alternativa: {path}")
                return path, "legacy"

        print("‚ùå No se encontr√≥ el dataset en Google Drive")
        return None, None

# Configurar datos
data_path, data_type = setup_data()
if data_path:
    print(f"üìÅ Ruta de datos configurada: {data_path}")
    print(f"üìä Tipo de datos: {data_type}")
else:
    print("‚ö†Ô∏è  Configura los datos manualmente antes de continuar")

"""## üìä An√°lisis de Datos

"""

# Funci√≥n para encontrar y analizar datasets (Unificada con HerdNet)
def find_and_analyze_datasets():
    """Encontrar y analizar datasets disponibles seg√∫n el tipo de datos"""

    if not data_path:
        print("‚ùå No hay ruta de datos configurada")
        return []

    datasets_found = []

    if data_type == "standard":
        # Estructura est√°ndar COCO (igual que HerdNet)
        datasets_found = [TRAIN_ANN_FILE, VAL_ANN_FILE, TEST_ANN_FILE]
        print("üìä Usando datasets est√°ndar COCO:")
        print(f"  Train: {TRAIN_ANN_FILE}")
        print(f"  Val: {VAL_ANN_FILE}")
        print(f"  Test: {TEST_ANN_FILE}")

    elif data_type == "groundtruth":
        # Estructura alternativa groundtruth
        datasets_found = [TRAIN_ANN_FILE_ALT, VAL_ANN_FILE_ALT, TEST_ANN_FILE_ALT]
        print("üìä Usando datasets groundtruth:")
        print(f"  Train: {TRAIN_ANN_FILE_ALT}")
        print(f"  Val: {VAL_ANN_FILE_ALT}")
        print(f"  Test: {TEST_ANN_FILE_ALT}")

    else:
        # Estructura legacy - buscar archivos JSON
        data_root = Path(data_path)
        json_patterns = [
            "**/train_*.json",
            "**/val_*.json",
            "**/test_*.json",
            "**/*_big_size_*.json",
            "**/*_subframes_*.json"
        ]

        for pattern in json_patterns:
            for json_file in data_root.glob(pattern):
                if json_file.is_file():
                    datasets_found.append(json_file)

        print(f"üìä Datasets encontrados en estructura legacy ({len(datasets_found)}):")
        for i, dataset in enumerate(datasets_found):
            print(f"  {i+1}. {dataset}")

    # Analizar el primer dataset encontrado
    if datasets_found:
        sample_data = analyze_dataset(datasets_found[0])
        return datasets_found

    return []

# Funci√≥n para analizar un dataset COCO
def analyze_dataset(json_path):
    """Analizar estad√≠sticas de un dataset COCO"""

    with open(json_path, 'r') as f:
        data = json.load(f)

    print(f"\nüìà An√°lisis de {json_path.name}:")
    print(f"  Im√°genes: {len(data['images'])}")
    print(f"  Anotaciones: {len(data['annotations'])}")
    print(f"  Categor√≠as: {len(data['categories'])}")

    # Estad√≠sticas por categor√≠a
    cat_counts = {}
    for ann in data['annotations']:
        cat_id = ann['category_id']
        cat_counts[cat_id] = cat_counts.get(cat_id, 0) + 1

    print("\n  Distribuci√≥n por categor√≠a:")
    for cat in data['categories']:
        count = cat_counts.get(cat['id'], 0)
        print(f"    {cat['name']}: {count}")

    return data

# Buscar y analizar datasets
datasets = find_and_analyze_datasets()



"""## ‚öôÔ∏è Configuraci√≥n del Entrenamiento"""

# Configuraci√≥n del entrenamiento
class YOLOConfig:
    def __init__(self):
        # Par√°metros del modelo - OPTIMIZADOS PARA VELOCIDAD
        self.model = 'yolov8s.pt'  # yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt
        self.image_size = 512
        self.epochs = 100
        self.batch_size = 64  # AUMENTADO para mayor velocidad (ajustar seg√∫n memoria)
        self.learning_rate = 0.01
        self.patience = 10
        self.device = 0  # GPU 0
        self.workers = 8  # AUMENTADO para mayor paralelizaci√≥n
        self.project = '/content/runs_yolo'
        self.name = 'yolo_aerial_wildlife_v1'
        self.fp16 = True  # Mixed precision

        # NUEVAS CONFIGURACIONES V1
        self.save_period = 3  # Guardar cada 5 √©pocas (m√°s frecuente)
        self.drive_backup_period = 3  # Backup en Drive cada 10 √©pocas
        self.drive_backup_dir = '/content/drive/MyDrive/aerial-wildlife-count-results/yolo_v1'
        self.resume_training = True  # Permitir reanudar entrenamiento

        # Clases del dataset
        self.classes = [
            "Buffalo", "Elephant", "Kob",
            "Alcelaphinae", "Warthog", "Waterbuck"
        ]

    def print_config(self):
        print("üîß Configuraci√≥n YOLOv8 V1 (Optimizada):")
        print(f"  Modelo: {self.model}")
        print(f"  Tama√±o de imagen: {self.image_size}")
        print(f"  √âpocas: {self.epochs}")
        print(f"  Batch size: {self.batch_size} (OPTIMIZADO)")
        print(f"  Workers: {self.workers} (OPTIMIZADO)")
        print(f"  Learning rate: {self.learning_rate}")
        print(f"  Dispositivo: {self.device}")
        print(f"  Mixed precision: {self.fp16}")
        print(f"  Save period: {self.save_period} √©pocas")
        print(f"  Drive backup: {self.drive_backup_period} √©pocas")
        print(f"  Resume training: {self.resume_training}")

# Crear instancia de configuraci√≥n
yolo_config = YOLOConfig()
yolo_config.print_config()

"""## üî• Funciones de Backup Autom√°tico en Drive

"""

# ============================================================
# FUNCIONES DE BACKUP AUTOM√ÅTICO EN DRIVE - V1 (TIEMPO REAL)
# ============================================================

import shutil
import time
from datetime import datetime
import threading
from ultralytics.utils.callbacks import default_callbacks

def create_drive_backup_dir():
    """Crear directorio de backup en Drive"""
    backup_dir = Path(yolo_config.drive_backup_dir)
    backup_dir.mkdir(parents=True, exist_ok=True)
    print(f"‚úÖ Directorio de backup creado: {backup_dir}")
    return backup_dir

def backup_to_drive(epoch=None, force=False):
    """Hacer backup de checkpoints a Drive"""
    try:
        # Crear directorio de backup
        backup_dir = create_drive_backup_dir()

        # Directorio fuente (Colab)
        source_dir = Path(f"{yolo_config.project}/{yolo_config.name}")

        if not source_dir.exists():
            print("‚ùå No existe directorio de entrenamiento para hacer backup")
            return False

        # Crear subdirectorio con timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if epoch is not None:
            backup_subdir = backup_dir / f"epoch_{epoch}_{timestamp}"
        else:
            backup_subdir = backup_dir / f"backup_{timestamp}"

        backup_subdir.mkdir(exist_ok=True)

        # Copiar archivos importantes
        files_to_backup = [
            "weights/",
            "results.png",
            "confusion_matrix.png",
            "results.csv",
            "train_batch*.jpg",
            "val_batch*.jpg"
        ]

        copied_files = 0
        for pattern in files_to_backup:
            try:
                for file_path in source_dir.glob(pattern):
                    if file_path.is_file():
                        dest_path = backup_subdir / file_path.name
                        shutil.copy2(file_path, dest_path)
                        copied_files += 1
                    elif file_path.is_dir():
                        dest_path = backup_subdir / file_path.name
                        shutil.copytree(file_path, dest_path, dirs_exist_ok=True)
                        copied_files += 1
            except Exception as e:
                print(f"‚ö†Ô∏è Error copiando {pattern}: {e}")

        print(f"‚úÖ Backup completado: {copied_files} archivos copiados a {backup_subdir}")
        return True

    except Exception as e:
        print(f"‚ùå Error en backup: {e}")
        return False

# ============================================================
# CALLBACK PERSONALIZADO PARA BACKUP EN TIEMPO REAL
# ============================================================

class RealtimeBackupCallback:
    """Callback personalizado para backup en tiempo real durante el entrenamiento"""

    def __init__(self, backup_period=3):
        self.backup_period = backup_period
        self.last_backup_epoch = 0
        self.backup_dir = None

    def on_train_epoch_end(self, trainer):
        """Se ejecuta al final de cada √©poca de entrenamiento"""
        try:
            current_epoch = trainer.epoch

            # Verificar si es momento de hacer backup
            if current_epoch - self.last_backup_epoch >= self.backup_period:
                print(f"üîÑ Iniciando backup autom√°tico en tiempo real (√©poca {current_epoch})...")

                # Crear directorio de backup si no existe
                if self.backup_dir is None:
                    self.backup_dir = create_drive_backup_dir()

                # Hacer backup inmediato
                if backup_to_drive(epoch=current_epoch):
                    self.last_backup_epoch = current_epoch

                    # Actualizar archivo de control
                    backup_file = Path(f"{yolo_config.drive_backup_dir}/last_backup_epoch.txt")
                    backup_file.parent.mkdir(parents=True, exist_ok=True)
                    with open(backup_file, 'w') as f:
                        f.write(str(current_epoch))

                    print(f"‚úÖ Backup en tiempo real completado (√©poca {current_epoch})")
                else:
                    print(f"‚ùå Error en backup en tiempo real (√©poca {current_epoch})")

        except Exception as e:
            print(f"‚ùå Error en callback de backup: {e}")

    def on_val_end(self, validator):
        """Se ejecuta al final de la validaci√≥n"""
        try:
            # Obtener la √©poca actual del trainer asociado al validator
            current_epoch = getattr(validator, 'epoch', None)
            if current_epoch is None and hasattr(validator, 'trainer'):
                current_epoch = getattr(validator.trainer, 'epoch', None)
            
            # Si no podemos obtener la √©poca, usar un valor por defecto
            if current_epoch is None:
                current_epoch = "unknown"
                print("‚ö†Ô∏è No se pudo obtener el n√∫mero de √©poca para backup")
                return

            # Backup del best model si es mejor que el anterior
            if hasattr(validator, 'best_fitness') and validator.best_fitness is not None:
                print(f"üìä √âpoca {current_epoch}: Mejor fitness = {validator.best_fitness:.4f}")

                # Backup del best model cada vez que mejora
                if backup_to_drive(epoch=f"best_{current_epoch}"):
                    print(f"‚úÖ Best model backup completado (√©poca {current_epoch})")

        except Exception as e:
            print(f"‚ùå Error en backup de best model: {e}")

# ============================================================
# FUNCIONES DE BACKUP LEGACY (MANTENIDAS PARA COMPATIBILIDAD)
# ============================================================

def auto_backup_thread():
    """Thread para backup autom√°tico cada X √©pocas (LEGACY - NO USAR)"""
    global backup_thread_running
    backup_thread_running = True

    print("üîÑ Thread de backup autom√°tico iniciado (LEGACY)")

    while backup_thread_running:
        try:
            # Verificar si hay nuevos checkpoints
            weights_dir = Path(f"{yolo_config.project}/{yolo_config.name}/weights")
            if weights_dir.exists():
                checkpoints = list(weights_dir.glob("*.pt"))
                if checkpoints:
                    # Obtener el checkpoint m√°s reciente
                    latest_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)

                    # Verificar si necesita backup
                    backup_file = Path(f"{yolo_config.drive_backup_dir}/last_backup_epoch.txt")
                    last_backup_epoch = 0

                    if backup_file.exists():
                        try:
                            with open(backup_file, 'r') as f:
                                last_backup_epoch = int(f.read().strip())
                        except:
                            last_backup_epoch = 0

                    # Extraer √©poca del nombre del archivo
                    current_epoch = 0
                    if "epoch" in latest_checkpoint.name:
                        try:
                            current_epoch = int(latest_checkpoint.name.split("epoch_")[1].split(".")[0])
                        except:
                            current_epoch = 0

                    # Hacer backup si ha pasado el per√≠odo configurado
                    if current_epoch - last_backup_epoch >= yolo_config.drive_backup_period:
                        print(f"üîÑ Iniciando backup autom√°tico (√©poca {current_epoch})...")
                        if backup_to_drive(epoch=current_epoch):
                            # Actualizar archivo de control
                            backup_file.parent.mkdir(parents=True, exist_ok=True)
                            with open(backup_file, 'w') as f:
                                f.write(str(current_epoch))
                            print(f"‚úÖ Backup autom√°tico completado (√©poca {current_epoch})")

            # Esperar 5 minutos antes de verificar nuevamente
            time.sleep(300)  # 5 minutos

        except Exception as e:
            print(f"‚ùå Error en backup autom√°tico: {e}")
            time.sleep(60)  # Esperar 1 minuto en caso de error

    print("üõë Thread de backup autom√°tico detenido")

def start_auto_backup():
    """Iniciar backup autom√°tico en segundo plano (LEGACY - NO USAR)"""
    global backup_thread, backup_thread_running

    # Detener thread anterior si existe
    if backup_thread_running:
        stop_auto_backup()
        time.sleep(2)  # Esperar a que se detenga

    backup_thread_running = False

    # Verificar si ya hay un thread corriendo
    if 'backup_thread' in globals() and backup_thread is not None and backup_thread.is_alive():
        print("‚ö†Ô∏è Backup autom√°tico ya est√° ejecut√°ndose")
        return

    backup_thread = threading.Thread(target=auto_backup_thread, daemon=True)
    backup_thread.start()
    print("üöÄ Backup autom√°tico iniciado en segundo plano")

def stop_auto_backup():
    """Detener backup autom√°tico (LEGACY - NO USAR)"""
    global backup_thread_running
    backup_thread_running = False
    print("üõë Backup autom√°tico detenido")

def resume_training_from_drive():
    """Reanudar entrenamiento desde el √∫ltimo checkpoint en Drive"""
    try:
        backup_dir = Path(yolo_config.drive_backup_dir)
        if not backup_dir.exists():
            print("‚ùå No hay backups disponibles en Drive")
            return None

        # Buscar el backup m√°s reciente
        backup_dirs = [d for d in backup_dir.iterdir() if d.is_dir() and "epoch_" in d.name]
        if not backup_dirs:
            print("‚ùå No se encontraron backups con checkpoints")
            return None

        # Ordenar por fecha de modificaci√≥n
        latest_backup = max(backup_dirs, key=lambda x: x.stat().st_mtime)

        # Buscar el mejor checkpoint
        weights_dir = latest_backup / "weights"
        if weights_dir.exists():
            checkpoints = list(weights_dir.glob("*.pt"))
            if checkpoints:
                # Priorizar best.pt, luego el m√°s reciente
                best_checkpoint = None
                for ckpt in checkpoints:
                    if "best" in ckpt.name:
                        best_checkpoint = ckpt
                        break

                if not best_checkpoint:
                    best_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)

                print(f"‚úÖ Checkpoint encontrado para reanudar: {best_checkpoint}")
                return str(best_checkpoint)

        print("‚ùå No se encontr√≥ checkpoint v√°lido en backups")
        return None

    except Exception as e:
        print(f"‚ùå Error al buscar checkpoint para reanudar: {e}")
        return None

print("‚úÖ Funciones de backup autom√°tico cargadas")

"""## üìä Funciones de Monitoreo en Tiempo Real

"""

# ============================================================
# FUNCIONES DE MONITOREO EN TIEMPO REAL
# ============================================================

def monitor_training_progress():
    """Monitorear el progreso del entrenamiento en tiempo real"""
    try:
        results_dir = Path(f"{yolo_config.project}/{yolo_config.name}")

        if not results_dir.exists():
            print("‚ùå Directorio de resultados no encontrado")
            return

        # Verificar archivos de resultados
        results_csv = results_dir / "results.csv"
        if results_csv.exists():
            import pandas as pd
            df = pd.read_csv(results_csv)
            if not df.empty:
                latest_epoch = df.iloc[-1]
                print(f"üìä Progreso actual:")
                print(f"  √âpoca: {latest_epoch.get('epoch', 'N/A')}")
                print(f"  mAP: {latest_epoch.get('metrics/mAP50(B)', 'N/A'):.4f}")
                print(f"  Loss: {latest_epoch.get('train/box_loss', 'N/A'):.4f}")
                print(f"  Val Loss: {latest_epoch.get('val/box_loss', 'N/A'):.4f}")

        # Verificar checkpoints
        weights_dir = results_dir / "weights"
        if weights_dir.exists():
            checkpoints = list(weights_dir.glob("*.pt"))
            print(f"üìÅ Checkpoints disponibles: {len(checkpoints)}")
            for ckpt in checkpoints:
                size_mb = ckpt.stat().st_size / (1024 * 1024)
                print(f"  - {ckpt.name} ({size_mb:.1f} MB)")

        # Verificar backups en Drive
        backup_dir = Path(yolo_config.drive_backup_dir)
        if backup_dir.exists():
            backups = list(backup_dir.glob("epoch_*"))
            print(f"üíæ Backups en Drive: {len(backups)}")

    except Exception as e:
        print(f"‚ùå Error en monitoreo: {e}")

def get_training_status():
    """Obtener estado actual del entrenamiento"""
    try:
        results_dir = Path(f"{yolo_config.project}/{yolo_config.name}")

        if not results_dir.exists():
            return "No iniciado"

        # Verificar si hay resultados
        results_csv = results_dir / "results.csv"
        if results_csv.exists():
            import pandas as pd
            df = pd.read_csv(results_csv)
            if not df.empty:
                latest_epoch = df.iloc[-1]['epoch']
                total_epochs = yolo_config.epochs
                progress = (latest_epoch / total_epochs) * 100
                return f"En progreso: {latest_epoch}/{total_epochs} √©pocas ({progress:.1f}%)"

        return "Iniciando"

    except Exception as e:
        return f"Error: {e}"

def estimate_remaining_time():
    """Estimar tiempo restante de entrenamiento"""
    try:
        results_dir = Path(f"{yolo_config.project}/{yolo_config.name}")
        results_csv = results_dir / "results.csv"

        if not results_csv.exists():
            return "No disponible"

        import pandas as pd
        df = pd.read_csv(results_csv)

        if len(df) < 2:
            return "Calculando..."

        # Calcular tiempo promedio por √©poca basado en el n√∫mero de √©pocas
        # Asumir que cada √©poca toma aproximadamente el mismo tiempo
        current_epoch = df.iloc[-1]['epoch']
        remaining_epochs = yolo_config.epochs - current_epoch

        # Estimaci√≥n simple: asumir 2-5 minutos por √©poca
        estimated_minutes = remaining_epochs * 3  # 3 minutos promedio por √©poca

        if estimated_minutes < 60:
            return f"Tiempo estimado restante: {estimated_minutes:.0f} minutos"
        else:
            hours = estimated_minutes / 60
            return f"Tiempo estimado restante: {hours:.1f} horas"

    except Exception as e:
        return f"Error: {e}"

def show_training_status():
    """Mostrar estado completo del entrenamiento"""
    print("=" * 60)
    print("üìä ESTADO DEL ENTRENAMIENTO YOLOv8 V1")
    print("=" * 60)
    print(f"Estado: {get_training_status()}")
    print(f"Tiempo restante: {estimate_remaining_time()}")
    print()
    monitor_training_progress()
    print("=" * 60)

# ============================================================
# CALLBACK DE MONITOREO DURANTE EL ENTRENAMIENTO
# ============================================================

class TrainingMonitorCallback:
    """Callback para monitorear el entrenamiento en tiempo real"""

    def __init__(self, monitor_period=5):
        self.monitor_period = monitor_period
        self.last_monitor_epoch = 0

    def on_train_epoch_end(self, trainer):
        """Se ejecuta al final de cada √©poca de entrenamiento"""
        try:
            current_epoch = trainer.epoch

            # Monitorear cada X √©pocas
            if current_epoch - self.last_monitor_epoch >= self.monitor_period:
                print(f"\nüìä MONITOREO √âPOCA {current_epoch}:")
                print(f"  Loss: {trainer.loss:.4f}")
                if hasattr(trainer, 'metrics') and trainer.metrics:
                    print(f"  mAP@0.5: {trainer.metrics.get('mAP50', 'N/A')}")
                    print(f"  Precision: {trainer.metrics.get('precision', 'N/A')}")
                    print(f"  Recall: {trainer.metrics.get('recall', 'N/A')}")

                # Mostrar progreso
                progress = (current_epoch / yolo_config.epochs) * 100
                print(f"  Progreso: {current_epoch}/{yolo_config.epochs} √©pocas ({progress:.1f}%)")

                self.last_monitor_epoch = current_epoch

        except Exception as e:
            print(f"‚ùå Error en callback de monitoreo: {e}")

    def on_val_end(self, validator):
        """Se ejecuta al final de la validaci√≥n"""
        try:
            # Obtener la √©poca actual del trainer asociado al validator
            current_epoch = getattr(validator, 'epoch', None)
            if current_epoch is None and hasattr(validator, 'trainer'):
                current_epoch = getattr(validator.trainer, 'epoch', None)
            
            # Si no podemos obtener la √©poca, usar un valor por defecto
            if current_epoch is None:
                current_epoch = "unknown"

            if hasattr(validator, 'metrics') and validator.metrics:
                print(f"üìà √âpoca {current_epoch} - Validaci√≥n completada")
                print(f"  mAP@0.5: {validator.metrics.get('mAP50', 'N/A'):.4f}")
                print(f"  mAP@0.5:0.95: {validator.metrics.get('mAP50-95', 'N/A'):.4f}")

        except Exception as e:
            print(f"‚ùå Error en callback de validaci√≥n: {e}")

print("‚úÖ Funciones de monitoreo en tiempo real cargadas")

"""## üîÑ Conversi√≥n de Datos COCO a YOLO

"""

# Funci√≥n para convertir COCO a YOLO
def coco_to_yolo(coco_json_path, images_dir, output_dir, class_names):
    """Convierte anotaciones COCO a formato YOLO"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Leer archivo COCO
    with open(coco_json_path, 'r') as f:
        coco_data = json.load(f)

    # Crear mapeo de categor√≠as
    cat_id_to_class = {cat['id']: cat['name'] for cat in coco_data['categories']}
    class_to_id = {name: idx for idx, name in enumerate(class_names)}

    # Crear mapeo de im√°genes
    img_id_to_info = {img['id']: img for img in coco_data['images']}

    # Procesar anotaciones
    annotations_by_image = {}
    for ann in coco_data['annotations']:
        img_id = ann['image_id']
        if img_id not in annotations_by_image:
            annotations_by_image[img_id] = []
        annotations_by_image[img_id].append(ann)

    # Convertir cada imagen
    for img_id, img_info in tqdm(img_id_to_info.items(), desc="Convirtiendo a YOLO"):
        img_name = img_info['file_name']
        img_width = img_info['width']
        img_height = img_info['height']

        # Crear archivo de anotaci√≥n YOLO
        txt_name = Path(img_name).stem + '.txt'
        txt_path = output_dir / txt_name

        with open(txt_path, 'w') as f:
            if img_id in annotations_by_image:
                for ann in annotations_by_image[img_id]:
                    cat_name = cat_id_to_class[ann['category_id']]
                    if cat_name in class_to_id:
                        class_id = class_to_id[cat_name]

                        # Convertir bbox [x, y, w, h] a [center_x, center_y, w, h] normalizado
                        x, y, w, h = ann['bbox']
                        center_x = (x + w/2) / img_width
                        center_y = (y + h/2) / img_height
                        norm_w = w / img_width
                        norm_h = h / img_height

                        f.write(f"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\n")

    print(f"‚úÖ Convertido {len(img_id_to_info)} im√°genes a formato YOLO")
    return output_dir

# Preparar datos para conversi√≥n (Unificado con HerdNet)
def prepare_yolo_data():
    """Preparar datos para entrenamiento YOLO seg√∫n el tipo de datos"""

    if data_type == "standard":
        # Usar rutas est√°ndar COCO (igual que HerdNet)
        train_json = TRAIN_ANN_FILE
        val_json = VAL_ANN_FILE
        test_json = TEST_ANN_FILE

        # Verificar que existan
        if not all([train_json.exists(), val_json.exists()]):
            print("‚ùå Faltan archivos de datos est√°ndar COCO")
            return None, None, None

    elif data_type == "groundtruth":
        # Usar rutas groundtruth
        train_json = TRAIN_ANN_FILE_ALT
        val_json = VAL_ANN_FILE_ALT
        test_json = TEST_ANN_FILE_ALT

        # Verificar que existan
        if not all([train_json.exists(), val_json.exists()]):
            print("‚ùå Faltan archivos de datos groundtruth")
            return None, None, None

    else:
        # Estructura legacy - buscar en datasets encontrados
        if not datasets:
            print("‚ùå No hay datasets disponibles")
            return None, None, None

        # Buscar archivos de datos
        train_files = [d for d in datasets if 'train' in d.name.lower()]
        val_files = [d for d in datasets if 'val' in d.name.lower()]
        test_files = [d for d in datasets if 'test' in d.name.lower()]

        train_json = train_files[0] if train_files else None
        val_json = val_files[0] if val_files else None
        test_json = test_files[0] if test_files else None

        if not all([train_json, val_json]):
            print("‚ùå Faltan archivos de datos. Necesitas al menos train y val JSON files.")
            return None, None, None

    print(f"‚úÖ Archivos seleccionados:")
    print(f"  Train: {train_json}")
    print(f"  Val: {val_json}")
    if test_json and test_json.exists():
        print(f"  Test: {test_json}")

    return train_json, val_json, test_json

# Preparar datos
train_json, val_json, test_json = prepare_yolo_data()

if train_json and val_json:
    print("‚úÖ Datos preparados para conversi√≥n")
else:
    print("‚ùå Error preparando datos")

# Convertir datos si est√°n disponibles (ANTES del entrenamiento)
if train_json and val_json:

    # Determinar directorios de im√°genes seg√∫n el tipo de datos
    if data_type == "standard":
        train_img_dir = TRAIN_IMG_DIR
        val_img_dir = VAL_IMG_DIR
        test_img_dir = TEST_IMG_DIR
    elif data_type == "groundtruth":
        train_img_dir = TRAIN_IMG_DIR_ALT
        val_img_dir = VAL_IMG_DIR_ALT
        test_img_dir = TEST_IMG_DIR_ALT
    else:
        # Estructura legacy
        train_img_dir = train_json.parent / "images" if (train_json.parent / "images").exists() else train_json.parent.parent / "train"
        val_img_dir = val_json.parent.parent / "val"
        test_img_dir = None

    # Convertir datos de entrenamiento
    print("üîÑ Convirtiendo datos de entrenamiento...")
    train_yolo_dir = coco_to_yolo(
        train_json,
        train_img_dir,
        '/content/yolo_data/train/labels',
        yolo_config.classes
    )

    # Convertir datos de validaci√≥n
    print("üîÑ Convirtiendo datos de validaci√≥n...")
    val_yolo_dir = coco_to_yolo(
        val_json,
        val_img_dir,
        '/content/yolo_data/val/labels',
        yolo_config.classes
    )

    # Crear directorios de im√°genes
    os.makedirs('/content/yolo_data/train/images', exist_ok=True)
    os.makedirs('/content/yolo_data/val/images', exist_ok=True)

    # Copiar im√°genes
    print("üìÅ Copiando im√°genes...")
    for img_file in tqdm(os.listdir(train_img_dir)):
        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
            src = os.path.join(train_img_dir, img_file)
            dst = os.path.join('/content/yolo_data/train/images', img_file)
            if os.path.exists(src):
                shutil.copy2(src, dst)

    for img_file in tqdm(os.listdir(val_img_dir)):
        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
            src = os.path.join(val_img_dir, img_file)
            dst = os.path.join('/content/yolo_data/val/images', img_file)
            if os.path.exists(src):
                shutil.copy2(src, dst)

    # Copiar im√°genes de test si est√°n disponibles
    if test_img_dir and test_img_dir.exists():
        print("üìÅ Copiando im√°genes de test...")
        os.makedirs('/content/yolo_data/test/images', exist_ok=True)
        for img_file in tqdm(os.listdir(test_img_dir)):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                src = os.path.join(test_img_dir, img_file)
                dst = os.path.join('/content/yolo_data/test/images', img_file)
                if os.path.exists(src):
                    shutil.copy2(src, dst)

    # Crear archivo de configuraci√≥n YOLO
    test_line = "test: test/images\n" if test_img_dir and test_img_dir.exists() else ""
    yolo_config_content = f"""# Dataset configuration for YOLOv8
path: /content/yolo_data
train: train/images
val: val/images
{test_line}
# Classes
nc: {len(yolo_config.classes)}
names: {yolo_config.classes}
"""

    with open('/content/yolo_data/dataset.yaml', 'w') as f:
        f.write(yolo_config_content)

    print("‚úÖ Conversi√≥n completada")
    print(f"üìä Im√°genes de entrenamiento: {len(os.listdir('/content/yolo_data/train/images'))}")
    print(f"üìä Im√°genes de validaci√≥n: {len(os.listdir('/content/yolo_data/val/images'))}")
    if test_img_dir and test_img_dir.exists():
        print(f"üìä Im√°genes de test: {len(os.listdir('/content/yolo_data/test/images'))}")

else:
    print("‚ùå No se puede convertir sin datos v√°lidos")

"""## üöÄ Entrenamiento Optimizado con Backup Autom√°tico

"""

# Entrenar modelo YOLOv8 V1 con backup autom√°tico EN TIEMPO REAL
if train_json and val_json:

    print("üöÄ Iniciando entrenamiento YOLOv8 V1 (Optimizado con Backup en Tiempo Real)...")
    print("üî• Caracter√≠sticas V1:")
    print(f"  - Batch size optimizado: {yolo_config.batch_size}")
    print(f"  - Workers optimizados: {yolo_config.workers}")
    print(f"  - Guardado cada {yolo_config.save_period} √©pocas")
    print(f"  - Backup en Drive cada {yolo_config.drive_backup_period} √©pocas (TIEMPO REAL)")
    print(f"  - Recuperaci√≥n autom√°tica: {yolo_config.resume_training}")
    print("üî• NUEVO: Backup autom√°tico en tiempo real durante el entrenamiento")

    # Inicializar modelo
    model = YOLO(yolo_config.model)

    # Crear callbacks para backup y monitoreo en tiempo real
    backup_callback = RealtimeBackupCallback(backup_period=yolo_config.drive_backup_period)
    monitor_callback = TrainingMonitorCallback(monitor_period=5)  # Monitorear cada 5 √©pocas

    print(f"‚úÖ Callback de backup en tiempo real creado (cada {yolo_config.drive_backup_period} √©pocas)")
    print(f"‚úÖ Callback de monitoreo en tiempo real creado (cada 5 √©pocas)")

    # Configurar par√°metros de entrenamiento - OPTIMIZADOS V1
    train_args = {
        'data': '/content/yolo_data/dataset.yaml',
        'epochs': yolo_config.epochs,
        'imgsz': yolo_config.image_size,
        'batch': yolo_config.batch_size,
        'device': yolo_config.device,
        'workers': yolo_config.workers,
        'project': yolo_config.project,
        'name': yolo_config.name,
        'patience': yolo_config.patience,
        'lr0': yolo_config.learning_rate,
        'amp': yolo_config.fp16,
        'save': True,
        'save_period': yolo_config.save_period,  # Consistente: 5 √©pocas
        'val': True,
        'plots': True,
        'verbose': True,
    }

    # Verificar si hay checkpoint para reanudar
    resume_path = None
    if yolo_config.resume_training:
        # Buscar en Colab primero
        weights_dir = Path(f"{yolo_config.project}/{yolo_config.name}/weights")
        if weights_dir.exists():
            checkpoints = list(weights_dir.glob("*.pt"))
            if checkpoints:
                resume_path = str(max(checkpoints, key=lambda x: x.stat().st_mtime))
                print(f"üîÑ Reanudando desde checkpoint local: {resume_path}")
        else:
            # Buscar en Drive
            resume_path = resume_training_from_drive()
            if resume_path:
                print(f"üîÑ Reanudando desde checkpoint en Drive: {resume_path}")

    if resume_path:
        train_args['resume'] = resume_path

    print("üìã Par√°metros de entrenamiento:")
    for key, value in train_args.items():
        print(f"  {key}: {value}")

    # NO usar el thread de backup legacy - usar callback en tiempo real
    print("üîÑ Usando sistema de backup en tiempo real (NO thread legacy)")

    # Iniciar entrenamiento con callbacks de backup y monitoreo
    print("üöÄ Iniciando entrenamiento con backup y monitoreo en tiempo real...")

    # Registrar los callbacks personalizados
    model.add_callback('on_train_epoch_end', backup_callback.on_train_epoch_end)
    model.add_callback('on_val_end', backup_callback.on_val_end)

    # Registrar callback de monitoreo
    model.add_callback('on_train_epoch_end', monitor_callback.on_train_epoch_end)
    model.add_callback('on_val_end', monitor_callback.on_val_end)

    # Iniciar entrenamiento
    results = model.train(**train_args)

    print("‚úÖ Entrenamiento completado!")
    print(f"üìÅ Resultados guardados en: {yolo_config.project}/{yolo_config.name}")

    # Hacer backup final
    print("üîÑ Realizando backup final...")
    backup_to_drive(epoch="final")

"""## üìä M√©tricas de Clasificaci√≥n Detalladas

"""

# ============================================================
# FUNCIONES PARA M√âTRICAS DE CLASIFICACI√ìN DETALLADAS
# ============================================================

import numpy as np
from sklearn.metrics import precision_recall_fscore_support, classification_report, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

def calculate_detailed_metrics(model, dataset_path, conf_threshold=0.5, iou_threshold=0.5):
    """Calcular m√©tricas detalladas de clasificaci√≥n para cada clase"""

    try:
        print("üîÑ Calculando m√©tricas detalladas de clasificaci√≥n...")

        # Realizar validaci√≥n con el modelo
        results = model.val(data=dataset_path, conf=conf_threshold, iou=iou_threshold, verbose=False)

        # Obtener m√©tricas del modelo
        metrics = results.results_dict

        # Crear diccionario de m√©tricas por clase
        class_metrics = {}

        # Obtener nombres de las clases
        class_names = yolo_config.classes

        # Calcular m√©tricas para cada clase
        for i, class_name in enumerate(class_names):
            # Obtener m√©tricas espec√≠ficas de la clase (si est√°n disponibles)
            precision_key = f'metrics/precision(B)_{i}'
            recall_key = f'metrics/recall(B)_{i}'
            f1_key = f'metrics/f1(B)_{i}'

            class_metrics[class_name] = {
                'precision': metrics.get(precision_key, 0.0),
                'recall': metrics.get(recall_key, 0.0),
                'f1': metrics.get(f1_key, 0.0),
                'class_id': i
            }

        # M√©tricas generales
        general_metrics = {
            'mAP50': metrics.get('metrics/mAP50(B)', 0.0),
            'mAP50-95': metrics.get('metrics/mAP50-95(B)', 0.0),
            'precision': metrics.get('metrics/precision(B)', 0.0),
            'recall': metrics.get('metrics/recall(B)', 0.0),
            'f1': metrics.get('metrics/f1(B)', 0.0)
        }

        return class_metrics, general_metrics, results

    except Exception as e:
        print(f"‚ùå Error calculando m√©tricas detalladas: {e}")
        return {}, {}, None

def create_classification_report(class_metrics, general_metrics, save_path=None):
    """Crear reporte detallado de clasificaci√≥n"""

    print("\n" + "="*80)
    print("üìä REPORTE DETALLADO DE M√âTRICAS DE CLASIFICACI√ìN")
    print("="*80)

    # M√©tricas generales
    print("\nüéØ M√âTRICAS GENERALES:")
    print(f"  mAP@0.5:     {general_metrics.get('mAP50', 0.0):.4f}")
    print(f"  mAP@0.5:0.95: {general_metrics.get('mAP50-95', 0.0):.4f}")
    print(f"  Precision:   {general_metrics.get('precision', 0.0):.4f}")
    print(f"  Recall:      {general_metrics.get('recall', 0.0):.4f}")
    print(f"  F1-Score:    {general_metrics.get('f1', 0.0):.4f}")

    # M√©tricas por clase
    print("\nüìã M√âTRICAS POR CLASE:")
    print("-" * 60)
    print(f"{'Clase':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}")
    print("-" * 60)

    for class_name, metrics in class_metrics.items():
        print(f"{class_name:<15} {metrics['precision']:<10.4f} {metrics['recall']:<10.4f} {metrics['f1']:<10.4f}")

    # Guardar reporte si se especifica ruta
    if save_path:
        with open(save_path, 'w') as f:
            f.write("REPORTE DETALLADO DE M√âTRICAS DE CLASIFICACI√ìN\n")
            f.write("="*50 + "\n\n")

            f.write("M√âTRICAS GENERALES:\n")
            f.write(f"mAP@0.5:     {general_metrics.get('mAP50', 0.0):.4f}\n")
            f.write(f"mAP@0.5:0.95: {general_metrics.get('mAP50-95', 0.0):.4f}\n")
            f.write(f"Precision:   {general_metrics.get('precision', 0.0):.4f}\n")
            f.write(f"Recall:      {general_metrics.get('recall', 0.0):.4f}\n")
            f.write(f"F1-Score:    {general_metrics.get('f1', 0.0):.4f}\n\n")

            f.write("M√âTRICAS POR CLASE:\n")
            f.write("-" * 60 + "\n")
            f.write(f"{'Clase':<15} {'Precision':<10} {'Recall':<10} {'F1-Score':<10}\n")
            f.write("-" * 60 + "\n")

            for class_name, metrics in class_metrics.items():
                f.write(f"{class_name:<15} {metrics['precision']:<10.4f} {metrics['recall']:<10.4f} {metrics['f1']:<10.4f}\n")

        print(f"\n‚úÖ Reporte guardado en: {save_path}")

    return class_metrics, general_metrics

def plot_class_metrics(class_metrics, save_path=None):
    """Crear gr√°ficos de m√©tricas por clase"""

    try:
        # Preparar datos para gr√°ficos
        classes = list(class_metrics.keys())
        precisions = [class_metrics[cls]['precision'] for cls in classes]
        recalls = [class_metrics[cls]['recall'] for cls in classes]
        f1_scores = [class_metrics[cls]['f1'] for cls in classes]

        # Crear figura con subplots
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('M√©tricas de Clasificaci√≥n por Clase', fontsize=16, fontweight='bold')

        # Gr√°fico de barras - Precision
        axes[0, 0].bar(classes, precisions, color='skyblue', alpha=0.7)
        axes[0, 0].set_title('Precision por Clase')
        axes[0, 0].set_ylabel('Precision')
        axes[0, 0].tick_params(axis='x', rotation=45)
        axes[0, 0].grid(True, alpha=0.3)

        # Gr√°fico de barras - Recall
        axes[0, 1].bar(classes, recalls, color='lightgreen', alpha=0.7)
        axes[0, 1].set_title('Recall por Clase')
        axes[0, 1].set_ylabel('Recall')
        axes[0, 1].tick_params(axis='x', rotation=45)
        axes[0, 1].grid(True, alpha=0.3)

        # Gr√°fico de barras - F1-Score
        axes[1, 0].bar(classes, f1_scores, color='lightcoral', alpha=0.7)
        axes[1, 0].set_title('F1-Score por Clase')
        axes[1, 0].set_ylabel('F1-Score')
        axes[1, 0].tick_params(axis='x', rotation=45)
        axes[1, 0].grid(True, alpha=0.3)

        # Gr√°fico combinado
        x = np.arange(len(classes))
        width = 0.25

        axes[1, 1].bar(x - width, precisions, width, label='Precision', alpha=0.7)
        axes[1, 1].bar(x, recalls, width, label='Recall', alpha=0.7)
        axes[1, 1].bar(x + width, f1_scores, width, label='F1-Score', alpha=0.7)

        axes[1, 1].set_title('Comparaci√≥n de M√©tricas por Clase')
        axes[1, 1].set_ylabel('Score')
        axes[1, 1].set_xticks(x)
        axes[1, 1].set_xticklabels(classes, rotation=45)
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)

        plt.tight_layout()

        # Guardar gr√°fico si se especifica ruta
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"‚úÖ Gr√°fico de m√©tricas guardado en: {save_path}")

        plt.show()

    except Exception as e:
        print(f"‚ùå Error creando gr√°ficos de m√©tricas: {e}")

def create_metrics_summary_table(class_metrics, general_metrics):
    """Crear tabla resumen de m√©tricas"""

    print("\n" + "="*80)
    print("üìä TABLA RESUMEN DE M√âTRICAS")
    print("="*80)

    # Crear DataFrame para mejor visualizaci√≥n
    import pandas as pd

    # Datos por clase
    class_data = []
    for class_name, metrics in class_metrics.items():
        class_data.append({
            'Clase': class_name,
            'Precision': f"{metrics['precision']:.4f}",
            'Recall': f"{metrics['recall']:.4f}",
            'F1-Score': f"{metrics['f1']:.4f}"
        })

    # Agregar m√©tricas generales
    class_data.append({
        'Clase': 'PROMEDIO',
        'Precision': f"{general_metrics.get('precision', 0.0):.4f}",
        'Recall': f"{general_metrics.get('recall', 0.0):.4f}",
        'F1-Score': f"{general_metrics.get('f1', 0.0):.4f}"
    })

    df = pd.DataFrame(class_data)
    print(df.to_string(index=False))

    return df

def save_metrics_to_csv(class_metrics, general_metrics, save_path):
    """Guardar m√©tricas en archivo CSV"""

    try:
        import pandas as pd

        # Preparar datos
        data = []
        for class_name, metrics in class_metrics.items():
            data.append({
                'Clase': class_name,
                'Precision': metrics['precision'],
                'Recall': metrics['recall'],
                'F1-Score': metrics['f1'],
                'Tipo': 'Clase_Individual'
            })

        # Agregar m√©tricas generales
        data.append({
            'Clase': 'GENERAL',
            'Precision': general_metrics.get('precision', 0.0),
            'Recall': general_metrics.get('recall', 0.0),
            'F1-Score': general_metrics.get('f1', 0.0),
            'Tipo': 'Promedio_General'
        })

        # Crear DataFrame y guardar
        df = pd.DataFrame(data)
        df.to_csv(save_path, index=False)
        print(f"‚úÖ M√©tricas guardadas en CSV: {save_path}")

        return df

    except Exception as e:
        print(f"‚ùå Error guardando m√©tricas en CSV: {e}")
        return None

def calculate_metrics_with_thresholds(model, dataset_path, thresholds=[0.3, 0.5, 0.7, 0.9]):
    """Calcular m√©tricas con diferentes umbrales de confianza"""

    print("\n" + "="*80)
    print("üìä AN√ÅLISIS DE M√âTRICAS CON DIFERENTES UMBRALES DE CONFIANZA")
    print("="*80)

    results_summary = []

    for threshold in thresholds:
        print(f"\nüîÑ Calculando m√©tricas con threshold = {threshold}")

        class_metrics, general_metrics, _ = calculate_detailed_metrics(
            model, dataset_path, conf_threshold=threshold, iou_threshold=0.5
        )

        if class_metrics and general_metrics:
            results_summary.append({
                'threshold': threshold,
                'mAP50': general_metrics.get('mAP50', 0.0),
                'precision': general_metrics.get('precision', 0.0),
                'recall': general_metrics.get('recall', 0.0),
                'f1': general_metrics.get('f1', 0.0)
            })

            print(f"  mAP@0.5: {general_metrics.get('mAP50', 0.0):.4f}")
            print(f"  Precision: {general_metrics.get('precision', 0.0):.4f}")
            print(f"  Recall: {general_metrics.get('recall', 0.0):.4f}")
            print(f"  F1-Score: {general_metrics.get('f1', 0.0):.4f}")

    # Crear gr√°fico de m√©tricas vs threshold
    if results_summary:
        import pandas as pd
        df_thresholds = pd.DataFrame(results_summary)

        plt.figure(figsize=(12, 8))

        plt.subplot(2, 2, 1)
        plt.plot(df_thresholds['threshold'], df_thresholds['mAP50'], 'o-', linewidth=2, markersize=8)
        plt.title('mAP@0.5 vs Threshold')
        plt.xlabel('Confidence Threshold')
        plt.ylabel('mAP@0.5')
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 2)
        plt.plot(df_thresholds['threshold'], df_thresholds['precision'], 'o-', linewidth=2, markersize=8, color='green')
        plt.title('Precision vs Threshold')
        plt.xlabel('Confidence Threshold')
        plt.ylabel('Precision')
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 3)
        plt.plot(df_thresholds['threshold'], df_thresholds['recall'], 'o-', linewidth=2, markersize=8, color='red')
        plt.title('Recall vs Threshold')
        plt.xlabel('Confidence Threshold')
        plt.ylabel('Recall')
        plt.grid(True, alpha=0.3)

        plt.subplot(2, 2, 4)
        plt.plot(df_thresholds['threshold'], df_thresholds['f1'], 'o-', linewidth=2, markersize=8, color='purple')
        plt.title('F1-Score vs Threshold')
        plt.xlabel('Confidence Threshold')
        plt.ylabel('F1-Score')
        plt.grid(True, alpha=0.3)

        plt.tight_layout()

        # Guardar gr√°fico
        threshold_plot_path = f"{yolo_config.project}/{yolo_config.name}/metrics_vs_threshold.png"
        plt.savefig(threshold_plot_path, dpi=300, bbox_inches='tight')
        print(f"\n‚úÖ Gr√°fico de m√©tricas vs threshold guardado en: {threshold_plot_path}")
        plt.show()

        # Guardar datos en CSV
        threshold_csv_path = f"{yolo_config.project}/{yolo_config.name}/metrics_vs_threshold.csv"
        df_thresholds.to_csv(threshold_csv_path, index=False)
        print(f"‚úÖ Datos de m√©tricas vs threshold guardados en: {threshold_csv_path}")

        return df_thresholds

    return None

def create_comprehensive_metrics_report():
    """Crear reporte comprensivo de todas las m√©tricas"""

    print("\n" + "="*80)
    print("üìã CREANDO REPORTE COMPRENSIVO DE M√âTRICAS")
    print("="*80)

    try:
        # Cargar modelo
        best_model_path = f"{yolo_config.project}/{yolo_config.name}/weights/best.pt"
        if not os.path.exists(best_model_path):
            print("‚ùå No se encontr√≥ el modelo entrenado")
            return

        model = YOLO(best_model_path)

        # 1. M√©tricas con threshold por defecto
        print("\n1Ô∏è‚É£ Calculando m√©tricas con threshold por defecto (0.5)...")
        class_metrics, general_metrics, _ = calculate_detailed_metrics(
            model, '/content/yolo_data/dataset.yaml', conf_threshold=0.5
        )

        if class_metrics and general_metrics:
            # Crear reporte detallado
            report_path = f"{yolo_config.project}/{yolo_config.name}/comprehensive_metrics_report.txt"
            create_classification_report(class_metrics, general_metrics, save_path=report_path)

            # Crear gr√°ficos
            plot_path = f"{yolo_config.project}/{yolo_config.name}/comprehensive_class_metrics.png"
            plot_class_metrics(class_metrics, save_path=plot_path)

            # 2. An√°lisis con diferentes thresholds
            print("\n2Ô∏è‚É£ Analizando m√©tricas con diferentes thresholds...")
            df_thresholds = calculate_metrics_with_thresholds(model, '/content/yolo_data/dataset.yaml')

            # 3. An√°lisis de rendimiento por clase
            print("\n3Ô∏è‚É£ Analizando rendimiento por clase...")
            analyze_class_performance(class_metrics, general_metrics)

            print(f"\n‚úÖ Reporte comprensivo completado:")
            print(f"  üìÑ Reporte detallado: {report_path}")
            print(f"  üìä Gr√°ficos por clase: {plot_path}")
            if df_thresholds is not None:
                print(f"  üìà An√°lisis de thresholds: {yolo_config.project}/{yolo_config.name}/metrics_vs_threshold.png")

        else:
            print("‚ùå No se pudieron calcular las m√©tricas")

    except Exception as e:
        print(f"‚ùå Error creando reporte comprensivo: {e}")

print("‚úÖ Funciones de m√©tricas de clasificaci√≥n cargadas")

"""## üìä An√°lisis Detallado de M√©tricas de Clasificaci√≥n"""

# ============================================================
# AN√ÅLISIS DETALLADO DE M√âTRICAS (EJECUTAR DESPU√âS DEL ENTRENAMIENTO)
# ============================================================

def analyze_trained_model_metrics():
    """Analizar m√©tricas del modelo entrenado"""

    try:
        print("üîÑ Analizando m√©tricas del modelo entrenado...")

        # Cargar el mejor modelo entrenado
        best_model_path = f"{yolo_config.project}/{yolo_config.name}/weights/best.pt"
        if not os.path.exists(best_model_path):
            print("‚ùå No se encontr√≥ el modelo entrenado")
            return None, None, None

        model = YOLO(best_model_path)

        # Calcular m√©tricas detalladas
        class_metrics, general_metrics, validation_results = calculate_detailed_metrics(
            model,
            '/content/yolo_data/dataset.yaml',
            conf_threshold=0.5,
            iou_threshold=0.5
        )

        if class_metrics and general_metrics:
            print("‚úÖ M√©tricas calculadas exitosamente")

            # Crear reporte detallado
            report_path = f"{yolo_config.project}/{yolo_config.name}/final_classification_report.txt"
            create_classification_report(class_metrics, general_metrics, save_path=report_path)

            # Crear tabla resumen
            metrics_df = create_metrics_summary_table(class_metrics, general_metrics)

            # Crear gr√°ficos de m√©tricas
            plot_path = f"{yolo_config.project}/{yolo_config.name}/final_class_metrics_plot.png"
            plot_class_metrics(class_metrics, save_path=plot_path)

            # Guardar m√©tricas en CSV
            csv_path = f"{yolo_config.project}/{yolo_config.name}/final_detailed_metrics.csv"
            save_metrics_to_csv(class_metrics, general_metrics, csv_path)

            # An√°lisis adicional
            analyze_class_performance(class_metrics, general_metrics)

            return class_metrics, general_metrics, model

        else:
            print("‚ùå No se pudieron calcular las m√©tricas")
            return None, None, None

    except Exception as e:
        print(f"‚ùå Error analizando m√©tricas: {e}")
        return None, None, None

def analyze_class_performance(class_metrics, general_metrics):
    """Analizar rendimiento por clase"""

    print("\n" + "="*80)
    print("üîç AN√ÅLISIS DE RENDIMIENTO POR CLASE")
    print("="*80)

    # Encontrar la mejor y peor clase
    best_class = max(class_metrics.items(), key=lambda x: x[1]['f1'])
    worst_class = min(class_metrics.items(), key=lambda x: x[1]['f1'])

    print(f"\nüèÜ MEJOR CLASE: {best_class[0]}")
    print(f"  F1-Score: {best_class[1]['f1']:.4f}")
    print(f"  Precision: {best_class[1]['precision']:.4f}")
    print(f"  Recall: {best_class[1]['recall']:.4f}")

    print(f"\n‚ö†Ô∏è PEOR CLASE: {worst_class[0]}")
    print(f"  F1-Score: {worst_class[1]['f1']:.4f}")
    print(f"  Precision: {worst_class[1]['precision']:.4f}")
    print(f"  Recall: {worst_class[1]['recall']:.4f}")

    # An√°lisis de balance
    f1_scores = [metrics['f1'] for metrics in class_metrics.values()]
    f1_std = np.std(f1_scores)
    f1_mean = np.mean(f1_scores)

    print(f"\nüìä AN√ÅLISIS DE BALANCE:")
    print(f"  F1-Score promedio: {f1_mean:.4f}")
    print(f"  Desviaci√≥n est√°ndar: {f1_std:.4f}")
    print(f"  Coeficiente de variaci√≥n: {(f1_std/f1_mean)*100:.2f}%")

    if f1_std < 0.1:
        print("  ‚úÖ Modelo balanceado (baja variaci√≥n entre clases)")
    elif f1_std < 0.2:
        print("  ‚ö†Ô∏è Modelo moderadamente balanceado")
    else:
        print("  ‚ùå Modelo desbalanceado (alta variaci√≥n entre clases)")

    # Recomendaciones
    print(f"\nüí° RECOMENDACIONES:")
    if worst_class[1]['recall'] < 0.5:
        print(f"  - Considerar aumentar datos de entrenamiento para '{worst_class[0]}'")
    if worst_class[1]['precision'] < 0.5:
        print(f"  - Revisar anotaciones de '{worst_class[0]}' para mejorar precisi√≥n")
    if f1_std > 0.2:
        print("  - Considerar t√©cnicas de balanceo de clases (focal loss, class weights)")

# Ejecutar an√°lisis si el modelo est√° entrenado
if train_json and val_json:
    print("üîÑ Ejecutando an√°lisis de m√©tricas...")
    class_metrics, general_metrics, trained_model = analyze_trained_model_metrics()
else:
    print("‚ö†Ô∏è Ejecuta el entrenamiento primero para analizar m√©tricas")

"""## üìä Visualizaci√≥n de Resultados
"""

# Cargar el mejor modelo entrenado (si existe)
best_model_path = f"{yolo_config.project}/{yolo_config.name}/weights/best.pt"
if os.path.exists(best_model_path):
    model = YOLO(best_model_path)
    print("‚úÖ Modelo entrenado cargado para visualizaci√≥n")
else:
    print("‚ö†Ô∏è No hay modelo entrenado disponible para visualizaci√≥n")

# Visualizar curvas de entrenamiento
results_dir = f"{yolo_config.project}/{yolo_config.name}"
if os.path.exists(f"{results_dir}/results.png"):
    display(IPImage(f"{results_dir}/results.png"))

# Mostrar m√©tricas finales
if os.path.exists(f"{results_dir}/results.csv"):
    results_df = pd.read_csv(f"{results_dir}/results.csv")
    print("üìä M√©tricas de entrenamiento:")
    print(results_df.tail(10))

# Mostrar matriz de confusi√≥n
if os.path.exists(f"{results_dir}/confusion_matrix.png"):
    print("\nüìä Matriz de Confusi√≥n:")
    display(IPImage(f"{results_dir}/confusion_matrix.png"))

"""## üîç Inferencia y Pruebas"""

# Realizar inferencia en im√°genes de prueba
if test_json and test_json.exists():
    # Determinar directorio de im√°genes de test seg√∫n el tipo de datos
    if data_type == "standard":
        test_images_dir = TEST_IMG_DIR
    elif data_type == "groundtruth":
        test_images_dir = TEST_IMG_DIR_ALT
    else:
        # Estructura legacy
        test_images_dir = test_json.parent.parent / "test"

    if test_images_dir and test_images_dir.exists():
        test_images = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

        # Seleccionar algunas im√°genes para prueba
        sample_images = test_images[:5]  # Primeras 5 im√°genes

        print(f"üîç Realizando inferencia en {len(sample_images)} im√°genes de prueba...")

        for img_name in sample_images:
            img_path = os.path.join(test_images_dir, img_name)

            # Realizar predicci√≥n
            results = model(img_path, conf=0.5)

            # Mostrar resultado
            for r in results:
                # Guardar imagen con predicciones
                output_path = f"/content/test_results_{img_name}"
                r.save(output_path)

                # Mostrar imagen
                display(IPImage(output_path))

                # Mostrar estad√≠sticas
                print(f"üìä {img_name}: {len(r.boxes)} objetos detectados")
                if len(r.boxes) > 0:
                    for box in r.boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        class_name = yolo_config.classes[class_id]
                        print(f"  - {class_name}: {confidence:.2f}")
                print()
    else:
        print("‚ö†Ô∏è  No se encontr√≥ directorio de im√°genes de test")
else:
    print("‚ö†Ô∏è  No hay datos de test disponibles para inferencia")

"""## üíæ Guardar y Exportar Modelo"""

# Exportar modelo a ONNX para deployment
print("üîÑ Exportando modelo a ONNX...")
onnx_path = model.export(format='onnx', imgsz=yolo_config.image_size)
print(f"‚úÖ Modelo exportado a: {onnx_path}")

# Copiar resultados a Google Drive
drive_results_dir = f"/content/drive/MyDrive/aerial-wildlife-count/results/yolov8_{yolo_config.name}"
os.makedirs(drive_results_dir, exist_ok=True)

# Copiar archivos importantes
files_to_copy = [
    f"{results_dir}/weights/best.pt",
    f"{results_dir}/weights/last.pt",
    f"{results_dir}/results.png",
    f"{results_dir}/confusion_matrix.png",
    f"{results_dir}/results.csv",
    onnx_path
]

for file_path in files_to_copy:
    if os.path.exists(file_path):
        filename = os.path.basename(file_path)
        shutil.copy2(file_path, os.path.join(drive_results_dir, filename))
        print(f"üìÅ Copiado: {filename}")

print(f"‚úÖ Resultados guardados en Google Drive: {drive_results_dir}")

# Mostrar resumen final
print("\nüéâ RESUMEN DEL ENTRENAMIENTO")
print("=" * 50)
print(f"Modelo: {yolo_config.model}")
print(f"√âpocas: {yolo_config.epochs}")
print(f"Tama√±o de imagen: {yolo_config.image_size}")
print(f"Batch size: {yolo_config.batch_size}")
print(f"Clases: {yolo_config.classes}")
print(f"Mejor modelo: {best_model_path}")
print(f"Modelo ONNX: {onnx_path}")
print(f"Resultados en Drive: {drive_results_dir}")