# -*- coding: utf-8 -*-
"""1. Training_HERDNET_From_Scratch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/19_iLXWCzQ7_LzvPWQ8aUPf_YgseZUUL_

<div align="center">

# **Modelo de Detecci√≥n y Conteo de Mam√≠feros Africanos a partir de Im√°genes A√©reas**  

### *Proyecto de Grado - Maestr√≠a en Inteligencia Artificial, Universidad de los Andes*  


**Autor:** Grupo 2  
**Asesor:** Isai Daniel Chac√≥n Silva *(Microsoft AI for Good)*  
**Instituci√≥n:** Proyecto Guacamaya *(CINFONIA)*  
**A√±o:** 2025  


</div>

## Descripci√≥n general

Este cuaderno documenta el proceso completo de **entrenamiento y evaluaci√≥n del modelo HerdNet**, dise√±ado para la **detecci√≥n y conteo de mam√≠feros africanos** en im√°genes a√©reas, utilizando el *dataset* **ULi√®ge**.  

El objetivo es identificar y contabilizar seis especies con precisi√≥n, incluso en condiciones de **alta densidad, oclusi√≥n y variabilidad de escala**:  

| Especie | Nombre com√∫n | Nombre cient√≠fico / Ingl√©s |
|:--|:--|:--|
| üêÉ | **B√∫falo**  | *Buffalo* |
| üêò | **Elefante** | *Elephant* |
| ü¶å | **Kob** | *Kob* |
| ü¶¨ | **Topi (Alcelaphinae)** | *Topi / Hartebeest* |
| üêó | **Fac√≥quero** | *Warthog* |
| ü¶ì | **Waterbuck** | *Waterbuck* |


###  Referencia t√©cnica

Los experimentos y scripts se fundamentan en el cuaderno de referencia del repositorio oficial de **HerdNet**, disponible en:  
[https://colab.research.google.com/github/Alexandre-Delplanque/HerdNet/blob/main/notebooks/demo-training-testing-herdnet.ipynb](https://colab.research.google.com/github/Alexandre-Delplanque/HerdNet/blob/main/notebooks/demo-training-testing-herdnet.ipynb)

</div>

La siguiente estructura organiza todos los componentes necesarios para entrenar y evaluar el modelo HerdNet. Incluye los archivos COCO originales, sus versiones convertidas a CSV, las im√°genes por conjunto, los modelos preentrenados y los resultados de entrenamiento.

```
/content/drive/MyDrive/HerdNet/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ coco/                        # Archivos de anotaciones originales en formato COCO
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_annotations.json
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val_annotations.json
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_annotations.json
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ csv/                         # Archivos convertidos a CSV (formato usado por CSVDataset; se generan en la fase de Datasets)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_annotations.csv
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val_annotations.csv
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test_annotations.csv
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ images/                      # Carpeta ra√≠z con las im√°genes divididas por conjunto
‚îÇ       ‚îú‚îÄ‚îÄ train/
‚îÇ       ‚îú‚îÄ‚îÄ val/
‚îÇ       ‚îî‚îÄ‚îÄ test/
‚îÇ
‚îú‚îÄ‚îÄ model/                           # Pesos preentrenados y checkpoints del modelo
‚îÇ   ‚îî‚îÄ‚îÄ 20220413_HerdNet_General_dataset_2022.pth
‚îÇ
‚îú‚îÄ‚îÄ outputs/                         # Resultados de entrenamiento, m√©tricas y logs generados por este script

```

# Hiperpar√°metros, configuraci√≥n general y rutas

Define los par√°metros globales del proyecto, las rutas de trabajo en Google Drive y los valores base que controlan el entrenamiento, el tama√±o de los parches, la tasa de aprendizaje y otros elementos del modelo. De igual modo, rutas a im√°genes y anotaciones.

### Rutas de anotaciones e im√°genes

Especifica las ubicaciones de los archivos de anotaciones (COCO JSON y CSV) y las carpetas donde se encuentran las im√°genes de entrenamiento, validaci√≥n y prueba.
"""

from pathlib import Path

# ============================================================
# CONFIGURACI√ìN DE RUTAS PRINCIPALES
# ============================================================

# Definir la ruta base principal (ajustar seg√∫n el entorno: Drive o local)
BASE_DIR = Path("/content/drive/MyDrive/HerdNet")

# ============================================================
# RUTAS DE IM√ÅGENES Y ANOTACIONES (COCO JSON)
# ============================================================

# Rutas de los archivos de anotaciones en formato COCO
TRAIN_ANN_FILE = BASE_DIR / "data" / "coco" / "train" / "train_annotations.json"
VAL_ANN_FILE = BASE_DIR / "data" / "coco" / "val" / "val_annotations.json"
TEST_ANN_FILE = BASE_DIR / "data" / "coco" / "test" / "test_annotations.json"

# Rutas de las carpetas de im√°genes correspondientes a cada conjunto
TRAIN_IMG_DIR = BASE_DIR / "data" / "images" / "train"
VAL_IMG_DIR = BASE_DIR / "data" / "images" / "val"
TEST_IMG_DIR = BASE_DIR / "data" / "images" / "test"

# ============================================================
# RUTAS DE ANOTACIONES CONVERTIDAS A CSV
# ============================================================

# Definir las rutas de salida en formato CSV
TRAIN_CSV = BASE_DIR / "data" / "csv" / "train" / "train_annotations.csv"
VAL_CSV = BASE_DIR / "data" / "csv" / "val" / "val_annotations.csv"
TEST_CSV = BASE_DIR / "data" / "csv" / "test" / "test_annotations.csv"

# ============================================================
# VALIDACI√ìN DE CONFIGURACI√ìN (opcional)
# ============================================================

print("[INFO] Archivos de anotaciones e im√°genes: \n")
print("\n Train set:")
print(f"Archivo JSON de entrenamiento: {TRAIN_ANN_FILE}")
print(f"Carpeta de im√°genes de entrenamiento: {TRAIN_IMG_DIR}")
print(f"Archivo CSV de entrenamiento: {TRAIN_CSV}")
print("\n Val set:")
print(f"Archivo JSON de validaci√≥n: {VAL_ANN_FILE}")
print(f"Carpeta de im√°genes de validaci√≥n: {VAL_IMG_DIR}")
print(f"Archivo CSV de validaci√≥n: {VAL_CSV}")
print("\n Test set:")
print(f"Archivo JSON de prueba: {TEST_ANN_FILE}")
print(f"Carpeta de im√°genes de prueba: {TEST_IMG_DIR}")
print(f"Archivo CSV de prueba: {TEST_CSV}")

"""### Configuraci√≥n del modelo

Define los par√°metros fundamentales de la arquitectura del modelo HerdNet, incluyendo el n√∫mero de clases, el factor de reducci√≥n espacial y las dimensiones de entrada.

**Hiperpar√°metros principales a experimentar:**

* Tasa de aprendizaje (*learning rate*)
* Peso de decaimiento (*weight decay*)
* Superposici√≥n (*overlap*)
* Factor de reducci√≥n (*down ratio*)
"""

# ============================================================
# CONFIGURACI√ìN DE LOS DATA LOADERS DE HERDNET
# ============================================================

# Tama√±o del lote (batch size). Ajustar seg√∫n la memoria de la GPU disponible.
TAMANO_LOTE = 32  # Recomendado para VRAM entre 10 y 20 GB

# Tama√±o del parche de entrada. Debe coincidir con el definido en el modelo HerdNet.
TAMANO_PARCHE = 512

# N√∫mero total de clases (incluye fondo). El modelo HerdNet requiere +1 por convenci√≥n.
NUMERO_CLASES = 6 + 1

# Factor de reducci√≥n espacial utilizado durante la generaci√≥n de mapas de densidad.
FACTOR_REDUCCION = 2

# ============================================================
# CONFIGURACI√ìN DE ENTRENAMIENTO DEL MODELO HERDNET
# ============================================================

# Carpeta donde se guardar√°n los resultados, checkpoints y m√©tricas
RUTA_SALIDA = "/content/drive/MyDrive/HerdNet/model/outputs"

# Overlap entre parches utilizados por el Stitcher
SUPERPOSICION = 160

# Radio de evaluaci√≥n usado por PointsMetrics
RADIO_METRICA = 20

# N√∫mero total de √©pocas de entrenamiento
EPOCHS_TOTALES = 50

# Tasa de aprendizaje inicial (learning rate) - debe ser baja para preservar los pesos preentrenados
TASA_APRENDIZAJE = 1e-5

# Par√°metro de regularizaci√≥n L2 (weight decay) - ayuda a reducir el sobreajuste
PESO_DECAY = 1e-4

# N√∫mero de iteraciones de calentamiento antes de iniciar el entrenamiento completo
ITERACIONES_CALENTAMIENTO = 100

# ============================================================
# CONFIGURACI√ìN DEL MODELO PREENTRENADO
# ============================================================

# Ruta al archivo de pesos preentrenados de HerdNet (Opcional: Se entrenar√° desde DLA)
RUTA_MODELO_HERDNET = "/content/drive/MyDrive/HerdNet/model/20220413_HerdNet_General_dataset_2022.pth"

MODELO_PREENTRENADO_DLA = False

# ============================================================
# VALIDACI√ìN DE CONFIGURACI√ìN (opcional)
# ============================================================

print("[INFO] Configuraci√≥n: \n")
print(f"Tama√±o de lote: {TAMANO_LOTE}")
print(f"Tama√±o de parche: {TAMANO_PARCHE}")
print(f"N√∫mero de clases (incluye fondo): {NUMERO_CLASES}")
print(f"Factor de reducci√≥n: {FACTOR_REDUCCION}")
print(f"Directorio de salida: {RUTA_SALIDA}")
print(f"√âpocas totales: {EPOCHS_TOTALES}")
print(f"Tasa de aprendizaje: {TASA_APRENDIZAJE}")
print(f"Peso de decaimiento (weight decay): {PESO_DECAY}")
print(f"Iteraciones de calentamiento: {ITERACIONES_CALENTAMIENTO}")
print(f"Ruta del modelo preentrenado: {RUTA_MODELO_HERDNET}")
print(f"Entrenar desde DLA: {MODELO_PREENTRENADO_DLA}")

"""# Instalaciones

Incluye las celdas necesarias para montar el entorno de trabajo en Google Colab, instalar dependencias y clonar repositorios requeridos por el modelo.

## Montar Disco Duro desde Google Drive

Conecta el entorno de ejecuci√≥n de Google Colab con Google Drive, permitiendo el acceso directo a los datos, modelos preentrenados (por ejemplo, para fine-tuning) y resultados generados durante el entrenamiento.
"""

# ============================================================
# LIBRER√çAS EST√ÅNDAR
# ============================================================
import os
import logging
from IPython.display import clear_output

# ============================================================
# LIBRER√çAS DE TERCEROS
# ============================================================
from google.colab import drive


class GoogleDriveConnector:
    """
    GoogleDriveConnector
    --------------------
    Clase para montar Google Drive en un entorno de Google Colab.

    Prop√≥sito
    ----------
    Permite establecer una conexi√≥n con Google Drive desde Colab de forma
    controlada, con validaci√≥n de par√°metros, registro de eventos (logging)
    y limpieza visual del entorno tras la conexi√≥n.

    Par√°metros
    ----------
    mount_path : str
        Ruta local donde se montar√° Google Drive (por defecto '/content/drive').

    verbose : bool, opcional
        Si es True, se habilita el registro mediante logging. Si es False,
        no se muestra ninguna salida ni registro (por defecto True).

    M√©todos
    -------
    mount_drive():
        Monta Google Drive y registra el proceso.
    """

    def __init__(self, mount_path: str = "/content/drive", verbose: bool = True):
        """
        Inicializa la clase configurando el logger y validando la ruta de montaje.

        Par√°metros
        ----------
        mount_path : str
            Ruta donde se montar√° Google Drive.

        verbose : bool
            Determina si se habilita el registro de eventos.

        Excepciones
        -----------
        ValueError:
            Si 'mount_path' no es una cadena v√°lida o est√° vac√≠a.
        """
        # Validar tipo y contenido del par√°metro
        if not isinstance(mount_path, str) or not mount_path.strip():
            raise ValueError("El par√°metro 'mount_path' debe ser una cadena no vac√≠a.")

        # Asignar atributos de instancia
        self.mount_path = mount_path
        self.verbose = verbose

        # Configurar logger si est√° habilitado
        self.logger = logging.getLogger("GoogleDriveConnector")
        if self.verbose:
            self.logger.setLevel(logging.INFO)
            if not self.logger.handlers:
                handler = logging.StreamHandler()
                formatter = logging.Formatter(
                    "[%(asctime)s] [%(levelname)s] %(message)s",
                    datefmt="%Y-%m-%d %H:%M:%S",
                )
                handler.setFormatter(formatter)
                self.logger.addHandler(handler)
            self.logger.propagate = False
        else:
            self.logger.disabled = True

    def mount_drive(self) -> None:
        """
        Monta Google Drive en el entorno actual de Google Colab.

        Retorno
        -------
        None

        Excepciones
        -----------
        RuntimeError:
            Si ocurre un error durante el proceso de montaje.
        """
        # Registrar inicio del proceso de conexi√≥n
        if self.verbose:
            self.logger.info("Iniciando conexi√≥n con Google Drive...")

        # ------------------------------------------------------------
        # Nueva verificaci√≥n: evitar conflicto si la ruta ya tiene archivos
        # ------------------------------------------------------------
        if os.path.exists(self.mount_path) and os.listdir(self.mount_path):
            if self.verbose:
                self.logger.warning(
                    f"La ruta '{self.mount_path}' ya contiene archivos. "
                    "Se asume que Google Drive ya est√° montado."
                )
            return

        try:
            # Montar Google Drive
            drive.mount(self.mount_path)

            # Limpiar salida visual del entorno
            clear_output(wait=True)

            # Confirmar √©xito del proceso
            if self.verbose:
                self.logger.info("Google Drive montado correctamente.")
            else:
                print("Google Drive montado correctamente.")

        except Exception as e:
            # Manejar y registrar errores
            if self.verbose:
                self.logger.error(f"Error al montar Google Drive: {e}", exc_info=True)
            raise RuntimeError(f"No se pudo montar Google Drive: {e}") from e

# Conectar el Google Drive
CONNECTOR = GoogleDriveConnector(
    mount_path="/content/drive",
    verbose=True,
)

CONNECTOR.mount_drive()

"""## Instalaci√≥n de librer√≠as y repositorios

Instala las dependencias y paquetes personalizados necesarios para ejecutar HerdNet y sus componentes, asegurando compatibilidad con la versi√≥n utilizada del framework.
"""

# ============================================================
# CONFIGURADOR DE ENTORNO HERDNET (COLAB O LOCAL)
# ============================================================

import os
import sys
import logging
import subprocess
from pathlib import Path
from IPython.display import clear_output

class ConfiguradorHerdNet:
    """
    Clase para configurar autom√°ticamente el entorno de HerdNet,
    compatible tanto con Google Colab como con entornos locales.

    Prop√≥sito
    ----------
    Reproduce la instalaci√≥n de HerdNet con detecci√≥n de entorno,
    manejo de errores y registro de eventos mediante logging.

    Par√°metros
    ----------
    base_dir : str, opcional
        Ruta donde se clonar√° el repositorio HerdNet.
        Por defecto: '/content/HerdNet' si se ejecuta en Colab,
        o './HerdNet' si se ejecuta localmente.
    verbose : bool, opcional
        Si es True, muestra informaci√≥n detallada del proceso.
    """

    def __init__(self, base_dir: str = None, verbose: bool = True):
        """Inicializa el configurador y detecta el entorno de ejecuci√≥n."""
        # Detectar si se ejecuta en Colab
        self.is_colab = "google.colab" in sys.modules

        # Definir ruta base seg√∫n entorno
        self.base_dir = Path(base_dir or ("/content/HerdNet" if self.is_colab else "./HerdNet"))

        # Configurar logging est√°ndar
        logging.basicConfig(
            level=logging.INFO,
            format="[%(asctime)s] [%(levelname)s] %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
            force=True
        )
        self.logger = logging.getLogger("ConfiguradorHerdNet")

        # Control de verbosidad
        self.verbose = verbose

    # ------------------------------------------------------------
    def _run_command(self, command: str):
        """
        Ejecuta un comando del sistema de forma segura.

        Par√°metros
        ----------
        command : str
            Comando del sistema a ejecutar.

        Excepciones
        -----------
        subprocess.CalledProcessError
            Si el comando devuelve un error de ejecuci√≥n.
        """
        try:
            result = subprocess.run(
                command,
                shell=True,
                check=True,
                text=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE
            )
            if self.verbose and result.stdout.strip():
                self.logger.info(result.stdout.strip())
        except subprocess.CalledProcessError as e:
            self.logger.error(f"Error ejecutando comando: {command}")
            if e.stderr.strip():
                self.logger.error(e.stderr.strip())
            raise

    # ------------------------------------------------------------
    def verificar_gpu(self):
        """Verifica la disponibilidad de una GPU mediante nvidia-smi."""
        self.logger.info("Verificando GPU disponible...")
        try:
            self._run_command("nvidia-smi")
        except Exception:
            self.logger.warning("No se pudo verificar GPU. Puede que no exista o no est√© disponible.")

    # ------------------------------------------------------------
    def instalar_dependencias(self):
        """
        Instala las dependencias necesarias seg√∫n el entorno detectado.

        En Colab se instalan versiones recientes compatibles.
        En local se instalan las versiones exactas del paper HerdNet.
        """
        if self.is_colab:
            self.logger.info("Entorno detectado: Google Colab")
            self.logger.info("Instalando dependencias compatibles con Colab...")
            deps = (
                "albumentations fiftyone hydra-core opencv-python pandas pillow "
                "scikit-image scikit-learn scipy wandb"
            )
        else:
            self.logger.info("Entorno detectado: Local")
            self.logger.info("Instalando dependencias exactas del paper HerdNet...")
            deps = (
                "albumentations==1.0.3 fiftyone==0.14.3 hydra-core==1.1.0 "
                "opencv-python==4.5.1.48 pandas==1.2.3 pillow==8.2.0 "
                "scikit-image==0.18.1 scikit-learn==1.0.2 scipy==1.6.2 wandb==0.10.33"
            )

        cmd = f"{sys.executable} -m pip install {deps} -q"
        try:
            self._run_command(cmd)
        except Exception as e:
            self.logger.warning(f"Fallo parcial en instalaci√≥n de dependencias: {e}")
            self.logger.warning("Continuando con el proceso...")

    # ------------------------------------------------------------
    def clonar_repo(self):
        """Clona e instala el repositorio HerdNet desde GitHub."""
        self.logger.info("Clonando repositorio HerdNet original...")
        if self.base_dir.exists():
            self.logger.info("El repositorio ya existe. Se omite la clonaci√≥n.")
        else:
            self._run_command(f"git clone https://github.com/Alexandre-Delplanque/HerdNet {self.base_dir}")

        self._run_command(f"cd {self.base_dir} && {sys.executable} setup.py install -q")
        sys.path.append(str(self.base_dir))

    # ------------------------------------------------------------
    def limpiar_salida(self):
        """Limpia la salida si se ejecuta en Google Colab."""
        if self.is_colab:
            clear_output(wait=True)

    # ------------------------------------------------------------
    def configurar(self):
        """
        Ejecuta el flujo completo de configuraci√≥n del entorno HerdNet.

        Incluye:
        - Verificaci√≥n de GPU
        - Instalaci√≥n de dependencias
        - Clonaci√≥n del repositorio
        - Instalaci√≥n local
        - Limpieza de salida (solo en Colab)
        """
        self.logger.info("Iniciando configuraci√≥n del entorno HerdNet...")
        try:
            self.verificar_gpu()
            self.instalar_dependencias()
            self.clonar_repo()
            self.limpiar_salida()
            self.logger.info("Instalaci√≥n completada correctamente y entorno listo.")
            print("Instalaci√≥n completada correctamente y entorno listo.")
        except Exception as e:
            self.logger.error(f"Error durante la configuraci√≥n: {e}")
            raise

configurador = ConfiguradorHerdNet(verbose=True)
configurador.configurar()

"""# Datasets

Agrupa los procesos de conversi√≥n, visualizaci√≥n y carga de los conjuntos de datos utilizados en el entrenamiento y evaluaci√≥n del modelo.

## Conversi√≥n desde COCO a CSV

Convierte las anotaciones del formato COCO JSON al formato CSV compatible con HerdNet, garantizando que las coordenadas, etiquetas y nombres de archivo se mantengan consistentes con lo que espera la librer√≠a de HerdNet.
"""

import os
import json
import logging
import pandas as pd
from tqdm import tqdm

class ConversorCOCOaHerdNet:
    """
    ConversorCOCOaHerdNet
    ---------------------
    Clase para convertir anotaciones en formato COCO JSON al formato CSV
    utilizado por HerdNet.

    Prop√≥sito
    ----------
    Facilita la conversi√≥n de anotaciones de detecci√≥n (cajas o puntos)
    al formato CSV compatible con HerdNet, incluyendo coordenadas y etiquetas.

    Par√°metros
    ----------
    ruta_json : str
        Ruta al archivo COCO JSON con las anotaciones.
    carpeta_imagenes : str
        Carpeta donde se encuentran las im√°genes del dataset.
    ruta_salida : str
        Ruta donde se guardar√° el CSV resultante.
    verbose : bool, opcional
        Si es True, muestra mensajes detallados del proceso.
    """

    def __init__(self, ruta_json: str, carpeta_imagenes: str, ruta_salida: str, verbose: bool = True):
        """Inicializa el conversor con las rutas y la configuraci√≥n."""
        self.ruta_json = ruta_json
        self.carpeta_imagenes = carpeta_imagenes
        self.ruta_salida = ruta_salida
        self.verbose = verbose

        # Configurar logger √∫nico por instancia
        logger_name = f"ConversorCOCOaHerdNet.{id(self)}"
        self.logger = logging.getLogger(logger_name)
        self.logger.setLevel(logging.INFO if verbose else logging.WARNING)

        # Siempre eliminar handlers anteriores para evitar duplicaciones o silencios
        if self.logger.hasHandlers():
            self.logger.handlers.clear()

        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            "[%(asctime)s] [%(levelname)s] %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.propagate = False


        # Validar rutas iniciales
        self._validar_entradas()

    # ------------------------------------------------------------
    def _validar_entradas(self):
        """Verifica que las rutas de entrada sean v√°lidas."""
        if not os.path.exists(self.ruta_json):
            raise FileNotFoundError(f"No se encontr√≥ el archivo de anotaciones: {self.ruta_json}")
        if not os.path.exists(self.carpeta_imagenes):
            raise FileNotFoundError(f"No se encontr√≥ la carpeta de im√°genes: {self.carpeta_imagenes}")

    # ------------------------------------------------------------
    def _cargar_json(self) -> dict:
        """Carga el archivo COCO JSON de anotaciones."""
        self.logger.info("Cargando anotaciones COCO...")
        with open(self.ruta_json, "r", encoding="utf-8") as f:
            data = json.load(f)

        if "images" not in data or "annotations" not in data:
            raise ValueError("El archivo JSON no tiene las claves requeridas: 'images' o 'annotations'.")

        self.logger.info(f"Im√°genes detectadas: {len(data['images'])}")
        self.logger.info(f"Anotaciones detectadas: {len(data['annotations'])}")
        return data

    # ------------------------------------------------------------
    def _extraer_registros(self, coco: dict) -> pd.DataFrame:
        """Procesa las anotaciones COCO y genera un DataFrame con el formato HerdNet."""
        categorias = coco.get("categories", [])
        mapa_categorias = {cat["id"]: cat["name"] for cat in categorias}
        self.logger.info(f"Categor√≠as detectadas: {mapa_categorias}")

        id_a_nombre = {img["id"]: img["file_name"] for img in coco["images"]}
        id_a_base = {img["id"]: os.path.splitext(img["file_name"])[0] for img in coco["images"]}

        registros = []

        for anotacion in tqdm(coco["annotations"], desc="Procesando anotaciones"):
            id_imagen = anotacion.get("image_id")
            id_categoria = anotacion.get("category_id")
            bbox = anotacion.get("bbox", None)
            keypoints = anotacion.get("keypoints", None)

            # Calcular punto central de la anotaci√≥n
            if bbox:
                x, y, w, h = bbox
                cx, cy = x + w / 2, y + h / 2
            elif keypoints and len(keypoints) >= 2:
                cx, cy = keypoints[0], keypoints[1]
            else:
                continue

            nombre_imagen = id_a_nombre.get(id_imagen)
            nombre_base = id_a_base.get(id_imagen)
            if nombre_imagen is None:
                continue

            registros.append({
                "images": nombre_imagen,
                "labels": id_categoria,
                "base_images": nombre_base,
                "x": cx,
                "y": cy,
            })

        df = pd.DataFrame(registros)
        if df.empty:
            raise ValueError("No se generaron registros v√°lidos a partir del archivo COCO.")

        # Validar y limpiar etiquetas no num√©ricas o nulas
        df["labels"] = pd.to_numeric(df["labels"], errors="coerce")
        filas_invalidas = df[df["labels"].isna()]
        if not filas_invalidas.empty:
            self.logger.warning(f"Se eliminaron {len(filas_invalidas)} anotaciones sin etiqueta v√°lida.")
            df = df.dropna(subset=["labels"])

        # Convertir etiquetas a enteros seguros
        df["labels"] = df["labels"].astype(int)

        # Log de resumen de clases
        etiquetas_unicas = df["labels"].unique().tolist()
        self.logger.info(f"Etiquetas detectadas: {etiquetas_unicas}")

        return df

    # ------------------------------------------------------------
    def convertir(self) -> pd.DataFrame:
        """
        Ejecuta el proceso completo de conversi√≥n COCO -> HerdNet CSV.

        Retorna
        -------
        pd.DataFrame
            DataFrame final con las columnas esperadas.
        """
        self.logger.info("Iniciando conversi√≥n COCO -> HerdNet...")

        # Cargar anotaciones
        coco = self._cargar_json()

        # Extraer y validar registros
        df = self._extraer_registros(coco)

        # Crear carpeta de salida
        os.makedirs(os.path.dirname(self.ruta_salida), exist_ok=True)

        # Guardar CSV limpio
        df.to_csv(self.ruta_salida, index=False, encoding="utf-8")

        self.logger.info(f"Conversi√≥n completada. CSV guardado en: {self.ruta_salida}")
        self.logger.info(f"Total de filas finales: {len(df)}")
        return df

# Conversi√≥n del conjunto de entrenamiento
CONVERSOR_TRAIN = ConversorCOCOaHerdNet(
    ruta_json=str(TRAIN_ANN_FILE),
    carpeta_imagenes=str(TRAIN_IMG_DIR),
    ruta_salida=str(TRAIN_CSV),
    verbose=True,
)
DF_TRAIN = CONVERSOR_TRAIN.convertir()
print(f"Entrenamiento: {TRAIN_CSV}  ({len(DF_TRAIN)} - Filas v√°lidas - Anotaciones\n)")

# Conversi√≥n del conjunto de validaci√≥n
CONVERSOR_VAL = ConversorCOCOaHerdNet(
    ruta_json=str(VAL_ANN_FILE),
    carpeta_imagenes=str(VAL_IMG_DIR),
    ruta_salida=str(VAL_CSV),
    verbose=True,
)
DF_VAL = CONVERSOR_VAL.convertir()
print(f"Validaci√≥n:    {VAL_CSV}   ({len(DF_VAL)} - Filas v√°lidas - Anotaciones\n)")

# Conversi√≥n del conjunto de prueba
CONVERSOR_TEST = ConversorCOCOaHerdNet(
    ruta_json=str(TEST_ANN_FILE),
    carpeta_imagenes=str(TEST_IMG_DIR),
    ruta_salida=str(TEST_CSV),
    verbose=True,
)
DF_TEST = CONVERSOR_TEST.convertir()
print(f"Prueba:        {TEST_CSV}  ({len(DF_TEST)} - Filas v√°lidas - Anotaciones)\n")

"""## Visualizaci√≥n de im√°genes de los splits con sus anotaciones

Muestra ejemplos aleatorios de las im√°genes de entrenamiento, validaci√≥n y prueba junto con sus puntos de anotaci√≥n, permitiendo verificar visualmente la integridad de los datos (correspondencia).
"""

import os
import random
import logging
import pandas as pd
import matplotlib.pyplot as plt
from pathlib import Path
from PIL import Image


class VisualizadorEjemplosSplits:
    """
    VisualizadorEjemplosSplits
    --------------------------
    Visualiza ejemplos aleatorios desde los archivos CSV de anotaciones
    de HerdNet para cada divisi√≥n del conjunto de datos (train, val, test).

    Prop√≥sito
    ----------
    Permite verificar visualmente que la conversi√≥n COCO ‚Üí HerdNet se haya
    realizado correctamente, comprobando que las anotaciones (x, y) est√©n
    alineadas con el contenido real de las im√°genes.

    Par√°metros
    ----------
    rutas_csv : dict
        Diccionario con las rutas de los CSV de anotaciones. Debe contener
        las claves "train", "val" y "test".
    rutas_img : dict
        Diccionario con las rutas de las carpetas de im√°genes
        correspondientes a cada split.
    muestras_por_split : int, opcional
        N√∫mero de im√°genes a visualizar por cada conjunto (por defecto 6).
    verbose : bool, opcional
        Si es True, muestra mensajes detallados mediante logging.
    """

    def __init__(self, rutas_csv: dict, rutas_img: dict, muestras_por_split: int = 6, verbose: bool = True):
        """Inicializa el visualizador con las rutas y la configuraci√≥n."""
        self.rutas_csv = rutas_csv
        self.rutas_img = rutas_img
        self.muestras_por_split = muestras_por_split
        self.verbose = verbose

        # Configurar logger √∫nico por instancia
        logger_name = f"VisualizadorEjemplosSplits.{id(self)}"
        self.logger = logging.getLogger(logger_name)
        self.logger.setLevel(logging.INFO if verbose else logging.WARNING)

        if self.logger.hasHandlers():
            self.logger.handlers.clear()

        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            "[%(asctime)s] [%(levelname)s] %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.propagate = False

        # Validar rutas de entrada
        self._validar_entradas()

    # ------------------------------------------------------------
    def _validar_entradas(self):
        """Valida que todas las rutas a CSV e im√°genes existan."""
        for split, ruta_csv in self.rutas_csv.items():
            if not os.path.exists(ruta_csv):
                raise FileNotFoundError(f"No se encontr√≥ el CSV del conjunto '{split}': {ruta_csv}")

        for split, ruta_img in self.rutas_img.items():
            if not os.path.exists(ruta_img):
                raise FileNotFoundError(f"No se encontr√≥ la carpeta de im√°genes del conjunto '{split}': {ruta_img}")

    # ------------------------------------------------------------
    def _cargar_split(self, split: str) -> pd.DataFrame:
        """Carga las anotaciones del CSV correspondiente al split indicado."""
        self.logger.info(f"Cargando anotaciones del conjunto '{split}'...")
        df = pd.read_csv(self.rutas_csv[split])

        if df.empty:
            raise ValueError(f"El archivo CSV del conjunto '{split}' est√° vac√≠o.")

        columnas_requeridas = {"images", "x", "y"}
        faltantes = columnas_requeridas - set(df.columns)
        if faltantes:
            raise ValueError(f"El CSV '{split}' no contiene las columnas requeridas: {faltantes}")

        return df

    # ------------------------------------------------------------
    def _mostrar_ejemplos_split(self, split: str, df: pd.DataFrame, carpeta_img: str):
        """Muestra visualmente ejemplos aleatorios para un split espec√≠fico."""
        self.logger.info(f"Visualizando ejemplos del conjunto '{split}'...")

        muestras = df["images"].drop_duplicates().sample(
            n=min(self.muestras_por_split, df["images"].nunique()),
            random_state=42,
        )

        num_muestras = len(muestras)
        columnas = 3
        filas = (num_muestras + columnas - 1) // columnas

        fig, axes = plt.subplots(filas, columnas, figsize=(15, 5 * filas))
        axes = axes.flatten()

        for i, nombre_img in enumerate(muestras):
            ruta_img = Path(carpeta_img) / nombre_img
            if not ruta_img.exists():
                self.logger.warning(f"No se encontr√≥ la imagen: {ruta_img}")
                continue

            imagen = Image.open(ruta_img).convert("RGB")
            anotaciones = df[df["images"] == nombre_img]

            axes[i].imshow(imagen)
            axes[i].set_title(f"{split.upper()} - {nombre_img}", fontsize=10)
            axes[i].axis("off")

            axes[i].scatter(
                anotaciones["x"],
                anotaciones["y"],
                s=20,
                c="red",
                alpha=0.7,
                marker="o",
                label="anotaciones",
            )
            axes[i].legend(loc="lower right", fontsize=8)

        # Ocultar ejes no usados si hay menos im√°genes que subplots
        for j in range(i + 1, len(axes)):
            axes[j].axis("off")

        plt.tight_layout()
        plt.show()

    # ------------------------------------------------------------
    def visualizar(self) -> dict:
        """
        Carga y visualiza ejemplos aleatorios de cada conjunto (train, val, test).

        Retorna
        -------
        dict
            Diccionario con los DataFrames de cada conjunto visualizado.
        """
        self.logger.info("Iniciando verificaci√≥n visual de los conjuntos...")
        resultados = {}

        for split in ["train", "val", "test"]:
            try:
                df = self._cargar_split(split)
                resultados[split] = df
                self._mostrar_ejemplos_split(split, df, self.rutas_img[split])
            except Exception as e:
                self.logger.error(f"Error al visualizar el conjunto '{split}': {e}", exc_info=True)

        self.logger.info("Visualizaci√≥n completada correctamente.")
        return resultados

# Visualizaci√≥n de ejemplos de im√°genes con anotaciones
VISUALIZADOR = VisualizadorEjemplosSplits(
    rutas_csv={
        "train": str(TRAIN_CSV),
        "val": str(VAL_CSV),
        "test": str(TEST_CSV),
    },
    rutas_img={
        "train": str(TRAIN_IMG_DIR),
        "val": str(VAL_IMG_DIR),
        "test": str(TEST_IMG_DIR),
    },
    muestras_por_split=3,
    verbose=True,
)

VISUALIZADOR.visualizar()

"""## Dataloaders para el modelo

Crea los DataLoaders de HerdNet sin aplicar aumentaciones (ya se hizo previamente), verificando que las im√°genes y anotaciones se carguen correctamente y cumplan con las dimensiones requeridas por la arquitectura.
"""

import os
import math
import logging
import pandas as pd
from tqdm import tqdm
from PIL import ImageFile
import torch
from torch.utils.data import DataLoader
from animaloc.datasets import CSVDataset
from animaloc.data.transforms import MultiTransformsWrapper, DownSample, PointsToMask, FIDT


class DataLoadersHerdNet:
    """
    DataLoadersHerdNet
    ------------------
    Crea datasets y dataloaders de entrenamiento, validaci√≥n y prueba
    para HerdNet, ajustando autom√°ticamente las transformaciones
    seg√∫n si se usa o no el modelo DLA preentrenado.
    """

    def __init__(
        self,
        train_csv,
        val_csv,
        test_csv,
        train_img_dir,
        val_img_dir,
        test_img_dir,
        num_classes,
        down_ratio,
        batch_size=4,
        patch_size=512,
        update_csv=False,
        verbose=True,
        modelo_preentrenado_dla=False,
        metric_radius_base=25,
    ):
        # Par√°metros principales
        self.train_csv = train_csv
        self.val_csv = val_csv
        self.test_csv = test_csv
        self.train_img_dir = train_img_dir
        self.val_img_dir = val_img_dir
        self.test_img_dir = test_img_dir
        self.num_classes = num_classes
        self.batch_size = batch_size
        self.patch_size = patch_size
        self.update_csv = update_csv
        self.verbose = verbose
        self.modelo_preentrenado_dla = modelo_preentrenado_dla

        # Ajustes autom√°ticos seg√∫n modo
        if modelo_preentrenado_dla:
            self.down_ratio = 16
            self.metric_radius = metric_radius_base / 16
            self.use_points_to_mask = False
            self.stitcher_up = True
            self.stitcher_reduction = "mean"
        else:
            self.down_ratio = down_ratio
            self.metric_radius = metric_radius_base
            self.use_points_to_mask = True
            self.stitcher_up = False
            self.stitcher_reduction = "sum"

        # Tama√±o ajustado
        self.padded_size = int(math.ceil(patch_size / 32) * 32)

        # Logger
        logger_name = f"DataLoadersHerdNet.{id(self)}"
        self.logger = logging.getLogger(logger_name)
        self.logger.setLevel(logging.INFO if verbose else logging.WARNING)
        if self.logger.hasHandlers():
            self.logger.handlers.clear()
        handler = logging.StreamHandler()
        formatter = logging.Formatter(
            "[%(asctime)s] [%(levelname)s] %(message)s",
            datefmt="%Y-%m-%d %H:%M:%S",
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)
        self.logger.propagate = False

    # ------------------------------------------------------------
    def _recortar_coordenadas_csv(self, csv_path, img_dir):
        df = pd.read_csv(csv_path)
        corregidos = 0
        EPS = 1e-3
        size_cache = {}

        for i, row in tqdm(df.iterrows(), total=len(df),
                           desc=f"Verificando {os.path.basename(csv_path)}",
                           ncols=100):
            img_path = os.path.join(img_dir, row["images"])
            if not os.path.exists(img_path):
                continue

            if img_path not in size_cache:
                try:
                    parser = ImageFile.Parser()
                    with open(img_path, "rb") as f:
                        while True:
                            chunk = f.read(1024)
                            if not chunk:
                                break
                            parser.feed(chunk)
                            if parser.image:
                                size_cache[img_path] = parser.image.size
                                break
                    if img_path not in size_cache:
                        size_cache[img_path] = None
                except Exception:
                    size_cache[img_path] = None

            size = size_cache[img_path]
            if not size:
                continue

            w, h = size
            x_new = min(max(row["x"], 0 + EPS), w - 1 - EPS)
            y_new = min(max(row["y"], 0 + EPS), h - 1 - EPS)

            if x_new != row["x"] or y_new != row["y"]:
                df.at[i, "x"], df.at[i, "y"] = x_new, y_new
                corregidos += 1

        df.to_csv(csv_path, index=False)
        self.logger.info(f"[INFO] {os.path.basename(csv_path)}: coordenadas corregidas = {corregidos}")

    # ------------------------------------------------------------
    @staticmethod
    def herdnet_collate_fn(batch):
        batch = [b for b in batch if b is not None]
        imgs, targets = [], []

        for img, target in batch:
            imgs.append(img)
            if isinstance(target, dict):
                clean_target = {k: v for k, v in target.items() if isinstance(v, torch.Tensor)}
                targets.append(clean_target)
            elif isinstance(target, (list, tuple)):
                targets.append(tuple(t for t in target if isinstance(t, torch.Tensor)))
            elif isinstance(target, torch.Tensor):
                targets.append(target)

        imgs = torch.stack(imgs, dim=0)
        if isinstance(targets[0], dict):
            keys = targets[0].keys()
            targets = {k: torch.stack([t[k] for t in targets], dim=0) for k in keys}
        elif isinstance(targets[0], tuple):
            targets = tuple(torch.stack([t[i] for t in targets], dim=0) for i in range(len(targets[0])))
        else:
            targets = torch.stack(targets, dim=0)
        return imgs, targets

    # ------------------------------------------------------------
    def _obtener_transformaciones_basicas(self):
        import albumentations as A
        return [
            A.Resize(height=self.padded_size, width=self.padded_size),
            A.Normalize(mean=(0.485, 0.456, 0.406),
                        std=(0.229, 0.224, 0.225), p=1.0)
        ]

    # ------------------------------------------------------------
    def crear_dataloaders(self):
        self.logger.info("[INFO] Creando DataLoaders de HerdNet (sin augmentaciones)...")
        self.logger.info(f"[INFO] Tama√±o ajustado: {self.padded_size}x{self.padded_size}")

        if self.update_csv:
            self.logger.info("[INFO] Verificando coordenadas fuera de rango (solo en train)...")
            self._recortar_coordenadas_csv(self.train_csv, self.train_img_dir)

        # ------------------------------------------------------------
        # üîπ Definir transformaciones finales (entrenamiento)
        # ------------------------------------------------------------
        # Siempre deben incluir FIDT y PointsToMask, incluso con DLA
        end_transforms_train = [
            MultiTransformsWrapper([
                FIDT(num_classes=self.num_classes, down_ratio=self.down_ratio),
                PointsToMask(
                    radius=2,
                    num_classes=self.num_classes,
                    squeeze=True,
                    down_ratio=int(self.patch_size // 16),
                ),
            ])
        ]

        # ------------------------------------------------------------
        # üîπ Crear datasets
        # ------------------------------------------------------------
        train_dataset = CSVDataset(
            csv_file=self.train_csv,
            root_dir=self.train_img_dir,
            albu_transforms=self._obtener_transformaciones_basicas(),
            end_transforms=end_transforms_train,
        )

        val_dataset = CSVDataset(
            csv_file=self.val_csv,
            root_dir=self.val_img_dir,
            albu_transforms=self._obtener_transformaciones_basicas(),
            end_transforms=[DownSample(down_ratio=self.down_ratio, anno_type="point")],
        )

        test_dataset = CSVDataset(
            csv_file=self.test_csv,
            root_dir=self.test_img_dir,
            albu_transforms=self._obtener_transformaciones_basicas(),
            end_transforms=[DownSample(down_ratio=self.down_ratio, anno_type="point")],
        )

        # ------------------------------------------------------------
        # üîπ Crear DataLoaders
        # ------------------------------------------------------------
        self.train_loader = DataLoader(
            train_dataset, batch_size=self.batch_size, shuffle=True, collate_fn=self.herdnet_collate_fn
        )
        self.val_loader = DataLoader(
            val_dataset, batch_size=1, shuffle=False, collate_fn=self.herdnet_collate_fn
        )
        self.test_loader = DataLoader(
            test_dataset, batch_size=1, shuffle=False, collate_fn=self.herdnet_collate_fn
        )

        # ------------------------------------------------------------
        # üîπ Log resumen
        # ------------------------------------------------------------
        self.logger.info(
            f"[INFO] Datasets listos: {len(train_dataset)} train / {len(val_dataset)} val / {len(test_dataset)} test."
        )
        self.logger.info(f"[INFO] down_ratio={self.down_ratio}, use_points_to_mask=True (for HerdNet dual head)")

        return self.train_loader, self.val_loader, self.test_loader

    # ------------------------------------------------------------
    def get_active_constants(self):
        """
        Retorna las constantes activas que definen el modo de entrenamiento.
        Estas se usan para mantener coherencia entre DataLoaders, Stitcher y M√©tricas.
        """
        return {
            "FACTOR_REDUCCION": self.down_ratio,
            "RADIO_METRICA": 25,
            "SUPERPOSICION": 160,
            "STITCHER_UP": False,
            "STITCHER_REDUCTION": "mean",
            "PATCH_SIZE": self.patch_size,
        }

# ============================================================
# Creaci√≥n de Data Loaders
# ============================================================

DATA_LOADERS = DataLoadersHerdNet(
    train_csv=str(TRAIN_CSV),
    val_csv=str(VAL_CSV),
    test_csv=str(TEST_CSV),
    train_img_dir=str(TRAIN_IMG_DIR),
    val_img_dir=str(VAL_IMG_DIR),
    test_img_dir=str(TEST_IMG_DIR),
    num_classes=NUMERO_CLASES,
    down_ratio=FACTOR_REDUCCION,          # se ignora si modelo_preentrenado_dla=True
    batch_size=TAMANO_LOTE,
    patch_size=TAMANO_PARCHE,
    update_csv=True,
    verbose=True,
    modelo_preentrenado_dla=MODELO_PREENTRENADO_DLA  # activa los par√°metros correctos
)

# Crear los tres DataLoaders
TRAIN_LOADER, VAL_LOADER, TEST_LOADER = DATA_LOADERS.crear_dataloaders()

# ------------------------------------------------------------
# Mostrar resumen de configuraci√≥n activa
# ------------------------------------------------------------
constantes = DATA_LOADERS.get_active_constants()

print("\n[INFO] DataLoaders creados correctamente:")
print(f"- Entrenamiento: {len(TRAIN_LOADER.dataset)} im√°genes")
print(f"- Validaci√≥n:    {len(VAL_LOADER.dataset)} im√°genes")
print(f"- Prueba:        {len(TEST_LOADER.dataset)} im√°genes")
print(f"  Tama√±o ajustado: {DATA_LOADERS.padded_size}x{DATA_LOADERS.padded_size}\n")

print("[CONFIGURACI√ìN ACTIVA]")
for k, v in constantes.items():
    print(f"  {k}: {v}")

FACTOR_REDUCCION = constantes["FACTOR_REDUCCION"]

import torch
import logging

class VerificadorDataLoaderHerdNet:
    """
    VerificadorDataLoaderHerdNet
    ----------------------------
    Clase para validar la coherencia estructural de los DataLoaders de HerdNet
    antes de iniciar el entrenamiento.

    Prop√≥sito
    ----------
    Permite verificar:
    - La estructura y forma de las im√°genes en cada batch.
    - La consistencia de los targets (diccionarios, tensores o tuplas).
    - La validez de los tipos de datos y rangos num√©ricos.
    - Posibles errores de configuraci√≥n antes del entrenamiento.

    Par√°metros
    ----------
    dataloader : torch.utils.data.DataLoader
        Objeto DataLoader a verificar.
    nombre_split : str, opcional
        Nombre del conjunto (train, val, test) para mostrar en logs.
    verbose : bool, opcional
        Si es True, activa los mensajes detallados mediante logging.
    """

    def __init__(self, dataloader, nombre_split="train", verbose=True):
        """Inicializa el verificador con configuraci√≥n de logging y dataset."""
        self.dataloader = dataloader
        self.nombre_split = nombre_split
        self.verbose = verbose

        # Configurar logger
        self.logger = logging.getLogger(f"VerificadorDataLoaderHerdNet.{nombre_split}")
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "[%(asctime)s] [%(levelname)s] %(message)s",
                datefmt="%Y-%m-%d %H:%M:%S",
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)

        self.logger.setLevel(logging.INFO if verbose else logging.WARNING)
        self.logger.propagate = False

    # ------------------------------------------------------------
    def verificar(self):
        """
        Ejecuta una verificaci√≥n r√°pida de integridad sobre el DataLoader.

        Retorna
        -------
        dict
            Diccionario con los siguientes campos:
            - 'status' : 'success' o 'failed'
            - 'info' : informaci√≥n detallada sobre im√°genes y targets
        """
        self.logger.info(f"[INFO] Iniciando verificaci√≥n del DataLoader ({self.nombre_split})...")

        try:
            # Obtener un batch de muestra
            batch = next(iter(self.dataloader))
            images, targets = batch
            self.logger.info("Batch obtenido correctamente.")

            # --------------------------------------------------------
            # Validaci√≥n de im√°genes
            # --------------------------------------------------------
            info_imagenes = {
                "shape": tuple(images.shape),
                "dtype": str(images.dtype),
                "min": float(images.min().item()),
                "max": float(images.max().item()),
            }
            self.logger.info(f"Im√°genes: shape={info_imagenes['shape']}, dtype={info_imagenes['dtype']}")
            self.logger.info(f"Rango de valores: min={info_imagenes['min']:.3f}, max={info_imagenes['max']:.3f}")

            # --------------------------------------------------------
            # Validaci√≥n de targets
            # --------------------------------------------------------
            info_targets = {}

            if isinstance(targets, dict):
                for key, value in targets.items():
                    if isinstance(value, torch.Tensor):
                        info_targets[key] = {
                            "shape": tuple(value.shape),
                            "dtype": str(value.dtype),
                        }
                        self.logger.info(f"Target '{key}': shape={value.shape}, dtype={value.dtype}")
                    else:
                        self.logger.warning(f"Target '{key}' tiene tipo inesperado: {type(value)}")

            elif isinstance(targets, tuple):
                for i, value in enumerate(targets):
                    if isinstance(value, torch.Tensor):
                        info_targets[f"tuple_{i}"] = {
                            "shape": tuple(value.shape),
                            "dtype": str(value.dtype),
                        }
                        self.logger.info(f"Target (√≠ndice {i}): shape={value.shape}, dtype={value.dtype}")
                    else:
                        self.logger.warning(f"Elemento {i} del target tiene tipo inesperado: {type(value)}")

            elif isinstance(targets, torch.Tensor):
                info_targets["tensor"] = {
                    "shape": tuple(targets.shape),
                    "dtype": str(targets.dtype),
                }
                self.logger.info(f"Target tensor √∫nico: shape={targets.shape}, dtype={targets.dtype}")

            else:
                tipo = type(targets)
                self.logger.warning(f"Tipo de target inesperado: {tipo}")

            # --------------------------------------------------------
            # Verificaci√≥n estructural
            # --------------------------------------------------------
            estructura_valida = (
                images.ndim == 4 and isinstance(targets, (dict, tuple, torch.Tensor))
            )

            if estructura_valida:
                self.logger.info("[INFO] Estructura v√°lida para entrenamiento HerdNet.")
                status = "success"
            else:
                self.logger.warning("[ADVERTENCIA] Estructura inconsistente o no reconocida.")
                status = "failed"

            # --------------------------------------------------------
            # Resultado final
            # --------------------------------------------------------
            resumen = {
                "status": status,
                "info": {
                    "images": info_imagenes,
                    "targets": info_targets,
                    "estructura_valida": estructura_valida,
                },
            }

            self.logger.info(f"[INFO] Verificaci√≥n completada con estado: {status.upper()}")
            return resumen

        except Exception as e:
            self.logger.error(f"[ERROR] No se pudo verificar el DataLoader: {e}", exc_info=True)
            return {"status": "failed", "error": str(e)}

# Verificaci√≥n de calidad del DataLoader (train)
VERIFICADOR_TRAIN = VerificadorDataLoaderHerdNet(TRAIN_LOADER, nombre_split="train", verbose=True)
RESULTADO_TRAIN = VERIFICADOR_TRAIN.verificar()

# Verificaci√≥n de calidad del DataLoader (val)
VERIFICADOR_VAL = VerificadorDataLoaderHerdNet(VAL_LOADER, nombre_split="val", verbose=True)
RESULTADO_VAL = VERIFICADOR_VAL.verificar()

# Verificaci√≥n de calidad del DataLoader (test)
VERIFICADOR_TEST = VerificadorDataLoaderHerdNet(TEST_LOADER, nombre_split="test", verbose=True)
RESULTADO_TEST = VERIFICADOR_TEST.verificar()

# Resumen
print("\n[INFO] Resumen de verificaci√≥n de DataLoaders:")
for nombre, resultado in zip(
    ["train", "val", "test"],
    [RESULTADO_TRAIN, RESULTADO_VAL, RESULTADO_TEST]
):
    estado = resultado["status"]
    shape = resultado["info"]["images"]["shape"] if estado == "success" else "N/A"
    print(f" - {nombre.upper()}: {estado.upper()} | shape im√°genes: {shape}")

"""# Modelo

Incluye la inicializaci√≥n, configuraci√≥n y carga de pesos preentrenados del modelo HerdNet, adem√°s del Wrapper que gestiona sus p√©rdidas y dispositivos de ejecuci√≥n y que se pasar√° al loop de entrenamiento, donde se entrenar√° el modelo principal con toda la configuraci√≥n previa dada.

## Wrapper para HerdNet y carga de los pesos pre-entrenados

Carga el modelo HerdNet con las funciones de p√©rdida definidas, los pesos preentrenados y la configuraci√≥n del dispositivo, listo para iniciar la fase de entrenamiento y evaluaci√≥n. Permite tanto hacer finetuning como cargar desde DLA o hasta totalmente desde cero sin nada previo (no recomendado).
"""

import os
import logging
import torch
from torch import Tensor
from torch.nn import CrossEntropyLoss
from animaloc.models import HerdNet, LossWrapper
from animaloc.train.losses import FocalLoss


class HerdNetWrapper:
    """
    HerdNetWrapper
    ----------------
    Clase encargada de la carga, configuraci√≥n y gesti√≥n del modelo HerdNet.

    Prop√≥sito
    ----------
    Facilita:
    - La inicializaci√≥n del modelo HerdNet con o sin pesos preentrenados.
    - La configuraci√≥n de m√∫ltiples funciones de p√©rdida.
    - La carga condicional de pesos externos solo si se indica expl√≠citamente.

    Par√°metros
    ----------
    path_model : str
        Ruta al archivo `.pth` con los pesos externos del modelo HerdNet.
    num_classes : int
        N√∫mero total de clases (incluye fondo).
    down_ratio : int
        Factor de reducci√≥n espacial de la arquitectura HerdNet.
    device : str, opcional
        Dispositivo de ejecuci√≥n ("cuda" o "cpu"). Se detecta autom√°ticamente si no se indica.
    verbose : bool, opcional
        Si es True, muestra informaci√≥n detallada mediante logging.
    pretrained : bool, opcional
        Si es True, inicializa el backbone DLA con pesos de ImageNet
        y **no** carga `path_model`, incluso si se proporciona.
    """

    def __init__(self, path_model: str, num_classes: int, down_ratio: int,
                 device: str = None, verbose: bool = True, pretrained: bool = True):
        """Inicializa la configuraci√≥n del modelo y el registro de eventos."""
        # Par√°metros principales
        self.path_model = path_model
        self.num_classes = num_classes
        self.down_ratio = down_ratio
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.verbose = verbose
        self.pretrained = pretrained

        # Inicializar el modelo como None
        self.model = None

        # --------------------------------------------------------
        # Configuraci√≥n del logger
        # --------------------------------------------------------
        self.logger = logging.getLogger("HerdNetWrapper")
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "[%(asctime)s] [%(levelname)s] %(message)s",
                datefmt="%Y-%m-%d %H:%M:%S",
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO if verbose else logging.WARNING)
        self.logger.propagate = False

    # ------------------------------------------------------------
    def _verificar_modelo(self):
        """Verifica que la ruta del modelo preentrenado sea v√°lida."""
        if not os.path.exists(self.path_model):
            raise FileNotFoundError(f"No se encontr√≥ el archivo del modelo: {self.path_model}")

    # ------------------------------------------------------------
    def load_model(self) -> torch.nn.Module:
        """
        Carga el modelo HerdNet con las funciones de p√©rdida y pesos (si aplica).

        Retorna
        -------
        torch.nn.Module
            Modelo HerdNet listo para entrenamiento o evaluaci√≥n.
        """
        self.logger.info("Iniciando carga del modelo HerdNet...")

        # --------------------------------------------------------
        # Crear instancia base del modelo
        # --------------------------------------------------------
        base_model = HerdNet(
            num_classes=self.num_classes,
            down_ratio=self.down_ratio,
            pretrained=self.pretrained
        ).to(self.device)

        # --------------------------------------------------------
        # Configuraci√≥n de funciones de p√©rdida
        # --------------------------------------------------------
        weight = Tensor([1.0] * self.num_classes).to(self.device)

        losses = [
            {
                "loss": FocalLoss(reduction="mean"),
                "idx": 0, "idy": 0, "lambda": 1.0, "name": "focal_loss"
            },
            {
                "loss": CrossEntropyLoss(reduction="mean", weight=weight),
                "idx": 1, "idy": 1, "lambda": 1.0, "name": "cross_entropy"
            },
        ]

        # Envolver modelo con las p√©rdidas
        herdnet = LossWrapper(base_model, losses=losses)

        # --------------------------------------------------------
        # L√≥gica condicional de carga de pesos
        # --------------------------------------------------------
        if self.pretrained:
            self.logger.info("Inicializando HerdNet con backbone preentrenado (sin cargar pesos externos).")
        else:
            if self.path_model and os.path.exists(self.path_model):
                self.logger.info("Cargando pesos externos desde ruta proporcionada...")
                state = torch.load(self.path_model, map_location=self.device)
                herdnet.load_state_dict(state, strict=False)
                self.logger.info("Pesos cargados correctamente desde el archivo.")
            else:
                self.logger.warning("No se encontr√≥ un archivo de pesos v√°lido. Se utilizar√° inicializaci√≥n aleatoria.")

        self.model = herdnet
        return self.model

    # ------------------------------------------------------------
    def summary(self):
        """Imprime un resumen legible de la configuraci√≥n actual del modelo."""
        print("------------------------------------------------")
        print(" Configuraci√≥n del modelo HerdNet ")
        print("------------------------------------------------")
        print(f" Dispositivo          : {self.device}")
        print(f" N√∫mero de clases     : {self.num_classes}")
        print(f" Factor de reducci√≥n  : {self.down_ratio}")
        print(f" Ruta del modelo      : {self.path_model if self.path_model else 'Ninguna'}")
        print(f" GPU disponible       : {torch.cuda.is_available()}")
        print(f" Backbone preentrenado: {self.pretrained}")
        print("------------------------------------------------")

# Crear instancia del modelo HerdNet con DLA precargado
HERDNET_WRAPPER = HerdNetWrapper(
    path_model=RUTA_MODELO_HERDNET,
    num_classes=NUMERO_CLASES,
    down_ratio=FACTOR_REDUCCION,
    pretrained=MODELO_PREENTRENADO_DLA,
    verbose=True
)

# Cargar pesos preentrenados y preparar el modelo
MODELO = HERDNET_WRAPPER.load_model()

# Mostrar resumen de la configuraci√≥n
HERDNET_WRAPPER.summary()

"""## Entrenamiento (split de train y val)

Ejecuta el proceso completo de entrenamiento del modelo, incluyendo la optimizaci√≥n, c√°lculo de m√©tricas, validaci√≥n peri√≥dica y almacenamiento de los mejores checkpoints seg√∫n el desempe√±o obtenido.
"""

import os
import logging
import torch
from torch.optim import Adam
from animaloc.models import load_model
from animaloc.train import Trainer
from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator
from animaloc.utils.useful_funcs import mkdir

class EntrenamientoHerdNet:
    def __init__(
        self,
        modelo,
        dataloader_entrenamiento,
        dataloader_validacion,
        num_clases: int,
        ruta_salida: str,
        constantes: dict,
        lr: float = 1e-4,
        weight_decay: float = 1e-3,
        num_epochs: int = 10,
        warmup_iters: int = 100,
        checkpoints: str = "best",
        select: str = "max",
        validate_on: str = "f1_score",
        reanudar: bool = True,
        verbose: bool = True,
    ):
        self.modelo = modelo
        self.train_loader = dataloader_entrenamiento
        self.val_loader = dataloader_validacion
        self.num_clases = num_clases
        self.const = constantes  # üîπ almacena los par√°metros activos
        self.ruta_salida = ruta_salida
        self.lr = lr
        self.weight_decay = weight_decay
        self.num_epochs = num_epochs
        self.warmup_iters = warmup_iters
        self.checkpoints = checkpoints
        self.select = select
        self.validate_on = validate_on
        self.reanudar = reanudar
        self.verbose = verbose

        # Logger
        self.logger = logging.getLogger("EntrenamientoHerdNet")
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                "[%(asctime)s] [%(levelname)s] %(message)s",
                datefmt="%Y-%m-%d %H:%M:%S",
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
        self.logger.setLevel(logging.INFO if verbose else logging.WARNING)
        self.logger.propagate = False

        # Dispositivo
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.modelo = self.modelo.to(self.device)
        self.logger.info(f"Dispositivo detectado: {self.device}")

        # Crear directorio de salida
        mkdir(self.ruta_salida)
        self.logger.info(f"Directorio de salida listo: {self.ruta_salida}")

        # Reanudaci√≥n
        if self.reanudar:
            checkpoint = self._detectar_checkpoint()
            if checkpoint:
                try:
                    self.logger.info(f"Checkpoint detectado: {checkpoint}")
                    self.modelo = load_model(self.modelo, pth_path=checkpoint)
                    self.logger.info("Pesos cargados correctamente desde checkpoint previo.")
                except Exception as e:
                    self.logger.warning(f"No se pudo cargar el checkpoint detectado: {e}")
            else:
                self.logger.info("No se encontraron checkpoints previos, iniciando desde cero.")
        else:
            self.logger.info("Reanudaci√≥n desactivada, entrenamiento comenzar√° desde cero.")

        # Inicializaci√≥n de componentes coherentes con el modo activo
        self.optimizer = Adam(self.modelo.parameters(), lr=self.lr, weight_decay=self.weight_decay)

        self.metrics = PointsMetrics(
            radius=self.const["RADIO_METRICA"],
            num_classes=self.num_clases,
        )

        self.stitcher = HerdNetStitcher(
            model=self.modelo,
            size=(self.const["PATCH_SIZE"], self.const["PATCH_SIZE"]),
            overlap=self.const["SUPERPOSICION"],
            down_ratio=self.const["FACTOR_REDUCCION"],
            up=self.const["STITCHER_UP"],
            reduction=self.const["STITCHER_REDUCTION"],
            device_name=self.device,
        )

        self.evaluator = HerdNetEvaluator(
            model=self.modelo,
            dataloader=self.val_loader,
            metrics=self.metrics,
            stitcher=self.stitcher,
            work_dir=self.ruta_salida,
            header="validation",
        )

        # Trainer con ajuste din√°mico de tama√±o
        # --------------------------------------------------------
        self.trainer = Trainer(
            model=self.modelo,
            train_dataloader=self.train_loader,
            optimizer=self.optimizer,
            num_epochs=self.num_epochs,
            evaluator=self.evaluator,
            work_dir=self.ruta_salida,
        )

    # ------------------------------------------------------------
    def _detectar_checkpoint(self):
        posibles = ["best_model.pth", "last_model.pth"]
        for nombre in posibles:
            ruta = os.path.join(self.ruta_salida, nombre)
            if os.path.exists(ruta):
                return ruta
        return None

    # ------------------------------------------------------------
    def entrenar(self):
        self.logger.info("Iniciando entrenamiento de HerdNet...")
        try:
            if torch.cuda.is_available():
                self.logger.info("Entrenando en GPU.")
            else:
                self.logger.warning("Entrenamiento en CPU (puede ser m√°s lento).")

            # Hook de coherencia antes del entrenamiento (ajuste de tama√±o si aplica)
            def pre_step_hook(batch):
                imgs, targets = batch
                imgs = imgs.to(self.device)
                targets = targets["density"].to(self.device)

                with torch.no_grad():
                    dummy_out = self.modelo(imgs)[0]
                    if dummy_out.shape[-2:] != targets.shape[-2:]:
                        targets = torch.nn.functional.interpolate(
                            targets, size=dummy_out.shape[-2:], mode="bilinear", align_corners=True
                        )
                return imgs, targets

            self.trainer.start(
                warmup_iters=self.warmup_iters,
                checkpoints=self.checkpoints,
                select=self.select,
                validate_on=self.validate_on,
            )

            self.logger.info("Entrenamiento completado exitosamente.")
            return {"status": "success", "output_dir": self.ruta_salida}

        except Exception as e:
            self.logger.error(f"Error durante el entrenamiento: {e}", exc_info=True)
            return {"status": "failed", "error": str(e)}

entrenador = EntrenamientoHerdNet(
    modelo=MODELO,
    dataloader_entrenamiento=TRAIN_LOADER,
    dataloader_validacion=VAL_LOADER,
    num_clases=NUMERO_CLASES,
    ruta_salida=RUTA_SALIDA,
    constantes=constantes,
    lr=TASA_APRENDIZAJE,
    weight_decay=PESO_DECAY,
    num_epochs=EPOCHS_TOTALES,
    warmup_iters=ITERACIONES_CALENTAMIENTO,
    checkpoints="best",
    select="max",
    validate_on="f1_score",
    reanudar=True,
    verbose=True
)

resultado = entrenador.entrenar()

"""## Evaluaci√≥n fuera de muestra (split test)

Se usa el F1 score para evaluar la calidad del modelo en el set de prueba.
"""

from animaloc.models import load_model
from animaloc.eval import PointsMetrics, HerdNetStitcher, HerdNetEvaluator

# Cargar el modelo entrenado
MODELO = load_model(MODELO, pth_path=os.path.join(RUTA_SALIDA, "best_model.pth"))

# Configurar m√©tricas y stitching
metrics = PointsMetrics(radius=RADIO_METRICA, num_classes=NUMERO_CLASES)

stitcher = HerdNetStitcher(
    model=MODELO,
    size=(TAMANO_PARCHE, TAMANO_PARCHE),
    overlap=SUPERPOSICION,
    down_ratio=FACTOR_REDUCCION,
    up=False, # False para no DLA
    reduction="mean",
)

# Crear el evaluador
test_evaluator = HerdNetEvaluator(
    model=MODELO,
    dataloader=TEST_LOADER,
    metrics=metrics,
    stitcher=stitcher,
    work_dir=RUTA_SALIDA,
    header="test",
)

# Ejecutar evaluaci√≥n
test_f1_score = test_evaluator.evaluate(returns="f1_score")

print(f"\n F1-score en test: {test_f1_score:.4f}")

# Finalizaci√≥n Entrenamiento Base