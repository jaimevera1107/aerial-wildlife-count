# -*- coding: utf-8 -*-
"""train_yolov8_colab_v1_0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kPfu_FvG17YO2uCmXcPwYqWO4r2U_HJR

# üöÄ Entrenamiento YOLOv8 en Google Colab - V1 (Optimizado)

Este notebook entrena un modelo YOLOv8 con Ultralytics en Google Colab para detecci√≥n de vida silvestre a√©rea.

## üî• **MEJORAS V1:**
- ‚úÖ **Guardado autom√°tico en Drive** cada X √©pocas
- ‚úÖ **Recuperaci√≥n de entrenamiento** interrumpido
- ‚úÖ **Configuraci√≥n optimizada** para velocidad
- ‚úÖ **Monitoreo en tiempo real** del progreso
- ‚úÖ **Backup autom√°tico** de checkpoints

## üìã Caracter√≠sticas
- **Modelo**: YOLOv8s, YOLOv8m, YOLOv8l, YOLOv8x
- **Detecci√≥n autom√°tica de GPU**
- **Conversi√≥n autom√°tica COCO a YOLO**
- **Visualizaci√≥n de resultados**
- **Exportaci√≥n a ONNX/TorchScript**
- **An√°lisis de m√©tricas detallado**

## üéØ Clases de Animales
- Buffalo
- Elephant  
- Kob
- Alcelaphinae
- Warthog
- Waterbuck

## ‚öôÔ∏è Configuraci√≥n por Defecto
- **Modelo**: YOLOv8s (balanceado entre velocidad y precisi√≥n)
- **Tama√±o de imagen**: 640x640
- **√âpocas**: 100
- **Batch size**: 16
- **Optimizador**: AdamW
- **Mixed Precision**: Habilitado

## üî¨ Ventajas de YOLOv8
- **R√°pido**: Entrenamiento e inferencia eficientes
- **Preciso**: Mejor rendimiento que versiones anteriores
- **F√°cil de usar**: API simple de Ultralytics
- **Flexible**: M√∫ltiples tama√±os de modelo

## üîß Instalaci√≥n de Dependencias
"""

# Commented out IPython magic to ensure Python compatibility.
# Instalar dependencias
# %pip install -q ultralytics pyyaml opencv-python pillow tqdm matplotlib seaborn pandas

# Verificar instalaci√≥n
import torch
print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA version: {torch.version.cuda}")
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

"""## üì¶ Importar Librer√≠as"""

# ============================================================
# VARIABLES GLOBALES PARA BACKUP AUTOM√ÅTICO
# ============================================================

# Variables globales para el sistema de backup
backup_thread_running = False
backup_thread = None

print("‚úÖ Variables globales de backup inicializadas")

import os
import sys
import yaml
import torch
import numpy as np
import pandas as pd
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
import cv2
from PIL import Image
import shutil
import json
from tqdm import tqdm

from ultralytics import YOLO
from google.colab import files, drive
from IPython.display import Image as IPImage, display

# Configurar matplotlib
plt.style.use('default')
sns.set_palette("husl")

print(f"PyTorch version: {torch.__version__}")
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"CUDA device: {torch.cuda.get_device_name(0)}")
    print(f"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

"""## üìÅ Configuraci√≥n de Datos"""

# ============================================================
# CONFIGURACI√ìN DE RUTAS PRINCIPALES (Unificado con HerdNet)
# ============================================================

# Definir la ruta base principal (ajustar seg√∫n el entorno: Drive o local)
BASE_DIR = Path("/content/drive/MyDrive/aerial-wildlife-count")

# ============================================================
# RUTAS DE IM√ÅGENES Y ANOTACIONES (COCO JSON) - Igual que HerdNet
# ============================================================

# Rutas de los archivos de anotaciones en formato COCO
TRAIN_ANN_FILE = BASE_DIR / "data" / "coco" / "train" / "train_annotations.json"
VAL_ANN_FILE = BASE_DIR / "data" / "coco" / "val" / "val_annotations.json"
TEST_ANN_FILE = BASE_DIR / "data" / "coco" / "test" / "test_annotations.json"

# Rutas de las carpetas de im√°genes correspondientes a cada conjunto
TRAIN_IMG_DIR = BASE_DIR / "data" / "images" / "train"
VAL_IMG_DIR = BASE_DIR / "data" / "images" / "val"
TEST_IMG_DIR = BASE_DIR / "data" / "images" / "test"

# ============================================================
# RUTAS ALTERNATIVAS (Fallback para compatibilidad)
# ============================================================

# Rutas alternativas si no existe la estructura est√°ndar
TRAIN_ANN_FILE_ALT = BASE_DIR / "data" / "groundtruth" / "json" / "big_size" / "train_big_size_A_B_E_K_WH_WB.json"
VAL_ANN_FILE_ALT = BASE_DIR / "data" / "groundtruth" / "json" / "big_size" / "val_big_size_A_B_E_K_WH_WB.json"
TEST_ANN_FILE_ALT = BASE_DIR / "data" / "groundtruth" / "json" / "big_size" / "test_big_size_A_B_E_K_WH_WB.json"

# Rutas alternativas para im√°genes
TRAIN_IMG_DIR_ALT = BASE_DIR / "data" / "train"
VAL_IMG_DIR_ALT = BASE_DIR / "data" / "val"
TEST_IMG_DIR_ALT = BASE_DIR / "data" / "test"

# ============================================================
# FUNCI√ìN PARA CONFIGURAR DATOS (Unificada con HerdNet)
# ============================================================

def setup_data():
    """Configurar datos desde Google Drive con detecci√≥n autom√°tica de estructura"""

    # Montar Google Drive
    drive.mount('/content/drive')
    print("‚úÖ Google Drive montado")

    # Verificar si existe la estructura est√°ndar (igual que HerdNet)
    if TRAIN_ANN_FILE.exists() and TRAIN_IMG_DIR.exists():
        print("‚úÖ Datos encontrados (estructura est√°ndar COCO)")
        return str(BASE_DIR), "standard"
    elif TRAIN_ANN_FILE_ALT.exists() and TRAIN_IMG_DIR_ALT.exists():
        print("‚úÖ Datos encontrados (estructura alternativa groundtruth)")
        return str(BASE_DIR), "groundtruth"
    else:
        # Buscar en ubicaciones alternativas
        drive_path = "/content/drive/MyDrive"
        possible_paths = [
            f"{drive_path}/aerial-wildlife-count",
            f"{drive_path}/datasets/aerial-wildlife-count",
            f"{drive_path}/Colab Notebooks/aerial-wildlife-count"
        ]

        for path in possible_paths:
            if os.path.exists(path):
                print(f"‚úÖ Dataset encontrado en ubicaci√≥n alternativa: {path}")
                return path, "legacy"

        print("‚ùå No se encontr√≥ el dataset en Google Drive")
        return None, None

# Configurar datos
data_path, data_type = setup_data()
if data_path:
    print(f"üìÅ Ruta de datos configurada: {data_path}")
    print(f"üìä Tipo de datos: {data_type}")
else:
    print("‚ö†Ô∏è  Configura los datos manualmente antes de continuar")

"""## üìä An√°lisis de Datos

"""

# Funci√≥n para encontrar y analizar datasets (Unificada con HerdNet)
def find_and_analyze_datasets():
    """Encontrar y analizar datasets disponibles seg√∫n el tipo de datos"""

    if not data_path:
        print("‚ùå No hay ruta de datos configurada")
        return []

    datasets_found = []

    if data_type == "standard":
        # Estructura est√°ndar COCO (igual que HerdNet)
        datasets_found = [TRAIN_ANN_FILE, VAL_ANN_FILE, TEST_ANN_FILE]
        print("üìä Usando datasets est√°ndar COCO:")
        print(f"  Train: {TRAIN_ANN_FILE}")
        print(f"  Val: {VAL_ANN_FILE}")
        print(f"  Test: {TEST_ANN_FILE}")

    elif data_type == "groundtruth":
        # Estructura alternativa groundtruth
        datasets_found = [TRAIN_ANN_FILE_ALT, VAL_ANN_FILE_ALT, TEST_ANN_FILE_ALT]
        print("üìä Usando datasets groundtruth:")
        print(f"  Train: {TRAIN_ANN_FILE_ALT}")
        print(f"  Val: {VAL_ANN_FILE_ALT}")
        print(f"  Test: {TEST_ANN_FILE_ALT}")

    else:
        # Estructura legacy - buscar archivos JSON
        data_root = Path(data_path)
        json_patterns = [
            "**/train_*.json",
            "**/val_*.json",
            "**/test_*.json",
            "**/*_big_size_*.json",
            "**/*_subframes_*.json"
        ]

        for pattern in json_patterns:
            for json_file in data_root.glob(pattern):
                if json_file.is_file():
                    datasets_found.append(json_file)

        print(f"üìä Datasets encontrados en estructura legacy ({len(datasets_found)}):")
        for i, dataset in enumerate(datasets_found):
            print(f"  {i+1}. {dataset}")

    # Analizar el primer dataset encontrado
    if datasets_found:
        sample_data = analyze_dataset(datasets_found[0])
        return datasets_found

    return []

# Funci√≥n para analizar un dataset COCO
def analyze_dataset(json_path):
    """Analizar estad√≠sticas de un dataset COCO"""

    with open(json_path, 'r') as f:
        data = json.load(f)

    print(f"\nüìà An√°lisis de {json_path.name}:")
    print(f"  Im√°genes: {len(data['images'])}")
    print(f"  Anotaciones: {len(data['annotations'])}")
    print(f"  Categor√≠as: {len(data['categories'])}")

    # Estad√≠sticas por categor√≠a
    cat_counts = {}
    for ann in data['annotations']:
        cat_id = ann['category_id']
        cat_counts[cat_id] = cat_counts.get(cat_id, 0) + 1

    print("\n  Distribuci√≥n por categor√≠a:")
    for cat in data['categories']:
        count = cat_counts.get(cat['id'], 0)
        print(f"    {cat['name']}: {count}")

    return data

# Buscar y analizar datasets
datasets = find_and_analyze_datasets()

"""## ‚öôÔ∏è Configuraci√≥n del Entrenamiento"""

# Configuraci√≥n del entrenamiento
class YOLOConfig:
    def __init__(self):
        # Par√°metros del modelo - OPTIMIZADOS PARA VELOCIDAD
        self.model = 'yolov8s.pt'  # yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt
        self.image_size = 512
        self.epochs = 100
        self.batch_size = 32  # AUMENTADO para mayor velocidad (ajustar seg√∫n memoria)
        self.learning_rate = 0.01
        self.patience = 10
        self.device = 0  # GPU 0
        self.workers = 8  # AUMENTADO para mayor paralelizaci√≥n
        self.project = '/content/runs_yolo'
        self.name = 'yolo_aerial_wildlife_v1'
        self.fp16 = True  # Mixed precision

        # NUEVAS CONFIGURACIONES V1
        self.save_period = 3  # Guardar cada 5 √©pocas (m√°s frecuente)
        self.drive_backup_period = 3  # Backup en Drive cada 10 √©pocas
        self.drive_backup_dir = '/content/drive/MyDrive/aerial-wildlife-count-results/yolo_v1'
        self.resume_training = True  # Permitir reanudar entrenamiento

        # Clases del dataset
        self.classes = [
            "Buffalo", "Elephant", "Kob",
            "Alcelaphinae", "Warthog", "Waterbuck"
        ]

    def print_config(self):
        print("üîß Configuraci√≥n YOLOv8 V1 (Optimizada):")
        print(f"  Modelo: {self.model}")
        print(f"  Tama√±o de imagen: {self.image_size}")
        print(f"  √âpocas: {self.epochs}")
        print(f"  Batch size: {self.batch_size} (OPTIMIZADO)")
        print(f"  Workers: {self.workers} (OPTIMIZADO)")
        print(f"  Learning rate: {self.learning_rate}")
        print(f"  Dispositivo: {self.device}")
        print(f"  Mixed precision: {self.fp16}")
        print(f"  Save period: {self.save_period} √©pocas")
        print(f"  Drive backup: {self.drive_backup_period} √©pocas")
        print(f"  Resume training: {self.resume_training}")

# Crear instancia de configuraci√≥n
yolo_config = YOLOConfig()
yolo_config.print_config()

"""## üî• Funciones de Backup Autom√°tico en Drive

"""

# ============================================================
# FUNCIONES DE BACKUP AUTOM√ÅTICO EN DRIVE - V1
# ============================================================

import shutil
import time
from datetime import datetime
import threading

def create_drive_backup_dir():
    """Crear directorio de backup en Drive"""
    backup_dir = Path(yolo_config.drive_backup_dir)
    backup_dir.mkdir(parents=True, exist_ok=True)
    print(f"‚úÖ Directorio de backup creado: {backup_dir}")
    return backup_dir

def backup_to_drive(epoch=None, force=False):
    """Hacer backup de checkpoints a Drive"""
    try:
        # Crear directorio de backup
        backup_dir = create_drive_backup_dir()

        # Directorio fuente (Colab)
        source_dir = Path(f"{yolo_config.project}/{yolo_config.name}")

        if not source_dir.exists():
            print("‚ùå No existe directorio de entrenamiento para hacer backup")
            return False

        # Crear subdirectorio con timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        if epoch is not None:
            backup_subdir = backup_dir / f"epoch_{epoch}_{timestamp}"
        else:
            backup_subdir = backup_dir / f"backup_{timestamp}"

        backup_subdir.mkdir(exist_ok=True)

        # Copiar archivos importantes
        files_to_backup = [
            "weights/",
            "results.png",
            "confusion_matrix.png",
            "results.csv",
            "train_batch*.jpg",
            "val_batch*.jpg"
        ]

        copied_files = 0
        for pattern in files_to_backup:
            try:
                for file_path in source_dir.glob(pattern):
                    if file_path.is_file():
                        dest_path = backup_subdir / file_path.name
                        shutil.copy2(file_path, dest_path)
                        copied_files += 1
                    elif file_path.is_dir():
                        dest_path = backup_subdir / file_path.name
                        shutil.copytree(file_path, dest_path, dirs_exist_ok=True)
                        copied_files += 1
            except Exception as e:
                print(f"‚ö†Ô∏è Error copiando {pattern}: {e}")

        print(f"‚úÖ Backup completado: {copied_files} archivos copiados a {backup_subdir}")
        return True

    except Exception as e:
        print(f"‚ùå Error en backup: {e}")
        return False

def auto_backup_thread():
    """Thread para backup autom√°tico cada X √©pocas"""
    global backup_thread_running
    backup_thread_running = True

    print("üîÑ Thread de backup autom√°tico iniciado")

    while backup_thread_running:
        try:
            # Verificar si hay nuevos checkpoints
            weights_dir = Path(f"{yolo_config.project}/{yolo_config.name}/weights")
            if weights_dir.exists():
                checkpoints = list(weights_dir.glob("*.pt"))
                if checkpoints:
                    # Obtener el checkpoint m√°s reciente
                    latest_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)

                    # Verificar si necesita backup
                    backup_file = Path(f"{yolo_config.drive_backup_dir}/last_backup_epoch.txt")
                    last_backup_epoch = 0

                    if backup_file.exists():
                        try:
                            with open(backup_file, 'r') as f:
                                last_backup_epoch = int(f.read().strip())
                        except:
                            last_backup_epoch = 0

                    # Extraer √©poca del nombre del archivo
                    current_epoch = 0
                    if "epoch" in latest_checkpoint.name:
                        try:
                            current_epoch = int(latest_checkpoint.name.split("epoch_")[1].split(".")[0])
                        except:
                            current_epoch = 0

                    # Hacer backup si ha pasado el per√≠odo configurado
                    if current_epoch - last_backup_epoch >= yolo_config.drive_backup_period:
                        print(f"üîÑ Iniciando backup autom√°tico (√©poca {current_epoch})...")
                        if backup_to_drive(epoch=current_epoch):
                            # Actualizar archivo de control
                            backup_file.parent.mkdir(parents=True, exist_ok=True)
                            with open(backup_file, 'w') as f:
                                f.write(str(current_epoch))
                            print(f"‚úÖ Backup autom√°tico completado (√©poca {current_epoch})")

            # Esperar 5 minutos antes de verificar nuevamente
            time.sleep(300)  # 5 minutos

        except Exception as e:
            print(f"‚ùå Error en backup autom√°tico: {e}")
            time.sleep(60)  # Esperar 1 minuto en caso de error

    print("üõë Thread de backup autom√°tico detenido")

def start_auto_backup():
    """Iniciar backup autom√°tico en segundo plano"""
    global backup_thread, backup_thread_running

    # Detener thread anterior si existe
    if backup_thread_running:
        stop_auto_backup()
        time.sleep(2)  # Esperar a que se detenga

    backup_thread_running = False

    # Verificar si ya hay un thread corriendo
    if 'backup_thread' in globals() and backup_thread is not None and backup_thread.is_alive():
        print("‚ö†Ô∏è Backup autom√°tico ya est√° ejecut√°ndose")
        return

    backup_thread = threading.Thread(target=auto_backup_thread, daemon=True)
    backup_thread.start()
    print("üöÄ Backup autom√°tico iniciado en segundo plano")

def stop_auto_backup():
    """Detener backup autom√°tico"""
    global backup_thread_running
    backup_thread_running = False
    print("üõë Backup autom√°tico detenido")

def resume_training_from_drive():
    """Reanudar entrenamiento desde el √∫ltimo checkpoint en Drive"""
    try:
        backup_dir = Path(yolo_config.drive_backup_dir)
        if not backup_dir.exists():
            print("‚ùå No hay backups disponibles en Drive")
            return None

        # Buscar el backup m√°s reciente
        backup_dirs = [d for d in backup_dir.iterdir() if d.is_dir() and "epoch_" in d.name]
        if not backup_dirs:
            print("‚ùå No se encontraron backups con checkpoints")
            return None

        # Ordenar por fecha de modificaci√≥n
        latest_backup = max(backup_dirs, key=lambda x: x.stat().st_mtime)

        # Buscar el mejor checkpoint
        weights_dir = latest_backup / "weights"
        if weights_dir.exists():
            checkpoints = list(weights_dir.glob("*.pt"))
            if checkpoints:
                # Priorizar best.pt, luego el m√°s reciente
                best_checkpoint = None
                for ckpt in checkpoints:
                    if "best" in ckpt.name:
                        best_checkpoint = ckpt
                        break

                if not best_checkpoint:
                    best_checkpoint = max(checkpoints, key=lambda x: x.stat().st_mtime)

                print(f"‚úÖ Checkpoint encontrado para reanudar: {best_checkpoint}")
                return str(best_checkpoint)

        print("‚ùå No se encontr√≥ checkpoint v√°lido en backups")
        return None

    except Exception as e:
        print(f"‚ùå Error al buscar checkpoint para reanudar: {e}")
        return None

print("‚úÖ Funciones de backup autom√°tico cargadas")

"""## üîÑ Conversi√≥n de Datos COCO a YOLO

"""

# Funci√≥n para convertir COCO a YOLO
def coco_to_yolo(coco_json_path, images_dir, output_dir, class_names):
    """Convierte anotaciones COCO a formato YOLO"""
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Leer archivo COCO
    with open(coco_json_path, 'r') as f:
        coco_data = json.load(f)

    # Crear mapeo de categor√≠as
    cat_id_to_class = {cat['id']: cat['name'] for cat in coco_data['categories']}
    class_to_id = {name: idx for idx, name in enumerate(class_names)}

    # Crear mapeo de im√°genes
    img_id_to_info = {img['id']: img for img in coco_data['images']}

    # Procesar anotaciones
    annotations_by_image = {}
    for ann in coco_data['annotations']:
        img_id = ann['image_id']
        if img_id not in annotations_by_image:
            annotations_by_image[img_id] = []
        annotations_by_image[img_id].append(ann)

    # Convertir cada imagen
    for img_id, img_info in tqdm(img_id_to_info.items(), desc="Convirtiendo a YOLO"):
        img_name = img_info['file_name']
        img_width = img_info['width']
        img_height = img_info['height']

        # Crear archivo de anotaci√≥n YOLO
        txt_name = Path(img_name).stem + '.txt'
        txt_path = output_dir / txt_name

        with open(txt_path, 'w') as f:
            if img_id in annotations_by_image:
                for ann in annotations_by_image[img_id]:
                    cat_name = cat_id_to_class[ann['category_id']]
                    if cat_name in class_to_id:
                        class_id = class_to_id[cat_name]

                        # Convertir bbox [x, y, w, h] a [center_x, center_y, w, h] normalizado
                        x, y, w, h = ann['bbox']
                        center_x = (x + w/2) / img_width
                        center_y = (y + h/2) / img_height
                        norm_w = w / img_width
                        norm_h = h / img_height

                        f.write(f"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\n")

    print(f"‚úÖ Convertido {len(img_id_to_info)} im√°genes a formato YOLO")
    return output_dir

# Preparar datos para conversi√≥n (Unificado con HerdNet)
def prepare_yolo_data():
    """Preparar datos para entrenamiento YOLO seg√∫n el tipo de datos"""

    if data_type == "standard":
        # Usar rutas est√°ndar COCO (igual que HerdNet)
        train_json = TRAIN_ANN_FILE
        val_json = VAL_ANN_FILE
        test_json = TEST_ANN_FILE

        # Verificar que existan
        if not all([train_json.exists(), val_json.exists()]):
            print("‚ùå Faltan archivos de datos est√°ndar COCO")
            return None, None, None

    elif data_type == "groundtruth":
        # Usar rutas groundtruth
        train_json = TRAIN_ANN_FILE_ALT
        val_json = VAL_ANN_FILE_ALT
        test_json = TEST_ANN_FILE_ALT

        # Verificar que existan
        if not all([train_json.exists(), val_json.exists()]):
            print("‚ùå Faltan archivos de datos groundtruth")
            return None, None, None

    else:
        # Estructura legacy - buscar en datasets encontrados
        if not datasets:
            print("‚ùå No hay datasets disponibles")
            return None, None, None

        # Buscar archivos de datos
        train_files = [d for d in datasets if 'train' in d.name.lower()]
        val_files = [d for d in datasets if 'val' in d.name.lower()]
        test_files = [d for d in datasets if 'test' in d.name.lower()]

        train_json = train_files[0] if train_files else None
        val_json = val_files[0] if val_files else None
        test_json = test_files[0] if test_files else None

        if not all([train_json, val_json]):
            print("‚ùå Faltan archivos de datos. Necesitas al menos train y val JSON files.")
            return None, None, None

    print(f"‚úÖ Archivos seleccionados:")
    print(f"  Train: {train_json}")
    print(f"  Val: {val_json}")
    if test_json and test_json.exists():
        print(f"  Test: {test_json}")

    return train_json, val_json, test_json

# Preparar datos
train_json, val_json, test_json = prepare_yolo_data()

if train_json and val_json:
    print("‚úÖ Datos preparados para conversi√≥n")
else:
    print("‚ùå Error preparando datos")

# Convertir datos si est√°n disponibles (ANTES del entrenamiento)
if train_json and val_json:

    # Determinar directorios de im√°genes seg√∫n el tipo de datos
    if data_type == "standard":
        train_img_dir = TRAIN_IMG_DIR
        val_img_dir = VAL_IMG_DIR
        test_img_dir = TEST_IMG_DIR
    elif data_type == "groundtruth":
        train_img_dir = TRAIN_IMG_DIR_ALT
        val_img_dir = VAL_IMG_DIR_ALT
        test_img_dir = TEST_IMG_DIR_ALT
    else:
        # Estructura legacy
        train_img_dir = train_json.parent / "images" if (train_json.parent / "images").exists() else train_json.parent.parent / "train"
        val_img_dir = val_json.parent.parent / "val"
        test_img_dir = None

    # Convertir datos de entrenamiento
    print("üîÑ Convirtiendo datos de entrenamiento...")
    train_yolo_dir = coco_to_yolo(
        train_json,
        train_img_dir,
        '/content/yolo_data/train/labels',
        yolo_config.classes
    )

    # Convertir datos de validaci√≥n
    print("üîÑ Convirtiendo datos de validaci√≥n...")
    val_yolo_dir = coco_to_yolo(
        val_json,
        val_img_dir,
        '/content/yolo_data/val/labels',
        yolo_config.classes
    )

    # Crear directorios de im√°genes
    os.makedirs('/content/yolo_data/train/images', exist_ok=True)
    os.makedirs('/content/yolo_data/val/images', exist_ok=True)

    # Copiar im√°genes
    print("üìÅ Copiando im√°genes...")
    for img_file in tqdm(os.listdir(train_img_dir)):
        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
            src = os.path.join(train_img_dir, img_file)
            dst = os.path.join('/content/yolo_data/train/images', img_file)
            if os.path.exists(src):
                shutil.copy2(src, dst)

    for img_file in tqdm(os.listdir(val_img_dir)):
        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
            src = os.path.join(val_img_dir, img_file)
            dst = os.path.join('/content/yolo_data/val/images', img_file)
            if os.path.exists(src):
                shutil.copy2(src, dst)

    # Copiar im√°genes de test si est√°n disponibles
    if test_img_dir and test_img_dir.exists():
        print("üìÅ Copiando im√°genes de test...")
        os.makedirs('/content/yolo_data/test/images', exist_ok=True)
        for img_file in tqdm(os.listdir(test_img_dir)):
            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):
                src = os.path.join(test_img_dir, img_file)
                dst = os.path.join('/content/yolo_data/test/images', img_file)
                if os.path.exists(src):
                    shutil.copy2(src, dst)

    # Crear archivo de configuraci√≥n YOLO
    test_line = "test: test/images\n" if test_img_dir and test_img_dir.exists() else ""
    yolo_config_content = f"""# Dataset configuration for YOLOv8
path: /content/yolo_data
train: train/images
val: val/images
{test_line}
# Classes
nc: {len(yolo_config.classes)}
names: {yolo_config.classes}
"""

    with open('/content/yolo_data/dataset.yaml', 'w') as f:
        f.write(yolo_config_content)

    print("‚úÖ Conversi√≥n completada")
    print(f"üìä Im√°genes de entrenamiento: {len(os.listdir('/content/yolo_data/train/images'))}")
    print(f"üìä Im√°genes de validaci√≥n: {len(os.listdir('/content/yolo_data/val/images'))}")
    if test_img_dir and test_img_dir.exists():
        print(f"üìä Im√°genes de test: {len(os.listdir('/content/yolo_data/test/images'))}")

else:
    print("‚ùå No se puede convertir sin datos v√°lidos")

"""## üöÄ Entrenamiento Optimizado con Backup Autom√°tico

"""

# Entrenar modelo YOLOv8 V1 con backup autom√°tico
if train_json and val_json:

    print("üöÄ Iniciando entrenamiento YOLOv8 V1 (Optimizado)...")
    print("üî• Caracter√≠sticas V1:")
    print(f"  - Batch size optimizado: {yolo_config.batch_size}")
    print(f"  - Workers optimizados: {yolo_config.workers}")
    print(f"  - Guardado cada {yolo_config.save_period} √©pocas")
    print(f"  - Backup en Drive cada {yolo_config.drive_backup_period} √©pocas")
    print(f"  - Recuperaci√≥n autom√°tica: {yolo_config.resume_training}")

    # Inicializar modelo
    model = YOLO(yolo_config.model)

    # Configurar par√°metros de entrenamiento - OPTIMIZADOS V1
    train_args = {
        'data': '/content/yolo_data/dataset.yaml',
        'epochs': yolo_config.epochs,
        'imgsz': yolo_config.image_size,
        'batch': yolo_config.batch_size,
        'device': yolo_config.device,
        'workers': yolo_config.workers,
        'project': yolo_config.project,
        'name': yolo_config.name,
        'patience': yolo_config.patience,
        'lr0': yolo_config.learning_rate,
        'amp': yolo_config.fp16,
        'save': True,
        'save_period': yolo_config.save_period,  # Consistente: 5 √©pocas
        'val': True,
        'plots': True,
        'verbose': True,
    }

    # Verificar si hay checkpoint para reanudar
    resume_path = None
    if yolo_config.resume_training:
        # Buscar en Colab primero
        weights_dir = Path(f"{yolo_config.project}/{yolo_config.name}/weights")
        if weights_dir.exists():
            checkpoints = list(weights_dir.glob("*.pt"))
            if checkpoints:
                resume_path = str(max(checkpoints, key=lambda x: x.stat().st_mtime))
                print(f"üîÑ Reanudando desde checkpoint local: {resume_path}")
        else:
            # Buscar en Drive
            resume_path = resume_training_from_drive()
            if resume_path:
                print(f"üîÑ Reanudando desde checkpoint en Drive: {resume_path}")

    if resume_path:
        train_args['resume'] = resume_path

    print("üìã Par√°metros de entrenamiento:")
    for key, value in train_args.items():
        print(f"  {key}: {value}")

    # Iniciar backup autom√°tico en segundo plano
    print("üîÑ Iniciando backup autom√°tico en segundo plano...")
    start_auto_backup()

    # Iniciar entrenamiento
    print("üöÄ Iniciando entrenamiento...")
    results = model.train(**train_args)

    # Detener backup autom√°tico
    stop_auto_backup()

    print("‚úÖ Entrenamiento completado!")
    print(f"üìÅ Resultados guardados en: {yolo_config.project}/{yolo_config.name}")

    # Hacer backup final
    print("üîÑ Realizando backup final...")
    backup_to_drive(epoch="final")

else:
    print("‚ùå No se puede entrenar sin datos v√°lidos")

"""## üìä Monitoreo en Tiempo Real

"""

# Funciones de monitoreo en tiempo real
def monitor_training_progress():
    """Monitorear el progreso del entrenamiento en tiempo real"""
    try:
        results_dir = Path(f"{yolo_config.project}/{yolo_config.name}")

        if not results_dir.exists():
            print("‚ùå Directorio de resultados no encontrado")
            return

        # Verificar archivos de resultados
        results_csv = results_dir / "results.csv"
        if results_csv.exists():
            import pandas as pd
            df = pd.read_csv(results_csv)
            if not df.empty:
                latest_epoch = df.iloc[-1]
                print(f"üìä Progreso actual:")
                print(f"  √âpoca: {latest_epoch.get('epoch', 'N/A')}")
                print(f"  mAP: {latest_epoch.get('metrics/mAP50(B)', 'N/A'):.4f}")
                print(f"  Loss: {latest_epoch.get('train/box_loss', 'N/A'):.4f}")
                print(f"  Val Loss: {latest_epoch.get('val/box_loss', 'N/A'):.4f}")

        # Verificar checkpoints
        weights_dir = results_dir / "weights"
        if weights_dir.exists():
            checkpoints = list(weights_dir.glob("*.pt"))
            print(f"üìÅ Checkpoints disponibles: {len(checkpoints)}")
            for ckpt in checkpoints:
                size_mb = ckpt.stat().st_size / (1024 * 1024)
                print(f"  - {ckpt.name} ({size_mb:.1f} MB)")

        # Verificar backups en Drive
        backup_dir = Path(yolo_config.drive_backup_dir)
        if backup_dir.exists():
            backups = list(backup_dir.glob("epoch_*"))
            print(f"üíæ Backups en Drive: {len(backups)}")

    except Exception as e:
        print(f"‚ùå Error en monitoreo: {e}")

def get_training_status():
    """Obtener estado actual del entrenamiento"""
    try:
        results_dir = Path(f"{yolo_config.project}/{yolo_config.name}")

        if not results_dir.exists():
            return "No iniciado"

        # Verificar si hay resultados
        results_csv = results_dir / "results.csv"
        if results_csv.exists():
            import pandas as pd
            df = pd.read_csv(results_csv)
            if not df.empty:
                latest_epoch = df.iloc[-1]['epoch']
                total_epochs = yolo_config.epochs
                progress = (latest_epoch / total_epochs) * 100
                return f"En progreso: {latest_epoch}/{total_epochs} √©pocas ({progress:.1f}%)"

        return "Iniciando"

    except Exception as e:
        return f"Error: {e}"

def estimate_remaining_time():
    """Estimar tiempo restante de entrenamiento"""
    try:
        results_dir = Path(f"{yolo_config.project}/{yolo_config.name}")
        results_csv = results_dir / "results.csv"

        if not results_csv.exists():
            return "No disponible"

        import pandas as pd
        df = pd.read_csv(results_csv)

        if len(df) < 2:
            return "Calculando..."

        # Calcular tiempo promedio por √©poca basado en el n√∫mero de √©pocas
        # Asumir que cada √©poca toma aproximadamente el mismo tiempo
        current_epoch = df.iloc[-1]['epoch']
        remaining_epochs = yolo_config.epochs - current_epoch

        # Estimaci√≥n simple: asumir 2-5 minutos por √©poca
        estimated_minutes = remaining_epochs * 3  # 3 minutos promedio por √©poca

        if estimated_minutes < 60:
            return f"Tiempo estimado restante: {estimated_minutes:.0f} minutos"
        else:
            hours = estimated_minutes / 60
            return f"Tiempo estimado restante: {hours:.1f} horas"

    except Exception as e:
        return f"Error: {e}"

# Funci√≥n para mostrar estado completo
def show_training_status():
    """Mostrar estado completo del entrenamiento"""
    print("=" * 60)
    print("üìä ESTADO DEL ENTRENAMIENTO YOLOv8 V1")
    print("=" * 60)
    print(f"Estado: {get_training_status()}")
    print(f"Tiempo restante: {estimate_remaining_time()}")
    print()
    monitor_training_progress()
    print("=" * 60)

print("‚úÖ Funciones de monitoreo cargadas")

"""## üöÄ Entrenamiento del Modelo

## üéâ ¬°Entrenamiento Completado! - V1 Optimizado

### üìã Resumen del Entrenamiento V1
- **Modelo**: YOLOv8 con configuraci√≥n {yolo_config.model}
- **Tama√±o de imagen**: {yolo_config.image_size}x{yolo_config.image_size}
- **√âpocas**: {yolo_config.epochs}
- **Early Stopping**: {yolo_config.patience} √©pocas de paciencia
- **Batch size optimizado**: {yolo_config.batch_size}
- **Workers optimizados**: {yolo_config.workers}
- **Clases detectadas**: {len(yolo_config.classes)} especies de animales

### üî• **Mejoras V1 Implementadas:**
- ‚úÖ **Guardado autom√°tico en Drive** cada {yolo_config.drive_backup_period} √©pocas
- ‚úÖ **Recuperaci√≥n autom√°tica** de entrenamiento interrumpido
- ‚úÖ **Configuraci√≥n optimizada** para mayor velocidad
- ‚úÖ **Monitoreo en tiempo real** del progreso
- ‚úÖ **Backup autom√°tico** de checkpoints

### üìä Pr√≥ximos Pasos
1. **Evaluar m√©tricas**: Revisar mAP, precision, recall
2. **Ajustar hiperpar√°metros**: Si es necesario mejorar el rendimiento
3. **Exportar modelo**: Convertir a ONNX o TorchScript para deployment
4. **Probar en nuevas im√°genes**: Validar en datos no vistos

### üîß Configuraci√≥n Personalizada
Para modificar par√°metros, edita la clase `YOLOConfig` en la celda de configuraci√≥n:
- Cambiar modelo: `"yolov8s.pt"`, `"yolov8m.pt"`, `"yolov8l.pt"`, `"yolov8x.pt"`
- Ajustar √©pocas: `epochs = 200`
- Modificar tama√±o de imagen: `image_size = 1024`
- Cambiar batch size: `batch_size = 32`

### üìö Recursos Adicionales
- [Documentaci√≥n Ultralytics](https://docs.ultralytics.com/)
- [YOLOv8 Paper](https://arxiv.org/abs/2305.09972)
- [GitHub Ultralytics](https://github.com/ultralytics/ultralytics)

## üöÄ Instrucciones de Uso - V1 Optimizado

### üìã **Antes de Ejecutar:**
1. **Montar Google Drive** (se hace autom√°ticamente)
2. **Verificar que tienes Colab Pro/Pro+** para mejor rendimiento
3. **Configurar datos** en la estructura correcta

### üî• **Caracter√≠sticas V1:**
- **Backup autom√°tico**: Los checkpoints se guardan en Drive cada 10 √©pocas
- **Recuperaci√≥n autom√°tica**: Si se interrumpe, reanuda desde el √∫ltimo checkpoint
- **Configuraci√≥n optimizada**: Batch size 32, workers 8 para mayor velocidad
- **Monitoreo en tiempo real**: Usa `show_training_status()` para ver progreso

### üìä **Comandos √ötiles Durante el Entrenamiento:**
```python
# Ver estado del entrenamiento
show_training_status()

# Hacer backup manual
backup_to_drive()

# Verificar backups en Drive
monitor_training_progress()
```

### ‚ö†Ô∏è **Importante:**
- **NO cierres la pesta√±a** de Colab durante el entrenamiento
- **Los backups se hacen autom√°ticamente** cada 10 √©pocas
- **Si se interrumpe**, simplemente ejecuta de nuevo y reanudar√° autom√°ticamente
- **Los checkpoints se guardan en**: `/content/drive/MyDrive/aerial-wildlife-count-results/yolo_v1/`

### üéØ **Optimizaciones de Velocidad:**
- **Batch size**: 32 (vs 16 original)
- **Workers**: 8 (vs 4 original)  
- **Save period**: 5 √©pocas (vs 10 original)
- **Mixed precision**: Habilitado
- **Early stopping**: 10 √©pocas de paciencia

## üìä Visualizaci√≥n de Resultados
"""

# Cargar el mejor modelo entrenado
best_model_path = f"{yolo_config.project}/{yolo_config.name}/weights/best.pt"
model = YOLO(best_model_path)

# Visualizar curvas de entrenamiento
results_dir = f"{yolo_config.project}/{yolo_config.name}"
if os.path.exists(f"{results_dir}/results.png"):
    display(IPImage(f"{results_dir}/results.png"))

# Mostrar m√©tricas finales
if os.path.exists(f"{results_dir}/results.csv"):
    results_df = pd.read_csv(f"{results_dir}/results.csv")
    print("üìä M√©tricas de entrenamiento:")
    print(results_df.tail(10))

# Mostrar matriz de confusi√≥n
if os.path.exists(f"{results_dir}/confusion_matrix.png"):
    print("\nüìä Matriz de Confusi√≥n:")
    display(IPImage(f"{results_dir}/confusion_matrix.png"))

"""## üîç Inferencia y Pruebas"""

# Realizar inferencia en im√°genes de prueba
if test_json and test_json.exists():
    # Determinar directorio de im√°genes de test seg√∫n el tipo de datos
    if data_type == "standard":
        test_images_dir = TEST_IMG_DIR
    elif data_type == "groundtruth":
        test_images_dir = TEST_IMG_DIR_ALT
    else:
        # Estructura legacy
        test_images_dir = test_json.parent.parent / "test"

    if test_images_dir and test_images_dir.exists():
        test_images = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

        # Seleccionar algunas im√°genes para prueba
        sample_images = test_images[:5]  # Primeras 5 im√°genes

        print(f"üîç Realizando inferencia en {len(sample_images)} im√°genes de prueba...")

        for img_name in sample_images:
            img_path = os.path.join(test_images_dir, img_name)

            # Realizar predicci√≥n
            results = model(img_path, conf=0.5)

            # Mostrar resultado
            for r in results:
                # Guardar imagen con predicciones
                output_path = f"/content/test_results_{img_name}"
                r.save(output_path)

                # Mostrar imagen
                display(IPImage(output_path))

                # Mostrar estad√≠sticas
                print(f"üìä {img_name}: {len(r.boxes)} objetos detectados")
                if len(r.boxes) > 0:
                    for box in r.boxes:
                        class_id = int(box.cls[0])
                        confidence = float(box.conf[0])
                        class_name = yolo_config.classes[class_id]
                        print(f"  - {class_name}: {confidence:.2f}")
                print()
    else:
        print("‚ö†Ô∏è  No se encontr√≥ directorio de im√°genes de test")
else:
    print("‚ö†Ô∏è  No hay datos de test disponibles para inferencia")

"""## üíæ Guardar y Exportar Modelo"""

# Exportar modelo a ONNX para deployment
print("üîÑ Exportando modelo a ONNX...")
onnx_path = model.export(format='onnx', imgsz=yolo_config.image_size)
print(f"‚úÖ Modelo exportado a: {onnx_path}")

# Copiar resultados a Google Drive
drive_results_dir = f"/content/drive/MyDrive/aerial-wildlife-count/results/yolov8_{yolo_config.name}"
os.makedirs(drive_results_dir, exist_ok=True)

# Copiar archivos importantes
files_to_copy = [
    f"{results_dir}/weights/best.pt",
    f"{results_dir}/weights/last.pt",
    f"{results_dir}/results.png",
    f"{results_dir}/confusion_matrix.png",
    f"{results_dir}/results.csv",
    onnx_path
]

for file_path in files_to_copy:
    if os.path.exists(file_path):
        filename = os.path.basename(file_path)
        shutil.copy2(file_path, os.path.join(drive_results_dir, filename))
        print(f"üìÅ Copiado: {filename}")

print(f"‚úÖ Resultados guardados en Google Drive: {drive_results_dir}")

# Mostrar resumen final
print("\nüéâ RESUMEN DEL ENTRENAMIENTO")
print("=" * 50)
print(f"Modelo: {yolo_config.model}")
print(f"√âpocas: {yolo_config.epochs}")
print(f"Tama√±o de imagen: {yolo_config.image_size}")
print(f"Batch size: {yolo_config.batch_size}")
print(f"Clases: {yolo_config.classes}")
print(f"Mejor modelo: {best_model_path}")
print(f"Modelo ONNX: {onnx_path}")
print(f"Resultados en Drive: {drive_results_dir}")