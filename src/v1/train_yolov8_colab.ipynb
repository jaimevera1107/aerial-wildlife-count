{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Entrenamiento YOLOv8 en Google Colab\n",
        "\n",
        "Este notebook entrena un modelo YOLOv8 con Ultralytics en Google Colab para detecci√≥n de vida silvestre a√©rea.\n",
        "\n",
        "## üìã Caracter√≠sticas\n",
        "- **Modelo**: YOLOv8s, YOLOv8m, YOLOv8l, YOLOv8x\n",
        "- **Detecci√≥n autom√°tica de GPU**\n",
        "- **Conversi√≥n autom√°tica COCO a YOLO**\n",
        "- **Visualizaci√≥n de resultados**\n",
        "- **Exportaci√≥n a ONNX/TorchScript**\n",
        "- **An√°lisis de m√©tricas detallado**\n",
        "\n",
        "## üéØ Clases de Animales\n",
        "- Buffalo\n",
        "- Elephant  \n",
        "- Kob\n",
        "- Alcelaphinae\n",
        "- Warthog\n",
        "- Waterbuck\n",
        "\n",
        "## ‚öôÔ∏è Configuraci√≥n por Defecto\n",
        "- **Modelo**: YOLOv8s (balanceado entre velocidad y precisi√≥n)\n",
        "- **Tama√±o de imagen**: 640x640\n",
        "- **√âpocas**: 100\n",
        "- **Batch size**: 16\n",
        "- **Optimizador**: AdamW\n",
        "- **Mixed Precision**: Habilitado\n",
        "\n",
        "## üî¨ Ventajas de YOLOv8\n",
        "- **R√°pido**: Entrenamiento e inferencia eficientes\n",
        "- **Preciso**: Mejor rendimiento que versiones anteriores\n",
        "- **F√°cil de usar**: API simple de Ultralytics\n",
        "- **Flexible**: M√∫ltiples tama√±os de modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîß Instalaci√≥n de Dependencias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instalar dependencias\n",
        "%pip install -q ultralytics pyyaml opencv-python pillow tqdm matplotlib seaborn pandas\n",
        "\n",
        "# Verificar instalaci√≥n\n",
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ Importar Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import yaml\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import shutil\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "from ultralytics import YOLO\n",
        "from google.colab import files, drive\n",
        "from IPython.display import Image as IPImage, display\n",
        "\n",
        "# Configurar matplotlib\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÅ Configuraci√≥n de Datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CONFIGURACI√ìN DE RUTAS PRINCIPALES (Unificado con HerdNet)\n",
        "# ============================================================\n",
        "\n",
        "# Definir la ruta base principal (ajustar seg√∫n el entorno: Drive o local)\n",
        "BASE_DIR = Path(\"/content/drive/MyDrive/aerial-wildlife-count\")\n",
        "\n",
        "# ============================================================\n",
        "# RUTAS DE IM√ÅGENES Y ANOTACIONES (COCO JSON) - Igual que HerdNet\n",
        "# ============================================================\n",
        "\n",
        "# Rutas de los archivos de anotaciones en formato COCO\n",
        "TRAIN_ANN_FILE = BASE_DIR / \"data\" / \"coco\" / \"train\" / \"train_annotations.json\"\n",
        "VAL_ANN_FILE = BASE_DIR / \"data\" / \"coco\" / \"val\" / \"val_annotations.json\"\n",
        "TEST_ANN_FILE = BASE_DIR / \"data\" / \"coco\" / \"test\" / \"test_annotations.json\"\n",
        "\n",
        "# Rutas de las carpetas de im√°genes correspondientes a cada conjunto\n",
        "TRAIN_IMG_DIR = BASE_DIR / \"data\" / \"images\" / \"train\"\n",
        "VAL_IMG_DIR = BASE_DIR / \"data\" / \"images\" / \"val\"\n",
        "TEST_IMG_DIR = BASE_DIR / \"data\" / \"images\" / \"test\"\n",
        "\n",
        "# ============================================================\n",
        "# RUTAS ALTERNATIVAS (Fallback para compatibilidad)\n",
        "# ============================================================\n",
        "\n",
        "# Rutas alternativas si no existe la estructura est√°ndar\n",
        "TRAIN_ANN_FILE_ALT = BASE_DIR / \"data\" / \"groundtruth\" / \"json\" / \"big_size\" / \"train_big_size_A_B_E_K_WH_WB.json\"\n",
        "VAL_ANN_FILE_ALT = BASE_DIR / \"data\" / \"groundtruth\" / \"json\" / \"big_size\" / \"val_big_size_A_B_E_K_WH_WB.json\"\n",
        "TEST_ANN_FILE_ALT = BASE_DIR / \"data\" / \"groundtruth\" / \"json\" / \"big_size\" / \"test_big_size_A_B_E_K_WH_WB.json\"\n",
        "\n",
        "# Rutas alternativas para im√°genes\n",
        "TRAIN_IMG_DIR_ALT = BASE_DIR / \"data\" / \"train\"\n",
        "VAL_IMG_DIR_ALT = BASE_DIR / \"data\" / \"val\"\n",
        "TEST_IMG_DIR_ALT = BASE_DIR / \"data\" / \"test\"\n",
        "\n",
        "# ============================================================\n",
        "# FUNCI√ìN PARA CONFIGURAR DATOS (Unificada con HerdNet)\n",
        "# ============================================================\n",
        "\n",
        "def setup_data():\n",
        "    \"\"\"Configurar datos desde Google Drive con detecci√≥n autom√°tica de estructura\"\"\"\n",
        "    \n",
        "    # Montar Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "    print(\"‚úÖ Google Drive montado\")\n",
        "    \n",
        "    # Verificar si existe la estructura est√°ndar (igual que HerdNet)\n",
        "    if TRAIN_ANN_FILE.exists() and TRAIN_IMG_DIR.exists():\n",
        "        print(\"‚úÖ Datos encontrados (estructura est√°ndar COCO)\")\n",
        "        return str(BASE_DIR), \"standard\"\n",
        "    elif TRAIN_ANN_FILE_ALT.exists() and TRAIN_IMG_DIR_ALT.exists():\n",
        "        print(\"‚úÖ Datos encontrados (estructura alternativa groundtruth)\")\n",
        "        return str(BASE_DIR), \"groundtruth\"\n",
        "    else:\n",
        "        # Buscar en ubicaciones alternativas\n",
        "        drive_path = \"/content/drive/MyDrive\"\n",
        "        possible_paths = [\n",
        "            f\"{drive_path}/aerial-wildlife-count\",\n",
        "            f\"{drive_path}/datasets/aerial-wildlife-count\",\n",
        "            f\"{drive_path}/Colab Notebooks/aerial-wildlife-count\"\n",
        "        ]\n",
        "        \n",
        "        for path in possible_paths:\n",
        "            if os.path.exists(path):\n",
        "                print(f\"‚úÖ Dataset encontrado en ubicaci√≥n alternativa: {path}\")\n",
        "                return path, \"legacy\"\n",
        "        \n",
        "        print(\"‚ùå No se encontr√≥ el dataset en Google Drive\")\n",
        "        return None, None\n",
        "\n",
        "# Configurar datos\n",
        "data_path, data_type = setup_data()\n",
        "if data_path:\n",
        "    print(f\"üìÅ Ruta de datos configurada: {data_path}\")\n",
        "    print(f\"üìä Tipo de datos: {data_type}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  Configura los datos manualmente antes de continuar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä An√°lisis de Datos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funci√≥n para encontrar y analizar datasets (Unificada con HerdNet)\n",
        "def find_and_analyze_datasets():\n",
        "    \"\"\"Encontrar y analizar datasets disponibles seg√∫n el tipo de datos\"\"\"\n",
        "    \n",
        "    if not data_path:\n",
        "        print(\"‚ùå No hay ruta de datos configurada\")\n",
        "        return []\n",
        "    \n",
        "    datasets_found = []\n",
        "    \n",
        "    if data_type == \"standard\":\n",
        "        # Estructura est√°ndar COCO (igual que HerdNet)\n",
        "        datasets_found = [TRAIN_ANN_FILE, VAL_ANN_FILE, TEST_ANN_FILE]\n",
        "        print(\"üìä Usando datasets est√°ndar COCO:\")\n",
        "        print(f\"  Train: {TRAIN_ANN_FILE}\")\n",
        "        print(f\"  Val: {VAL_ANN_FILE}\")\n",
        "        print(f\"  Test: {TEST_ANN_FILE}\")\n",
        "        \n",
        "    elif data_type == \"groundtruth\":\n",
        "        # Estructura alternativa groundtruth\n",
        "        datasets_found = [TRAIN_ANN_FILE_ALT, VAL_ANN_FILE_ALT, TEST_ANN_FILE_ALT]\n",
        "        print(\"üìä Usando datasets groundtruth:\")\n",
        "        print(f\"  Train: {TRAIN_ANN_FILE_ALT}\")\n",
        "        print(f\"  Val: {VAL_ANN_FILE_ALT}\")\n",
        "        print(f\"  Test: {TEST_ANN_FILE_ALT}\")\n",
        "        \n",
        "    else:\n",
        "        # Estructura legacy - buscar archivos JSON\n",
        "        data_root = Path(data_path)\n",
        "        json_patterns = [\n",
        "            \"**/train_*.json\",\n",
        "            \"**/val_*.json\", \n",
        "            \"**/test_*.json\",\n",
        "            \"**/*_big_size_*.json\",\n",
        "            \"**/*_subframes_*.json\"\n",
        "        ]\n",
        "        \n",
        "        for pattern in json_patterns:\n",
        "            for json_file in data_root.glob(pattern):\n",
        "                if json_file.is_file():\n",
        "                    datasets_found.append(json_file)\n",
        "        \n",
        "        print(f\"üìä Datasets encontrados en estructura legacy ({len(datasets_found)}):\")\n",
        "        for i, dataset in enumerate(datasets_found):\n",
        "            print(f\"  {i+1}. {dataset}\")\n",
        "    \n",
        "    # Analizar el primer dataset encontrado\n",
        "    if datasets_found:\n",
        "        sample_data = analyze_dataset(datasets_found[0])\n",
        "        return datasets_found\n",
        "    \n",
        "    return []\n",
        "\n",
        "# Funci√≥n para analizar un dataset COCO\n",
        "def analyze_dataset(json_path):\n",
        "    \"\"\"Analizar estad√≠sticas de un dataset COCO\"\"\"\n",
        "    \n",
        "    with open(json_path, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    print(f\"\\nüìà An√°lisis de {json_path.name}:\")\n",
        "    print(f\"  Im√°genes: {len(data['images'])}\")\n",
        "    print(f\"  Anotaciones: {len(data['annotations'])}\")\n",
        "    print(f\"  Categor√≠as: {len(data['categories'])}\")\n",
        "    \n",
        "    # Estad√≠sticas por categor√≠a\n",
        "    cat_counts = {}\n",
        "    for ann in data['annotations']:\n",
        "        cat_id = ann['category_id']\n",
        "        cat_counts[cat_id] = cat_counts.get(cat_id, 0) + 1\n",
        "    \n",
        "    print(\"\\n  Distribuci√≥n por categor√≠a:\")\n",
        "    for cat in data['categories']:\n",
        "        count = cat_counts.get(cat['id'], 0)\n",
        "        print(f\"    {cat['name']}: {count}\")\n",
        "    \n",
        "    return data\n",
        "\n",
        "# Buscar y analizar datasets\n",
        "datasets = find_and_analyze_datasets()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ‚öôÔ∏è Configuraci√≥n del Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuraci√≥n del entrenamiento\n",
        "class YOLOConfig:\n",
        "    def __init__(self):\n",
        "        # Par√°metros del modelo\n",
        "        self.model = 'yolov8s.pt'  # yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt\n",
        "        self.image_size = 640\n",
        "        self.epochs = 100\n",
        "        self.batch_size = 16  # Ajustar seg√∫n memoria disponible\n",
        "        self.learning_rate = 0.01\n",
        "        self.patience = 10\n",
        "        self.device = 0  # GPU 0\n",
        "        self.workers = 4\n",
        "        self.project = '/content/runs_yolo'\n",
        "        self.name = 'yolo_aerial_wildlife'\n",
        "        self.fp16 = True  # Mixed precision\n",
        "        \n",
        "        # Clases del dataset\n",
        "        self.classes = [\n",
        "            \"Buffalo\", \"Elephant\", \"Kob\", \n",
        "            \"Alcelaphinae\", \"Warthog\", \"Waterbuck\"\n",
        "        ]\n",
        "        \n",
        "    def print_config(self):\n",
        "        print(\"üîß Configuraci√≥n YOLOv8:\")\n",
        "        print(f\"  Modelo: {self.model}\")\n",
        "        print(f\"  Tama√±o de imagen: {self.image_size}\")\n",
        "        print(f\"  √âpocas: {self.epochs}\")\n",
        "        print(f\"  Batch size: {self.batch_size}\")\n",
        "        print(f\"  Learning rate: {self.learning_rate}\")\n",
        "        print(f\"  Dispositivo: {self.device}\")\n",
        "        print(f\"  Mixed precision: {self.fp16}\")\n",
        "\n",
        "# Crear instancia de configuraci√≥n\n",
        "yolo_config = YOLOConfig()\n",
        "yolo_config.print_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÑ Conversi√≥n de Datos COCO a YOLO\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Funci√≥n para convertir COCO a YOLO\n",
        "def coco_to_yolo(coco_json_path, images_dir, output_dir, class_names):\n",
        "    \"\"\"Convierte anotaciones COCO a formato YOLO\"\"\"\n",
        "    output_dir = Path(output_dir)\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    # Leer archivo COCO\n",
        "    with open(coco_json_path, 'r') as f:\n",
        "        coco_data = json.load(f)\n",
        "    \n",
        "    # Crear mapeo de categor√≠as\n",
        "    cat_id_to_class = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "    class_to_id = {name: idx for idx, name in enumerate(class_names)}\n",
        "    \n",
        "    # Crear mapeo de im√°genes\n",
        "    img_id_to_info = {img['id']: img for img in coco_data['images']}\n",
        "    \n",
        "    # Procesar anotaciones\n",
        "    annotations_by_image = {}\n",
        "    for ann in coco_data['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in annotations_by_image:\n",
        "            annotations_by_image[img_id] = []\n",
        "        annotations_by_image[img_id].append(ann)\n",
        "    \n",
        "    # Convertir cada imagen\n",
        "    for img_id, img_info in tqdm(img_id_to_info.items(), desc=\"Convirtiendo a YOLO\"):\n",
        "        img_name = img_info['file_name']\n",
        "        img_width = img_info['width']\n",
        "        img_height = img_info['height']\n",
        "        \n",
        "        # Crear archivo de anotaci√≥n YOLO\n",
        "        txt_name = Path(img_name).stem + '.txt'\n",
        "        txt_path = output_dir / txt_name\n",
        "        \n",
        "        with open(txt_path, 'w') as f:\n",
        "            if img_id in annotations_by_image:\n",
        "                for ann in annotations_by_image[img_id]:\n",
        "                    cat_name = cat_id_to_class[ann['category_id']]\n",
        "                    if cat_name in class_to_id:\n",
        "                        class_id = class_to_id[cat_name]\n",
        "                        \n",
        "                        # Convertir bbox [x, y, w, h] a [center_x, center_y, w, h] normalizado\n",
        "                        x, y, w, h = ann['bbox']\n",
        "                        center_x = (x + w/2) / img_width\n",
        "                        center_y = (y + h/2) / img_height\n",
        "                        norm_w = w / img_width\n",
        "                        norm_h = h / img_height\n",
        "                        \n",
        "                        f.write(f\"{class_id} {center_x:.6f} {center_y:.6f} {norm_w:.6f} {norm_h:.6f}\\n\")\n",
        "    \n",
        "    print(f\"‚úÖ Convertido {len(img_id_to_info)} im√°genes a formato YOLO\")\n",
        "    return output_dir\n",
        "\n",
        "# Preparar datos para conversi√≥n (Unificado con HerdNet)\n",
        "def prepare_yolo_data():\n",
        "    \"\"\"Preparar datos para entrenamiento YOLO seg√∫n el tipo de datos\"\"\"\n",
        "    \n",
        "    if data_type == \"standard\":\n",
        "        # Usar rutas est√°ndar COCO (igual que HerdNet)\n",
        "        train_json = TRAIN_ANN_FILE\n",
        "        val_json = VAL_ANN_FILE\n",
        "        test_json = TEST_ANN_FILE\n",
        "        \n",
        "        # Verificar que existan\n",
        "        if not all([train_json.exists(), val_json.exists()]):\n",
        "            print(\"‚ùå Faltan archivos de datos est√°ndar COCO\")\n",
        "            return None, None, None\n",
        "            \n",
        "    elif data_type == \"groundtruth\":\n",
        "        # Usar rutas groundtruth\n",
        "        train_json = TRAIN_ANN_FILE_ALT\n",
        "        val_json = VAL_ANN_FILE_ALT\n",
        "        test_json = TEST_ANN_FILE_ALT\n",
        "        \n",
        "        # Verificar que existan\n",
        "        if not all([train_json.exists(), val_json.exists()]):\n",
        "            print(\"‚ùå Faltan archivos de datos groundtruth\")\n",
        "            return None, None, None\n",
        "            \n",
        "    else:\n",
        "        # Estructura legacy - buscar en datasets encontrados\n",
        "        if not datasets:\n",
        "            print(\"‚ùå No hay datasets disponibles\")\n",
        "            return None, None, None\n",
        "        \n",
        "        # Buscar archivos de datos\n",
        "        train_files = [d for d in datasets if 'train' in d.name.lower()]\n",
        "        val_files = [d for d in datasets if 'val' in d.name.lower()]\n",
        "        test_files = [d for d in datasets if 'test' in d.name.lower()]\n",
        "        \n",
        "        train_json = train_files[0] if train_files else None\n",
        "        val_json = val_files[0] if val_files else None\n",
        "        test_json = test_files[0] if test_files else None\n",
        "        \n",
        "        if not all([train_json, val_json]):\n",
        "            print(\"‚ùå Faltan archivos de datos. Necesitas al menos train y val JSON files.\")\n",
        "            return None, None, None\n",
        "    \n",
        "    print(f\"‚úÖ Archivos seleccionados:\")\n",
        "    print(f\"  Train: {train_json}\")\n",
        "    print(f\"  Val: {val_json}\")\n",
        "    if test_json and test_json.exists():\n",
        "        print(f\"  Test: {test_json}\")\n",
        "    \n",
        "    return train_json, val_json, test_json\n",
        "\n",
        "# Preparar datos\n",
        "train_json, val_json, test_json = prepare_yolo_data()\n",
        "\n",
        "if train_json and val_json:\n",
        "    print(\"‚úÖ Datos preparados para conversi√≥n\")\n",
        "else:\n",
        "    print(\"‚ùå Error preparando datos\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convertir datos si est√°n disponibles (Adaptado para pipelines)\n",
        "if train_json and val_json:\n",
        "    \n",
        "    # Determinar directorios de im√°genes seg√∫n el tipo de datos\n",
        "    if data_type == \"standard\":\n",
        "        train_img_dir = TRAIN_IMG_DIR\n",
        "        val_img_dir = VAL_IMG_DIR\n",
        "        test_img_dir = TEST_IMG_DIR\n",
        "    elif data_type == \"groundtruth\":\n",
        "        train_img_dir = TRAIN_IMG_DIR_ALT\n",
        "        val_img_dir = VAL_IMG_DIR_ALT\n",
        "        test_img_dir = TEST_IMG_DIR_ALT\n",
        "    else:\n",
        "        # Estructura legacy\n",
        "        train_img_dir = train_json.parent / \"images\" if (train_json.parent / \"images\").exists() else train_json.parent.parent / \"train\"\n",
        "        val_img_dir = val_json.parent.parent / \"val\"\n",
        "        test_img_dir = None\n",
        "    \n",
        "    # Convertir datos de entrenamiento\n",
        "    print(\"üîÑ Convirtiendo datos de entrenamiento...\")\n",
        "    train_yolo_dir = coco_to_yolo(\n",
        "        train_json,\n",
        "        train_img_dir,\n",
        "        '/content/yolo_data/train/labels',\n",
        "        yolo_config.classes\n",
        "    )\n",
        "    \n",
        "    # Convertir datos de validaci√≥n\n",
        "    print(\"üîÑ Convirtiendo datos de validaci√≥n...\")\n",
        "    val_yolo_dir = coco_to_yolo(\n",
        "        val_json,\n",
        "        val_img_dir,\n",
        "        '/content/yolo_data/val/labels',\n",
        "        yolo_config.classes\n",
        "    )\n",
        "    \n",
        "    # Crear directorios de im√°genes\n",
        "    os.makedirs('/content/yolo_data/train/images', exist_ok=True)\n",
        "    os.makedirs('/content/yolo_data/val/images', exist_ok=True)\n",
        "    \n",
        "    # Copiar im√°genes\n",
        "    print(\"üìÅ Copiando im√°genes...\")\n",
        "    for img_file in tqdm(os.listdir(train_img_dir)):\n",
        "        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            src = os.path.join(train_img_dir, img_file)\n",
        "            dst = os.path.join('/content/yolo_data/train/images', img_file)\n",
        "            if os.path.exists(src):\n",
        "                shutil.copy2(src, dst)\n",
        "    \n",
        "    for img_file in tqdm(os.listdir(val_img_dir)):\n",
        "        if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "            src = os.path.join(val_img_dir, img_file)\n",
        "            dst = os.path.join('/content/yolo_data/val/images', img_file)\n",
        "            if os.path.exists(src):\n",
        "                shutil.copy2(src, dst)\n",
        "    \n",
        "    # Copiar im√°genes de test si est√°n disponibles\n",
        "    if test_img_dir and test_img_dir.exists():\n",
        "        print(\"üìÅ Copiando im√°genes de test...\")\n",
        "        os.makedirs('/content/yolo_data/test/images', exist_ok=True)\n",
        "        for img_file in tqdm(os.listdir(test_img_dir)):\n",
        "            if img_file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                src = os.path.join(test_img_dir, img_file)\n",
        "                dst = os.path.join('/content/yolo_data/test/images', img_file)\n",
        "                if os.path.exists(src):\n",
        "                    shutil.copy2(src, dst)\n",
        "    \n",
        "    # Crear archivo de configuraci√≥n YOLO\n",
        "    test_line = \"test: test/images\\n\" if test_img_dir and test_img_dir.exists() else \"\"\n",
        "    yolo_config_content = f\"\"\"# Dataset configuration for YOLOv8\n",
        "path: /content/yolo_data\n",
        "train: train/images\n",
        "val: val/images\n",
        "{test_line}\n",
        "# Classes\n",
        "nc: {len(yolo_config.classes)}\n",
        "names: {yolo_config.classes}\n",
        "\"\"\"\n",
        "    \n",
        "    with open('/content/yolo_data/dataset.yaml', 'w') as f:\n",
        "        f.write(yolo_config_content)\n",
        "    \n",
        "    print(\"‚úÖ Conversi√≥n completada\")\n",
        "    print(f\"üìä Im√°genes de entrenamiento: {len(os.listdir('/content/yolo_data/train/images'))}\")\n",
        "    print(f\"üìä Im√°genes de validaci√≥n: {len(os.listdir('/content/yolo_data/val/images'))}\")\n",
        "    if test_img_dir and test_img_dir.exists():\n",
        "        print(f\"üìä Im√°genes de test: {len(os.listdir('/content/yolo_data/test/images'))}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No se puede convertir sin datos v√°lidos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Entrenamiento del Modelo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Entrenar modelo YOLOv8\n",
        "if train_json and val_json:\n",
        "    \n",
        "    print(\"üöÄ Iniciando entrenamiento YOLOv8...\")\n",
        "    \n",
        "    # Inicializar modelo\n",
        "    model = YOLO(yolo_config.model)\n",
        "    \n",
        "    # Configurar par√°metros de entrenamiento\n",
        "    train_args = {\n",
        "        'data': '/content/yolo_data/dataset.yaml',\n",
        "        'epochs': yolo_config.epochs,\n",
        "        'imgsz': yolo_config.image_size,\n",
        "        'batch': yolo_config.batch_size,\n",
        "        'device': yolo_config.device,\n",
        "        'workers': yolo_config.workers,\n",
        "        'project': yolo_config.project,\n",
        "        'name': yolo_config.name,\n",
        "        'patience': yolo_config.patience,\n",
        "        'lr0': yolo_config.learning_rate,\n",
        "        'amp': yolo_config.fp16,\n",
        "        'save': True,\n",
        "        'save_period': 10,\n",
        "        'val': True,\n",
        "        'plots': True,\n",
        "        'verbose': True,\n",
        "    }\n",
        "    \n",
        "    print(\"üìã Par√°metros de entrenamiento:\")\n",
        "    for key, value in train_args.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "    \n",
        "    # Iniciar entrenamiento\n",
        "    results = model.train(**train_args)\n",
        "    \n",
        "    print(\"‚úÖ Entrenamiento completado!\")\n",
        "    print(f\"üìÅ Resultados guardados en: {yolo_config.project}/{yolo_config.name}\")\n",
        "    \n",
        "else:\n",
        "    print(\"‚ùå No se puede entrenar sin datos v√°lidos\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéâ ¬°Entrenamiento Completado!\n",
        "\n",
        "### üìã Resumen del Entrenamiento\n",
        "- **Modelo**: YOLOv8 con configuraci√≥n {yolo_config.model}\n",
        "- **Tama√±o de imagen**: {yolo_config.image_size}x{yolo_config.image_size}\n",
        "- **√âpocas**: {yolo_config.epochs}\n",
        "- **Clases detectadas**: {len(yolo_config.classes)} especies de animales\n",
        "\n",
        "### üìä Pr√≥ximos Pasos\n",
        "1. **Evaluar m√©tricas**: Revisar mAP, precision, recall\n",
        "2. **Ajustar hiperpar√°metros**: Si es necesario mejorar el rendimiento\n",
        "3. **Exportar modelo**: Convertir a ONNX o TorchScript para deployment\n",
        "4. **Probar en nuevas im√°genes**: Validar en datos no vistos\n",
        "\n",
        "### üîß Configuraci√≥n Personalizada\n",
        "Para modificar par√°metros, edita la clase `YOLOConfig` en la celda de configuraci√≥n:\n",
        "- Cambiar modelo: `\"yolov8s.pt\"`, `\"yolov8m.pt\"`, `\"yolov8l.pt\"`, `\"yolov8x.pt\"`\n",
        "- Ajustar √©pocas: `epochs = 200`\n",
        "- Modificar tama√±o de imagen: `image_size = 1024`\n",
        "- Cambiar batch size: `batch_size = 32`\n",
        "\n",
        "### üìö Recursos Adicionales\n",
        "- [Documentaci√≥n Ultralytics](https://docs.ultralytics.com/)\n",
        "- [YOLOv8 Paper](https://arxiv.org/abs/2305.09972)\n",
        "- [GitHub Ultralytics](https://github.com/ultralytics/ultralytics)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Visualizaci√≥n de Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cargar el mejor modelo entrenado\n",
        "best_model_path = f\"{yolo_config.project}/{yolo_config.name}/weights/best.pt\"\n",
        "model = YOLO(best_model_path)\n",
        "\n",
        "# Visualizar curvas de entrenamiento\n",
        "results_dir = f\"{yolo_config.project}/{yolo_config.name}\"\n",
        "if os.path.exists(f\"{results_dir}/results.png\"):\n",
        "    display(IPImage(f\"{results_dir}/results.png\"))\n",
        "\n",
        "# Mostrar m√©tricas finales\n",
        "if os.path.exists(f\"{results_dir}/results.csv\"):\n",
        "    results_df = pd.read_csv(f\"{results_dir}/results.csv\")\n",
        "    print(\"üìä M√©tricas de entrenamiento:\")\n",
        "    print(results_df.tail(10))\n",
        "\n",
        "# Mostrar matriz de confusi√≥n\n",
        "if os.path.exists(f\"{results_dir}/confusion_matrix.png\"):\n",
        "    print(\"\\nüìä Matriz de Confusi√≥n:\")\n",
        "    display(IPImage(f\"{results_dir}/confusion_matrix.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Inferencia y Pruebas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Realizar inferencia en im√°genes de prueba\n",
        "if test_json and test_json.exists():\n",
        "    # Determinar directorio de im√°genes de test seg√∫n el tipo de datos\n",
        "    if data_type == \"standard\":\n",
        "        test_images_dir = TEST_IMG_DIR\n",
        "    elif data_type == \"groundtruth\":\n",
        "        test_images_dir = TEST_IMG_DIR_ALT\n",
        "    else:\n",
        "        # Estructura legacy\n",
        "        test_images_dir = test_json.parent.parent / \"test\"\n",
        "    \n",
        "    if test_images_dir and test_images_dir.exists():\n",
        "        test_images = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        \n",
        "        # Seleccionar algunas im√°genes para prueba\n",
        "        sample_images = test_images[:5]  # Primeras 5 im√°genes\n",
        "        \n",
        "        print(f\"üîç Realizando inferencia en {len(sample_images)} im√°genes de prueba...\")\n",
        "        \n",
        "        for img_name in sample_images:\n",
        "            img_path = os.path.join(test_images_dir, img_name)\n",
        "            \n",
        "            # Realizar predicci√≥n\n",
        "            results = model(img_path, conf=0.5)\n",
        "            \n",
        "            # Mostrar resultado\n",
        "            for r in results:\n",
        "                # Guardar imagen con predicciones\n",
        "                output_path = f\"/content/test_results_{img_name}\"\n",
        "                r.save(output_path)\n",
        "                \n",
        "                # Mostrar imagen\n",
        "                display(IPImage(output_path))\n",
        "                \n",
        "                # Mostrar estad√≠sticas\n",
        "                print(f\"üìä {img_name}: {len(r.boxes)} objetos detectados\")\n",
        "                if len(r.boxes) > 0:\n",
        "                    for box in r.boxes:\n",
        "                        class_id = int(box.cls[0])\n",
        "                        confidence = float(box.conf[0])\n",
        "                        class_name = yolo_config.classes[class_id]\n",
        "                        print(f\"  - {class_name}: {confidence:.2f}\")\n",
        "                print()\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è  No se encontr√≥ directorio de im√°genes de test\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No hay datos de test disponibles para inferencia\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ Guardar y Exportar Modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exportar modelo a ONNX para deployment\n",
        "print(\"üîÑ Exportando modelo a ONNX...\")\n",
        "onnx_path = model.export(format='onnx', imgsz=yolo_config.image_size)\n",
        "print(f\"‚úÖ Modelo exportado a: {onnx_path}\")\n",
        "\n",
        "# Copiar resultados a Google Drive\n",
        "drive_results_dir = f\"/content/drive/MyDrive/aerial-wildlife-count/results/yolov8_{yolo_config.name}\"\n",
        "os.makedirs(drive_results_dir, exist_ok=True)\n",
        "\n",
        "# Copiar archivos importantes\n",
        "files_to_copy = [\n",
        "    f\"{results_dir}/weights/best.pt\",\n",
        "    f\"{results_dir}/weights/last.pt\",\n",
        "    f\"{results_dir}/results.png\",\n",
        "    f\"{results_dir}/confusion_matrix.png\",\n",
        "    f\"{results_dir}/results.csv\",\n",
        "    onnx_path\n",
        "]\n",
        "\n",
        "for file_path in files_to_copy:\n",
        "    if os.path.exists(file_path):\n",
        "        filename = os.path.basename(file_path)\n",
        "        shutil.copy2(file_path, os.path.join(drive_results_dir, filename))\n",
        "        print(f\"üìÅ Copiado: {filename}\")\n",
        "\n",
        "print(f\"‚úÖ Resultados guardados en Google Drive: {drive_results_dir}\")\n",
        "\n",
        "# Mostrar resumen final\n",
        "print(\"\\nüéâ RESUMEN DEL ENTRENAMIENTO\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Modelo: {yolo_config.model}\")\n",
        "print(f\"√âpocas: {yolo_config.epochs}\")\n",
        "print(f\"Tama√±o de imagen: {yolo_config.image_size}\")\n",
        "print(f\"Batch size: {yolo_config.batch_size}\")\n",
        "print(f\"Clases: {yolo_config.classes}\")\n",
        "print(f\"Mejor modelo: {best_model_path}\")\n",
        "print(f\"Modelo ONNX: {onnx_path}\")\n",
        "print(f\"Resultados en Drive: {drive_results_dir}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
