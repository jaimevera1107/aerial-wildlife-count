{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MZ77v8oQmJTI"
   },
   "outputs": [],
   "source": [
    "# Proyecto ULiège - Detección y Conteo de Fauna con YOLOv8m\n",
    "# Pipeline completo: entrenamiento, evaluación y conversión a centroides (HerdNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zmWrNdgXmOxy"
   },
   "outputs": [],
   "source": [
    "import os, json, random, hashlib\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "import yaml\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import imagehash\n",
    "\n",
    "# Reproducibilidad\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lt7_GtDDmRKW"
   },
   "outputs": [],
   "source": [
    "# 1. Configuración de rutas y entorno\n",
    "DATASET_DIR = Path(\"./dataset\").resolve()\n",
    "GROUNDTRUTH = DATASET_DIR / \"groundtruth\" / \"json\" / \"big_size\"\n",
    "TRAIN_JSON = GROUNDTRUTH / \"train_big_size_A_B_E_K_WH_WB.json\"\n",
    "VAL_JSON = GROUNDTRUTH / \"val_big_size_A_B_E_K_WH_WB.json\"\n",
    "TEST_JSON = GROUNDTRUTH / \"test_big_size_A_B_E_K_WH_WB.json\"\n",
    "TRAIN_IMGS = DATASET_DIR / \"train\"\n",
    "VAL_IMGS = DATASET_DIR / \"val\"\n",
    "TEST_IMGS = DATASET_DIR / \"test\"\n",
    "TRAIN_SUB = DATASET_DIR / \"train_subframes\"\n",
    "EXPERIMENTS_DIR = (DATASET_DIR.parent / \"experimentos_yolo_final\").resolve()\n",
    "EXPERIMENTS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TYAfHkZimTQq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solapamiento entre train_big_size_A_B_E_K_WH_WB.json y val_big_size_A_B_E_K_WH_WB.json: 0 imágenes\n",
      "Solapamiento entre train_big_size_A_B_E_K_WH_WB.json y test_big_size_A_B_E_K_WH_WB.json: 0 imágenes\n",
      "Solapamiento entre val_big_size_A_B_E_K_WH_WB.json y test_big_size_A_B_E_K_WH_WB.json: 0 imágenes\n",
      "Posibles duplicados perceptuales entre train_subframes y val: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Verificación anti-data leakage\n",
    "def check_overlap(json1, json2):\n",
    "    with open(json1) as f1, open(json2) as f2:\n",
    "        set1 = {img[\"file_name\"] for img in json.load(f1)[\"images\"]}\n",
    "        set2 = {img[\"file_name\"] for img in json.load(f2)[\"images\"]}\n",
    "        overlap = set1.intersection(set2)\n",
    "        print(f\"Solapamiento entre {json1.name} y {json2.name}: {len(overlap)} imágenes\")\n",
    "        return overlap\n",
    "\n",
    "def check_hash_duplicates(dir_a, dir_b, sample=300):\n",
    "    \"\"\"Compara hashes perceptuales entre dos carpetas (para detectar subframes duplicados)\"\"\"\n",
    "    imgs_a = list(dir_a.glob(\"*.jpg\"))[:sample]\n",
    "    imgs_b = list(dir_b.glob(\"*.jpg\"))[:sample]\n",
    "    hashes_a = {imagehash.phash(Image.open(p)) for p in imgs_a}\n",
    "    dup = 0\n",
    "    for pb in imgs_b:\n",
    "        hb = imagehash.phash(Image.open(pb))\n",
    "        if any(abs(hb - ha) < 5 for ha in hashes_a):\n",
    "            dup += 1\n",
    "    print(f\"Posibles duplicados perceptuales entre {dir_a.name} y {dir_b.name}: {dup}\")\n",
    "    return dup\n",
    "\n",
    "# Ejecutar verificaciones\n",
    "check_overlap(TRAIN_JSON, VAL_JSON)\n",
    "check_overlap(TRAIN_JSON, TEST_JSON)\n",
    "check_overlap(VAL_JSON, TEST_JSON)\n",
    "check_hash_duplicates(TRAIN_SUB, VAL_IMGS, sample=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "aH2oN_FqmWtn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando conversión de: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\groundtruth\\json\\big_size\\train_big_size_A_B_E_K_WH_WB.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.06s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convirtiendo train_big_size_A_B_E_K_WH_WB.json: 100%|██████████| 6962/6962 [00:00<00:00, 347913.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión completada. Etiquetas guardadas en: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\labels\\train\n",
      "Iniciando conversión de: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\groundtruth\\json\\big_size\\val_big_size_A_B_E_K_WH_WB.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convirtiendo val_big_size_A_B_E_K_WH_WB.json: 100%|██████████| 978/978 [00:00<00:00, 325248.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión completada. Etiquetas guardadas en: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\labels\\val\n",
      "Iniciando conversión de: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\groundtruth\\json\\big_size\\test_big_size_A_B_E_K_WH_WB.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Convirtiendo test_big_size_A_B_E_K_WH_WB.json: 100%|██████████| 2299/2299 [00:00<00:00, 176865.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión completada. Etiquetas guardadas en: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\labels\\test\n",
      "Ajustando estructura de etiquetas para el motor de YOLOv8...\n",
      "\n",
      "Reorganizando conjunto TRAIN...\n",
      "Movidas 928 imágenes a C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\train\\images\n",
      "Movidas 928 etiquetas a C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\train\\labels\n",
      "\n",
      "Reorganizando conjunto VAL...\n",
      "Movidas 111 imágenes a C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\val\\images\n",
      "Movidas 111 etiquetas a C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\val\\labels\n",
      "\n",
      "Reorganizando conjunto TEST...\n",
      "Movidas 258 imágenes a C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\test\\images\n",
      "Movidas 258 etiquetas a C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\test\\labels\n",
      "\n",
      "Ajuste completado. La estructura de carpetas ahora es la esperada por YOLOv8.\n"
     ]
    }
   ],
   "source": [
    "# 3. Conversión de COCO JSON a YOLO TXT\n",
    "\n",
    "# Rutas de salida para las etiquetas YOLO\n",
    "YOLO_LABELS_DIR = DATASET_DIR / \"labels\"\n",
    "YOLO_LABELS_TRAIN = YOLO_LABELS_DIR / \"train\"\n",
    "YOLO_LABELS_VAL = YOLO_LABELS_DIR / \"val\"\n",
    "YOLO_LABELS_TEST = YOLO_LABELS_DIR / \"test\"\n",
    "\n",
    "YOLO_LABELS_TRAIN.mkdir(parents=True, exist_ok=True)\n",
    "YOLO_LABELS_VAL.mkdir(parents=True, exist_ok=True)\n",
    "YOLO_LABELS_TEST.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def convert_coco_to_yolo(json_path, output_dir):\n",
    "    \"\"\"Convierte un archivo COCO JSON a archivos de etiquetas YOLO TXT.\"\"\"\n",
    "    print(f\"Iniciando conversión de: {json_path}\")\n",
    "    coco = COCO(json_path)\n",
    "    \n",
    "    # Mapeo de IDs de imágenes a sus nombres de archivo y dimensiones\n",
    "    img_details = {img['id']: (img['file_name'], img['width'], img['height']) for img in coco.dataset['images']}\n",
    "    \n",
    "    # Obtener todas las anotaciones\n",
    "    annotations = coco.anns.values()\n",
    "    \n",
    "    # Inicializar un diccionario para acumular anotaciones por imagen\n",
    "    yolo_annotations = defaultdict(list)\n",
    "    \n",
    "    for ann in tqdm(annotations, desc=f\"Convirtiendo {json_path.name}\"):\n",
    "        image_id = ann['image_id']\n",
    "        category_id = ann['category_id']\n",
    "        bbox = ann['bbox']\n",
    "        \n",
    "        # Obtener detalles de la imagen\n",
    "        try:\n",
    "            file_name, img_w, img_h = img_details[image_id]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        \n",
    "        # 1. Desnormalizar las coordenadas\n",
    "        x_min, y_min, w, h = bbox\n",
    "        \n",
    "        # 2. Calcular el centro y el tamaño normalizado (formato YOLO)\n",
    "        x_center = (x_min + w / 2) / img_w\n",
    "        y_center = (y_min + h / 2) / img_h\n",
    "        w_norm = w / img_w\n",
    "        h_norm = h / img_h\n",
    "        \n",
    "        # 3. Mapear el ID de categoría (si es necesario)\n",
    "        # category_ids en el JSON corresponden\n",
    "        # al índice de clase (0 a 5) que se usa en el YAML.\n",
    "        # Si no es así, mapearlos aquí.\n",
    "        # Para simplificar y alineado a las 6 clases:\n",
    "        # 1 -> 0, 2 -> 1, ..., 6 -> 5\n",
    "        class_id_yolo = category_id - 1\n",
    "        \n",
    "        yolo_line = f\"{class_id_yolo} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\"\n",
    "        \n",
    "        # El nombre del archivo de etiqueta es el mismo que el nombre de la imagen\n",
    "        # pero con extensión .txt\n",
    "        label_file_name = Path(file_name).stem + \".txt\"\n",
    "        yolo_annotations[label_file_name].append(yolo_line)\n",
    "    \n",
    "    # Escribir los archivos de anotación TXT\n",
    "    for file_name, lines in yolo_annotations.items():\n",
    "        with open(output_dir / file_name, 'w') as f:\n",
    "            f.write(\"\\n\".join(lines))\n",
    "    \n",
    "    print(f\"Conversión completada. Etiquetas guardadas en: {output_dir}\")\n",
    "\n",
    "# Ejecutar la conversión para los conjuntos de Train, Val y Test\n",
    "convert_coco_to_yolo(TRAIN_JSON, YOLO_LABELS_TRAIN)\n",
    "convert_coco_to_yolo(VAL_JSON, YOLO_LABELS_VAL)\n",
    "convert_coco_to_yolo(TEST_JSON, YOLO_LABELS_TEST)\n",
    "\n",
    "# 3.1: Ajuste Físico de la Estructura de Carpetas para YOLOv8\n",
    "\n",
    "print(\"Ajustando estructura de etiquetas para el motor de YOLOv8...\")\n",
    "\n",
    "import shutil\n",
    "\n",
    "def reorganize_dataset_for_yolo(base_dir, labels_source):\n",
    "    \"\"\"\n",
    "    Reorganiza el dataset para que siga la estructura esperada por YOLOv8:\n",
    "    base_dir/\n",
    "        images/  <- mueve aquí las imágenes que están directamente en base_dir\n",
    "        labels/  <- mueve aquí las etiquetas desde labels_source\n",
    "    \"\"\"\n",
    "    images_dir = base_dir / \"images\"\n",
    "    labels_dir = base_dir / \"labels\"\n",
    "    \n",
    "    images_dir.mkdir(parents=True, exist_ok=True)\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Mover imágenes de base_dir/*.jpg a base_dir/images/\n",
    "    moved_images = 0\n",
    "    for img_file in base_dir.glob(\"*.jpg\"):\n",
    "        try:\n",
    "            shutil.move(str(img_file), str(images_dir / img_file.name))\n",
    "            moved_images += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error moviendo imagen {img_file.name}: {e}\")\n",
    "    \n",
    "    # Intentar también con extensión .JPG (mayúscula)\n",
    "    for img_file in base_dir.glob(\"*.JPG\"):\n",
    "        try:\n",
    "            shutil.move(str(img_file), str(images_dir / img_file.name))\n",
    "            moved_images += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error moviendo imagen {img_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"Movidas {moved_images} imágenes a {images_dir}\")\n",
    "    \n",
    "    # Mover etiquetas desde labels_source a base_dir/labels/\n",
    "    moved_labels = 0\n",
    "    for label_file in labels_source.glob(\"*.txt\"):\n",
    "        try:\n",
    "            shutil.move(str(label_file), str(labels_dir / label_file.name))\n",
    "            moved_labels += 1\n",
    "        except Exception as e:\n",
    "            print(f\"Error moviendo etiqueta {label_file.name}: {e}\")\n",
    "    \n",
    "    print(f\"Movidas {moved_labels} etiquetas a {labels_dir}\")\n",
    "    \n",
    "    return moved_images, moved_labels\n",
    "\n",
    "# Reorganizar train\n",
    "print(\"\\nReorganizando conjunto TRAIN...\")\n",
    "reorganize_dataset_for_yolo(TRAIN_IMGS, YOLO_LABELS_TRAIN)\n",
    "\n",
    "# Reorganizar val\n",
    "print(\"\\nReorganizando conjunto VAL...\")\n",
    "reorganize_dataset_for_yolo(VAL_IMGS, YOLO_LABELS_VAL)\n",
    "\n",
    "# Reorganizar test\n",
    "print(\"\\nReorganizando conjunto TEST...\")\n",
    "reorganize_dataset_for_yolo(TEST_IMGS, YOLO_LABELS_TEST)\n",
    "\n",
    "print(\"\\nAjuste completado. La estructura de carpetas ahora es la esperada por YOLOv8.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OkFgDPncmefU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments folder creado en: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\n",
      "data_full.yaml guardado en: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\data_full.yaml\n",
      "\n",
      "Contenido escrito en data_full.yaml:\n",
      "----------------------------------------\n",
      "path: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\n",
      "train: train\\images\n",
      "val: val\\images\n",
      "nc: 6\n",
      "names:\n",
      "- class_0\n",
      "- class_1\n",
      "- class_2\n",
      "- class_3\n",
      "- class_4\n",
      "- class_5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. Archivo data.yaml (dataset completo)\n",
    "\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    DATASET_DIR = Path(\"./dataset\").resolve()\n",
    "except Exception:\n",
    "    DATASET_DIR = Path.cwd() / \"dataset\"\n",
    "\n",
    "# Actualizar rutas para apuntar a las carpetas correctas\n",
    "TRAIN_IMGS_YOLO = DATASET_DIR / \"train\" / \"images\"\n",
    "VAL_IMGS_YOLO = DATASET_DIR / \"val\" / \"images\"\n",
    "TEST_IMGS_YOLO = DATASET_DIR / \"test\" / \"images\"\n",
    "\n",
    "yaml_path = EXPERIMENTS_DIR / \"data_full.yaml\"\n",
    "\n",
    "data_yaml = {\n",
    "    \"path\": str(DATASET_DIR),\n",
    "    \"train\": str(TRAIN_IMGS_YOLO.relative_to(DATASET_DIR)),\n",
    "    \"val\": str(VAL_IMGS_YOLO.relative_to(DATASET_DIR)),\n",
    "    \"nc\": 6,\n",
    "    \"names\": [\"class_0\", \"class_1\", \"class_2\", \"class_3\", \"class_4\", \"class_5\"]\n",
    "}\n",
    "\n",
    "with open(yaml_path, \"w\") as f:\n",
    "    yaml.dump(data_yaml, f, default_flow_style=False, sort_keys=False)\n",
    "\n",
    "print(f\"Experiments folder creado en: {EXPERIMENTS_DIR}\")\n",
    "print(f\"data_full.yaml guardado en: {yaml_path}\")\n",
    "print(f\"\\nContenido escrito en data_full.yaml:\")\n",
    "print(\"-\" * 40)\n",
    "with open(yaml_path) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "2HeZ2aWNmlGh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.214 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.207  Python-3.10.18 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5080 Laptop GPU, 16303MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\data_full.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=1024, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8m.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=ULiege_YOLOv8m_full15, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=6\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3779170  ultralytics.nn.modules.head.Detect           [6, [192, 384, 576]]          \n",
      "Model summary: 169 layers, 25,859,794 parameters, 25,859,778 gradients, 79.1 GFLOPs\n",
      "\n",
      "Transferred 469/475 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 2279.0760.1 MB/s, size: 9464.1 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\train\\labels... 928 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 928/928 2.3Kit/s 0.4s0.2ss\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\train\\labels.cache\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 1406.8549.2 MB/s, size: 8326.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\val\\labels... 111 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 111/111 1.8Kit/s 0.1s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\dataset\\val\\labels.cache\n",
      "Plotting labels to C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/10/14 17:15:09 INFO mlflow.tracking.fluent: Experiment with name 'C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mMLflow: \u001b[0mlogging run_id(7591596c604e455fb114e29cfbf586f3) to runs\\mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mview at http://127.0.0.1:5000 with 'mlflow server --backend-store-uri runs\\mlflow'\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Image sizes 1024 train, 1024 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mC:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50      8.38G      3.054      16.63      1.005         17       1024: 100% ━━━━━━━━━━━━ 116/116 2.5it/s 45.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.9it/s 1.4s0.2s\n",
      "                   all        111        978      0.476      0.231      0.167     0.0498\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50      8.08G      2.964      3.776     0.9612         86       1024: 100% ━━━━━━━━━━━━ 116/116 2.8it/s 40.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.3s0.2s\n",
      "                   all        111        978      0.237      0.172     0.0586     0.0172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50      8.01G      3.105      3.348      0.977         43       1024: 100% ━━━━━━━━━━━━ 116/116 2.9it/s 40.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.1it/s 1.4s0.2s\n",
      "                   all        111        978       0.36      0.218       0.13     0.0358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50      8.12G      3.057      3.153     0.9571        192       1024: 100% ━━━━━━━━━━━━ 116/116 3.0it/s 39.3s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.4s0.2s\n",
      "                   all        111        978      0.519      0.195       0.16     0.0459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50       8.4G       3.11      3.174      0.968         80       1024: 100% ━━━━━━━━━━━━ 116/116 2.9it/s 39.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.4s0.2s\n",
      "                   all        111        978      0.261      0.301      0.171     0.0469\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50      8.06G      3.013      3.021      0.947        210       1024: 100% ━━━━━━━━━━━━ 116/116 2.9it/s 40.1s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.1it/s 1.4s0.2s\n",
      "                   all        111        978      0.589      0.237      0.198     0.0617\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50      8.09G       3.06      3.077     0.9579        189       1024: 100% ━━━━━━━━━━━━ 116/116 3.0it/s 38.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.4s0.2s\n",
      "                   all        111        978      0.589      0.198      0.218     0.0678\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50      7.98G      2.958      2.945     0.9471         70       1024: 100% ━━━━━━━━━━━━ 116/116 3.0it/s 38.2s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.1it/s 1.4s0.2s\n",
      "                   all        111        978      0.586       0.22      0.195     0.0546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50      8.01G      2.937      2.826     0.9439         77       1024: 100% ━━━━━━━━━━━━ 116/116 2.5it/s 46.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.8it/s 1.8s0.3s\n",
      "                   all        111        978      0.564      0.258      0.213     0.0665\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50      8.45G      2.888      2.782     0.9302         54       1024: 100% ━━━━━━━━━━━━ 116/116 2.3it/s 49.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.337      0.328      0.239     0.0797\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50      8.03G      2.863      2.737     0.9298        158       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        111        978      0.555      0.258      0.202     0.0623\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50      8.35G      2.909      2.721     0.9304         53       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        111        978      0.431      0.265      0.228     0.0703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50      8.75G      2.846      2.656     0.9185        131       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        111        978      0.518      0.308      0.256     0.0831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50      8.21G      2.805      2.663     0.9186         46       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 47.9s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        111        978      0.372       0.31      0.267     0.0901\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50      8.32G      2.826      2.604      0.931         31       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.6it/s 1.5s0.2s\n",
      "                   all        111        978      0.682       0.28      0.291     0.0954\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50      8.11G      2.708       2.42     0.9113        142       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 47.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        111        978        0.7      0.263      0.293     0.0987\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50      8.07G      2.711      2.419     0.9142         75       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.6s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.6it/s 1.5s0.2s\n",
      "                   all        111        978      0.348      0.378      0.315      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50      8.29G      2.737      2.473     0.9111         50       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.442      0.311      0.285      0.095\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50      8.03G      2.743      2.589     0.9167         68       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        111        978       0.53      0.284       0.27     0.0898\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50      8.41G      2.679      2.415     0.8987         80       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.2s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.5s0.3s\n",
      "                   all        111        978      0.618      0.272      0.269     0.0959\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50       8.5G      2.655       2.32     0.9021        123       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.3s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.8s0.3s\n",
      "                   all        111        978      0.515      0.287      0.278      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         8G      2.668      2.364      0.906         89       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 47.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.5s0.3s\n",
      "                   all        111        978      0.351      0.388      0.338       0.13\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50       8.1G      2.659       2.35     0.9008         68       1024: 100% ━━━━━━━━━━━━ 116/116 2.5it/s 47.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        111        978      0.527      0.315      0.283        0.1\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50      8.46G      2.574      2.232     0.8939        246       1024: 100% ━━━━━━━━━━━━ 116/116 2.5it/s 47.2s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.4it/s 1.6s0.3s\n",
      "                   all        111        978      0.365      0.369       0.32      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50      8.15G      2.596      2.305     0.8928         70       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 47.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.563      0.315       0.32      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50      8.28G      2.626      2.342     0.8999        164       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 47.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.5it/s 1.6s0.3s\n",
      "                   all        111        978      0.514      0.297        0.3      0.109\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50      8.27G      2.564      2.209     0.8904        125       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 47.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.431      0.356      0.348      0.131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50      8.26G      2.649      2.387     0.8957        157       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.3s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        111        978      0.501        0.3      0.304      0.104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50      8.38G      2.547        2.2     0.8917         83       1024: 100% ━━━━━━━━━━━━ 116/116 2.4it/s 48.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        111        978      0.363      0.314      0.314      0.106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50      8.35G       2.56      2.187     0.8927         83       1024: 100% ━━━━━━━━━━━━ 116/116 2.3it/s 49.5s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.4it/s 1.6s0.3s\n",
      "                   all        111        978      0.443      0.385      0.371      0.141\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50      8.24G      2.486      2.013     0.8847         87       1024: 100% ━━━━━━━━━━━━ 116/116 2.3it/s 49.7s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.4it/s 1.6s0.3s\n",
      "                   all        111        978      0.427      0.396      0.353      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50      8.24G      2.515      2.191     0.8849         72       1024: 100% ━━━━━━━━━━━━ 116/116 2.3it/s 50.4s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        111        978      0.378      0.343      0.314      0.111\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50      8.31G      2.529      2.078     0.8913        118       1024: 100% ━━━━━━━━━━━━ 116/116 2.3it/s 51.2s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.416      0.398      0.336      0.129\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50      8.39G       2.44      1.996     0.8744        148       1024: 100% ━━━━━━━━━━━━ 116/116 2.2it/s 51.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        111        978      0.382      0.415      0.345      0.126\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50      8.34G      2.495      2.075     0.8891         64       1024: 100% ━━━━━━━━━━━━ 116/116 2.2it/s 52.4s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.411      0.376      0.339      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50      8.45G      2.465      2.048     0.8912         24       1024: 100% ━━━━━━━━━━━━ 116/116 2.2it/s 52.8s0.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.401      0.392       0.38      0.138\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50      8.23G      2.459      2.053     0.8813        126       1024: 100% ━━━━━━━━━━━━ 116/116 2.2it/s 53.1s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        111        978      0.527      0.411      0.406      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50      8.85G      2.374      1.912      0.878        157       1024: 100% ━━━━━━━━━━━━ 116/116 2.2it/s 53.3s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.2it/s 1.7s0.3s\n",
      "                   all        111        978      0.501      0.394       0.39      0.147\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50      8.27G      2.385      1.891     0.8751         55       1024: 100% ━━━━━━━━━━━━ 116/116 2.2it/s 53.9s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 3.9it/s 1.8s0.3s\n",
      "                   all        111        978      0.395      0.421      0.372       0.14\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50      8.08G      2.432      1.954     0.8774         95       1024: 100% ━━━━━━━━━━━━ 116/116 2.1it/s 54.0s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.1it/s 1.7s0.3s\n",
      "                   all        111        978      0.532      0.398      0.378      0.145\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50      8.08G      2.377      2.039     0.8848         30       1024: 100% ━━━━━━━━━━━━ 116/116 2.1it/s 54.2s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.3it/s 1.6s0.3s\n",
      "                   all        111        978      0.471      0.407      0.392      0.151\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50      8.08G       2.38      2.081      0.889         76       1024: 100% ━━━━━━━━━━━━ 116/116 2.1it/s 54.5s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s0.3s\n",
      "                   all        111        978      0.499      0.377      0.387      0.143\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50      7.98G      2.379      2.046     0.8727         70       1024: 100% ━━━━━━━━━━━━ 116/116 2.1it/s 54.6s0.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 4.0it/s 1.7s0.3s\n",
      "                   all        111        978      0.529      0.415      0.416      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50      8.06G      2.368      2.041     0.8829         43       1024: 100% ━━━━━━━━━━━━ 116/116 2.5it/s 46.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.3s0.2s\n",
      "                   all        111        978      0.532      0.357      0.382      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50      8.09G       2.39      2.098     0.8817         52       1024: 100% ━━━━━━━━━━━━ 116/116 3.1it/s 37.9s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.3s0.2s\n",
      "                   all        111        978      0.518      0.406      0.409      0.157\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50      8.23G      2.343      2.004     0.8896         42       1024: 100% ━━━━━━━━━━━━ 116/116 3.1it/s 37.7s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.3s0.2s\n",
      "                   all        111        978      0.513      0.418      0.408      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50      8.07G      2.298      1.901     0.8729        102       1024: 100% ━━━━━━━━━━━━ 116/116 3.1it/s 37.6s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.5it/s 1.3s0.2s\n",
      "                   all        111        978      0.543      0.405       0.42      0.159\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50      8.29G      2.366      1.953     0.8806         69       1024: 100% ━━━━━━━━━━━━ 116/116 3.1it/s 37.8s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.2it/s 1.3s0.2s\n",
      "                   all        111        978      0.501      0.425      0.425      0.162\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50      8.14G      2.373      1.978     0.8816         55       1024: 100% ━━━━━━━━━━━━ 116/116 3.1it/s 37.5s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.5it/s 1.3s0.2s\n",
      "                   all        111        978      0.533      0.427      0.419      0.158\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50      8.12G      2.293      1.864     0.8781         23       1024: 100% ━━━━━━━━━━━━ 116/116 3.1it/s 38.0s0.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.5it/s 1.3s0.2s\n",
      "                   all        111        978      0.537      0.439      0.423      0.163\n",
      "\n",
      "50 epochs completed in 0.700 hours.\n",
      "Optimizer stripped from C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15\\weights\\last.pt, 52.1MB\n",
      "Optimizer stripped from C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15\\weights\\best.pt, 52.1MB\n",
      "\n",
      "Validating C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15\\weights\\best.pt...\n",
      "Ultralytics 8.3.207  Python-3.10.18 torch-2.8.0+cu128 CUDA:0 (NVIDIA GeForce RTX 5080 Laptop GPU, 16303MiB)\n",
      "Model summary (fused): 92 layers, 25,843,234 parameters, 0 gradients, 78.7 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 7/7 5.1it/s 1.4s0.2s\n",
      "                   all        111        978      0.538      0.439      0.426      0.163\n",
      "               class_0         29        369      0.614      0.669      0.635      0.209\n",
      "               class_1         11        102      0.386      0.696      0.545      0.222\n",
      "               class_2         22        161       0.62      0.646      0.666      0.254\n",
      "               class_3         14         43       0.49      0.093      0.121     0.0553\n",
      "               class_4          7         39       0.69      0.228       0.33      0.152\n",
      "               class_5         35        264      0.428      0.299       0.26     0.0891\n",
      "Speed: 0.2ms preprocess, 8.2ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15\u001b[0m\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mresults logged to runs\\mlflow\n",
      "\u001b[34m\u001b[1mMLflow: \u001b[0mdisable with 'yolo settings mlflow=False'\n",
      "Pesos guardados en: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\ULiege_YOLOv8m_full15\\weights\\best.pt\n"
     ]
    }
   ],
   "source": [
    "# 5. Entrenamiento YOLOv8\n",
    "model = YOLO(\"yolov8m.pt\")\n",
    "train_params = {\n",
    "    \"data\": str(yaml_path),\n",
    "    \"epochs\": 50,\n",
    "    \"imgsz\": 1024,\n",
    "    \"batch\": 8,\n",
    "    \"project\": str(EXPERIMENTS_DIR),\n",
    "    \"name\": \"ULiege_YOLOv8m_full15\",\n",
    "    \"device\": 0 if torch.cuda.is_available() else \"cpu\",\n",
    "    \"workers\": 8,\n",
    "    \"patience\": 15,\n",
    "    \"save_period\": 10,\n",
    "}\n",
    "\n",
    "results = model.train(**train_params)\n",
    "best_weights = Path(results.save_dir) / \"weights\" / \"best.pt\"\n",
    "print(\"Pesos guardados en:\", best_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "dUP5YZkDmoIr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencia val: 111it [00:16,  6.65it/s]\n",
      "Inferencia val (JPG): 111it [00:15,  7.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "MAE: 4.811 | RMSE: 7.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 6. Evaluación inicial- conjunto de validación: mAP + métricas de conteo (MAE, RMSE)\n",
    "def yolo_predictions_to_coco(model, image_dir, conf=0.25, iou=0.45):\n",
    "    preds = []\n",
    "    for img_path in tqdm(image_dir.glob(\"*.jpg\"), desc=\"Inferencia val\"):\n",
    "        res = model.predict(source=str(img_path), conf=conf, iou=iou, verbose=False)\n",
    "        if not res:\n",
    "            continue\n",
    "        boxes = res[0].boxes\n",
    "        \n",
    "        for b in boxes:\n",
    "            x1, y1, x2, y2 = b.xyxy[0].cpu().numpy()\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            preds.append({\n",
    "                \"image_id\": img_path.name,\n",
    "                \"category_id\": int(b.cls[0]),\n",
    "                \"bbox\": [float(x1), float(y1), float(w), float(h)],\n",
    "                \"score\": float(b.conf[0])\n",
    "            })\n",
    "    \n",
    "    # Intentar también con extensión .JPG (mayúscula)\n",
    "    for img_path in tqdm(image_dir.glob(\"*.JPG\"), desc=\"Inferencia val (JPG)\"):\n",
    "        res = model.predict(source=str(img_path), conf=conf, iou=iou, verbose=False)\n",
    "        if not res:\n",
    "            continue\n",
    "        boxes = res[0].boxes\n",
    "        \n",
    "        for b in boxes:\n",
    "            x1, y1, x2, y2 = b.xyxy[0].cpu().numpy()\n",
    "            w, h = x2 - x1, y2 - y1\n",
    "            preds.append({\n",
    "                \"image_id\": img_path.name,\n",
    "                \"category_id\": int(b.cls[0]),\n",
    "                \"bbox\": [float(x1), float(y1), float(w), float(h)],\n",
    "                \"score\": float(b.conf[0])\n",
    "            })\n",
    "    \n",
    "    return preds\n",
    "\n",
    "def conteo_mae_rmse(gt_json, preds):\n",
    "    coco_gt = COCO(gt_json)\n",
    "    gt_counts = defaultdict(int)\n",
    "    for a in coco_gt.loadAnns(coco_gt.getAnnIds()):\n",
    "        gt_counts[coco_gt.loadImgs(a[\"image_id\"])[0][\"file_name\"]] += 1\n",
    "    pred_counts = defaultdict(int)\n",
    "    for p in preds:\n",
    "        pred_counts[p[\"image_id\"]] += 1\n",
    "    ids = sorted(set(gt_counts) | set(pred_counts))\n",
    "    diffs = np.array([pred_counts[i] - gt_counts[i] for i in ids])\n",
    "    mae = float(np.mean(np.abs(diffs)))\n",
    "    rmse = float(np.sqrt(np.mean(diffs**2)))\n",
    "    return mae, rmse\n",
    "\n",
    "trained_model = YOLO(str(best_weights))\n",
    "preds = yolo_predictions_to_coco(trained_model, VAL_IMGS_YOLO)\n",
    "mae, rmse = conteo_mae_rmse(VAL_JSON, preds)\n",
    "print(f\"MAE: {mae:.3f} | RMSE: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PyEwh-eomrQL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 7. Conversión a centroides (para comparación HerdNet)\n",
    "def centroides_from_bboxes(preds):\n",
    "    pts = defaultdict(list)\n",
    "    for p in preds:\n",
    "        x, y, w, h = p[\"bbox\"]\n",
    "        pts[p[\"image_id\"]].append((x + w/2, y + h/2))\n",
    "    return pts\n",
    "\n",
    "centros_pred = centroides_from_bboxes(preds)\n",
    "img_sample = list(VAL_IMGS_YOLO.glob(\".jpg\"))[0] if list(VAL_IMGS_YOLO.glob(\".jpg\")) else list(VAL_IMGS_YOLO.glob(\"*.JPG\"))[0]\n",
    "img = Image.open(img_sample).convert(\"RGB\")\n",
    "draw = ImageDraw.Draw(img)\n",
    "for (cx, cy) in centros_pred[img_sample.name]:\n",
    "    r = 5\n",
    "    draw.ellipse((cx - r, cy - r, cx + r, cy + r), outline=\"red\", width=2)\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Predicciones convertidas a centroides (comparables con HerdNet)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_Z5F1Kkumthg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Iniciando Evaluación Final con el Conjunto de Test ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inferencia val: 258it [00:43,  5.89it/s]\n",
      "Inferencia val (JPG): 258it [00:35,  7.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      " Resultados de Conteo en el Conjunto de Test (Métricas de HerdNet):\n",
      "MAE (Error Absoluto Medio): 5.229\n",
      "RMSE (Raíz del Error Cuadrático Medio): 10.201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Evaluación Final con el Conjunto de Test (Rendimiento Definitivo)\n",
    "\n",
    "print(\"\\n--- Iniciando Evaluación Final con el Conjunto de Test ---\")\n",
    "\n",
    "# Se reutiliza el 'trained_model' cargado con los mejores pesos.\n",
    "\n",
    "# 1. Generar predicciones en formato COCO JSON para el conjunto de Test\n",
    "# Se utiliza la carpeta de imágenes de Test (TEST_IMGS_YOLO)\n",
    "\n",
    "preds_test = yolo_predictions_to_coco(trained_model, TEST_IMGS_YOLO)\n",
    "\n",
    "# 2. Calcular métricas de Conteo (MAE y RMSE) usando el JSON de Test\n",
    "# Se utiliza el JSON de Ground Truth de Test (TEST_JSON)\n",
    "mae_test, rmse_test = conteo_mae_rmse(TEST_JSON, preds_test)\n",
    "\n",
    "print(f\"\\n Resultados de Conteo en el Conjunto de Test (Métricas de HerdNet):\")\n",
    "print(f\"MAE (Error Absoluto Medio): {mae_test:.3f}\")\n",
    "print(f\"RMSE (Raíz del Error Cuadrático Medio): {rmse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "jrZlhHfCmyW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Generando Salida en Formato Centroides (HerdNet Style) para Test ---\n",
      " Centroides generados para 161 imágenes del Test.\n",
      "Resultado guardado en: C:\\Users\\durle\\anaconda3\\Fauna_Detection\\experimentos_yolo_final\\test_centroides.json\n"
     ]
    }
   ],
   "source": [
    "# 9. Conversión a Centroides para Test (Comparación HerdNet)\n",
    "\n",
    "print(\"--- Generando Salida en Formato Centroides (HerdNet Style) para Test ---\")\n",
    "\n",
    "# 'preds_test' se obtiene de la Celda 8 (Evaluación Final con Test)\n",
    "# La función 'centroides_from_bboxes' definida previamente\n",
    "centroides_test = centroides_from_bboxes(preds_test)\n",
    "\n",
    "# Opcional: Guardar el resultado en un archivo JSON o TXT si es necesario para comparaciones posteriores\n",
    "#El formato de 'centroides_test' será un diccionario: {file_name: [(x_center, y_center), ...]}\n",
    "\n",
    "# Guardar si se necesita el archivo:\n",
    "output_centroid_path = EXPERIMENTS_DIR / \"test_centroides.json\"\n",
    "with open(output_centroid_path, 'w') as f:\n",
    "    # Nota: Es posible que se necesite convertir defaultdict a dict si se usa json.dump\n",
    "    json.dump(centroides_test, f, indent=4)\n",
    "\n",
    "print(f\" Centroides generados para {len(centroides_test)} imágenes del Test.\")\n",
    "print(f\"Resultado guardado en: {output_centroid_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (Fauna Detection)",
   "language": "python",
   "name": "fauna_py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
