{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b0c88af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Todas las rutas fueron encontradas correctamente.\n",
      "Claves principales del JSON COCO:\n",
      "['images', 'annotations', 'categories', '_meta']\n",
      "\n",
      "Ejemplo de imagen:\n",
      "{'id': 1, 'file_name': 'L_07_05_16_DSC00126.JPG', 'orig_file': 'L_07_05_16_DSC00126.JPG', 'width': 6000, 'height': 4000, 'source_stage': 'clean'}\n",
      "\n",
      "Ejemplo de anotación:\n",
      "{'segmentation': [[]], 'area': 2610.0, 'iscrowd': 0, 'image_id': 824, 'bbox': [1072.0, 2068.0, 58.0, 45.0], 'category_id': 6.0, 'id': 1, 'source_stage': 'clean'}\n",
      "\n",
      "Número total de categorías: 6\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# ==========================================================\n",
    "# CONFIGURACIÓN DE RUTAS\n",
    "# ==========================================================\n",
    "\n",
    "# Ruta base de tu dataset (ajusta según tu entorno)\n",
    "BASE_DIR = Path(\"G:\\My Drive\\HerdNet\\data\")\n",
    "\n",
    "# Rutas de las imágenes y anotaciones en formato COCO\n",
    "TRAIN_IMG_DIR = BASE_DIR / \"images\" / \"train\"\n",
    "VAL_IMG_DIR = BASE_DIR / \"images\"/ \"val\"\n",
    "TEST_IMG_DIR = BASE_DIR / \"images\" / \"test\"\n",
    "\n",
    "TRAIN_JSON = BASE_DIR / \"coco\" / \"train\" / \"train_annotations.json\"\n",
    "VAL_JSON = BASE_DIR / \"coco\"/ \"val\" / \"val_annotations.json\"\n",
    "TEST_JSON = BASE_DIR / \"coco\" / \"test\" / \"test_annotations.json\"\n",
    "\n",
    "# ==========================================================\n",
    "# VALIDACIÓN DE EXISTENCIA\n",
    "# ==========================================================\n",
    "\n",
    "for path in [TRAIN_IMG_DIR, VAL_IMG_DIR, TEST_IMG_DIR,\n",
    "             TRAIN_JSON, VAL_JSON, TEST_JSON]:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Ruta no encontrada: {path}\")\n",
    "\n",
    "print(\"Todas las rutas fueron encontradas correctamente.\")\n",
    "\n",
    "# ==========================================================\n",
    "# VISUALIZACIÓN DE ESTRUCTURA COCO (solo verificación)\n",
    "# ==========================================================\n",
    "\n",
    "with open(TRAIN_JSON, \"r\", encoding=\"utf-8\") as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "print(\"Claves principales del JSON COCO:\")\n",
    "print(list(coco_data.keys()))\n",
    "\n",
    "print(f\"\\nEjemplo de imagen:\")\n",
    "print(coco_data[\"images\"][0])\n",
    "\n",
    "print(f\"\\nEjemplo de anotación:\")\n",
    "print(coco_data[\"annotations\"][0])\n",
    "\n",
    "print(f\"\\nNúmero total de categorías:\", len(coco_data[\"categories\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50ba67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class COCODualDataset(Dataset):\n",
    "    \"\"\"\n",
    "    COCODualDataset\n",
    "    ----------------\n",
    "    Dataset compatible with LiteDualNet.\n",
    "    Convierte anotaciones COCO en pares (imagen, (mapa de densidad, etiqueta de clase)).\n",
    "\n",
    "    Propósito\n",
    "    ----------\n",
    "    Generar entradas listas para el modelo de conteo y clasificación:\n",
    "      - Imagen: tensor 3xHxW normalizado [0,1].\n",
    "      - Mapa de densidad: tensor 1xHxW con puntos suavizados.\n",
    "      - Clase: entero que representa la categoría dominante.\n",
    "\n",
    "    Parámetros\n",
    "    ----------\n",
    "    img_dir : str or Path\n",
    "        Directorio que contiene las imágenes.\n",
    "    ann_file : str or Path\n",
    "        Ruta del archivo JSON en formato COCO.\n",
    "    image_size : tuple(int, int)\n",
    "        Tamaño al que se redimensionan las imágenes (alto, ancho).\n",
    "    num_classes : int\n",
    "        Número total de clases (sin incluir fondo).\n",
    "    transform : callable, opcional\n",
    "        Transformaciones (por ejemplo Albumentations o Torchvision).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, img_dir, ann_file, image_size=(512, 512),\n",
    "                 num_classes=6, transform=None):\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.image_size = image_size\n",
    "        self.num_classes = num_classes\n",
    "        self.transform = transform\n",
    "\n",
    "        # Validar existencia de rutas\n",
    "        if not self.img_dir.exists():\n",
    "            raise FileNotFoundError(f\"Image directory not found: {self.img_dir}\")\n",
    "        if not Path(ann_file).exists():\n",
    "            raise FileNotFoundError(f\"Annotation file not found: {ann_file}\")\n",
    "\n",
    "        # Cargar archivo COCO\n",
    "        with open(ann_file, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        self.images = data[\"images\"]\n",
    "        self.annotations = data[\"annotations\"]\n",
    "\n",
    "        # Crear índice de anotaciones por imagen\n",
    "        self.ann_index = {}\n",
    "        for ann in self.annotations:\n",
    "            img_id = ann[\"image_id\"]\n",
    "            if img_id not in self.ann_index:\n",
    "                self.ann_index[img_id] = []\n",
    "            self.ann_index[img_id].append(ann)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Obtener información de la imagen\n",
    "        img_info = self.images[idx]\n",
    "        img_id = img_info[\"id\"]\n",
    "        img_path = self.img_dir / img_info[\"file_name\"]\n",
    "\n",
    "        # Cargar y redimensionar imagen\n",
    "        image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        h_target, w_target = self.image_size\n",
    "        image = cv2.resize(image, (w_target, h_target))\n",
    "\n",
    "        # Crear mapa de densidad vacío\n",
    "        density_map = np.zeros((h_target, w_target), dtype=np.float32)\n",
    "\n",
    "        # Obtener anotaciones de esa imagen\n",
    "        anns = self.ann_index.get(img_id, [])\n",
    "\n",
    "        for ann in anns:\n",
    "            # Convertir bbox a coordenadas del centro\n",
    "            x_center = ann[\"bbox\"][0] + ann[\"bbox\"][2] / 2\n",
    "            y_center = ann[\"bbox\"][1] + ann[\"bbox\"][3] / 2\n",
    "\n",
    "            # Escalar a tamaño redimensionado\n",
    "            x = int(x_center * (w_target / img_info[\"width\"]))\n",
    "            y = int(y_center * (h_target / img_info[\"height\"]))\n",
    "\n",
    "            # Dibujar un pequeño círculo fijo (kernel constante)\n",
    "            if 0 <= x < w_target and 0 <= y < h_target:\n",
    "                cv2.circle(density_map, (x, y), 2, 1, -1)\n",
    "\n",
    "        # Suavizado leve\n",
    "        density_map = cv2.GaussianBlur(density_map, (7, 7), 0)\n",
    "\n",
    "        # Determinar clase dominante o \"background\"\n",
    "        if len(anns) > 0:\n",
    "            classes = [ann[\"category_id\"] for ann in anns]\n",
    "            class_label = max(set(classes), key=classes.count) - 1\n",
    "        else:\n",
    "            class_label = self.num_classes - 1\n",
    "\n",
    "        # Aplicar transformaciones si existen\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=density_map)\n",
    "            image = transformed[\"image\"]\n",
    "            density_map = transformed[\"mask\"]\n",
    "\n",
    "        # Convertir a tensores PyTorch\n",
    "        image = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32) / 255.0\n",
    "        density_map = torch.tensor(density_map, dtype=torch.float32).unsqueeze(0)\n",
    "        class_label = torch.tensor(class_label, dtype=torch.long)\n",
    "\n",
    "        return image, (density_map, class_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b978bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejemplo de salida:\n",
      "Imagen: torch.Size([3, 512, 512])\n",
      "Mapa de densidad: torch.Size([1, 512, 512])\n",
      "Clase: 2\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "IMAGE_SIZE = (512, 512)\n",
    "\n",
    "train_dataset = COCODualDataset(\n",
    "    img_dir=TRAIN_IMG_DIR,\n",
    "    ann_file=TRAIN_JSON,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    num_classes=6\n",
    ")\n",
    "\n",
    "val_dataset = COCODualDataset(\n",
    "    img_dir=VAL_IMG_DIR,\n",
    "    ann_file=VAL_JSON,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    num_classes=6\n",
    ")\n",
    "\n",
    "# Verificación rápida\n",
    "print(\"Ejemplo de salida:\")\n",
    "img, (dmap, cls) = train_dataset[0]\n",
    "print(\"Imagen:\", img.shape)\n",
    "print(\"Mapa de densidad:\", dmap.shape)\n",
    "print(\"Clase:\", cls.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e78a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de lotes (train): 1226\n",
      "Número de lotes (val): 28\n",
      "Número de lotes (test): 65\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# ==========================================================\n",
    "# PARÁMETROS DE ENTRENAMIENTO\n",
    "# ==========================================================\n",
    "\n",
    "# Tamaño de lote (ajústalo según VRAM disponible)\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# Número de clases (ajustado al dataset)\n",
    "NUM_CLASSES = 6\n",
    "\n",
    "# Número de *workers* para carga paralela\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "# ==========================================================\n",
    "# CREACIÓN DE DATASETS\n",
    "# ==========================================================\n",
    "\n",
    "train_dataset = COCODualDataset(\n",
    "    img_dir=TRAIN_IMG_DIR,\n",
    "    ann_file=TRAIN_JSON,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "val_dataset = COCODualDataset(\n",
    "    img_dir=VAL_IMG_DIR,\n",
    "    ann_file=VAL_JSON,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "test_dataset = COCODualDataset(\n",
    "    img_dir=TEST_IMG_DIR,\n",
    "    ann_file=TEST_JSON,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    num_classes=NUM_CLASSES\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# CREACIÓN DE DATALOADERS\n",
    "# ==========================================================\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# ==========================================================\n",
    "# VALIDACIÓN RÁPIDA\n",
    "# ==========================================================\n",
    "\n",
    "print(\"Número de lotes (train):\", len(train_loader))\n",
    "print(\"Número de lotes (val):\", len(val_loader))\n",
    "print(\"Número de lotes (test):\", len(test_loader))\n",
    "\n",
    "# Comprobación de un batch\n",
    "images, (dmap, cls) = next(iter(train_loader))\n",
    "print(\"Batch de imágenes:\", images.shape)\n",
    "print(\"Batch de mapas:\", dmap.shape)\n",
    "print(\"Batch de clases:\", cls.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9203bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LiteDualNet(nn.Module):\n",
    "    \"\"\"\n",
    "    LiteDualNet\n",
    "    ------------\n",
    "    Lightweight CNN for animal counting and classification.\n",
    "    Dual-head architecture:\n",
    "      - Density head: predicts per-pixel density map (counting)\n",
    "      - Classification head: predicts global class label\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=6):\n",
    "        super(LiteDualNet, self).__init__()\n",
    "\n",
    "        # Backbone: simple feature extractor (lightweight)\n",
    "        self.backbone = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(64, 128, 3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            nn.Conv2d(128, 256, 3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        # Head 1: Density regression (1 channel output)\n",
    "        self.density_head = nn.Sequential(\n",
    "            nn.Conv2d(256, 128, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 1, 1)\n",
    "        )\n",
    "\n",
    "        # Head 2: Classification (global features)\n",
    "        self.class_head = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Shared backbone\n",
    "        features = self.backbone(x)\n",
    "        # Density map prediction\n",
    "        density_map = self.density_head(features)\n",
    "        # Class prediction\n",
    "        class_logits = self.class_head(features)\n",
    "        return density_map, class_logits\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
