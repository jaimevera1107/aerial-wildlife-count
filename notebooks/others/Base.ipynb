{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5a2820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§  DEEP LAYER AGGREGATION (DLA) - FULL REIMPLEMENTATION\n",
    "# ============================================================\n",
    "# Clean-room reimplementation faithful to the original DLA paper\n",
    "# and the code by Zhou et al. (2019) used in HerdNet v0.2.1.\n",
    "# No external dependencies, fully self-contained and notebook-safe.\n",
    "# ============================================================\n",
    "\n",
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ðŸ”¹ Utility Layers\n",
    "# ------------------------------------------------------------\n",
    "class Identity(nn.Module):\n",
    "    \"\"\"Identity mapping layer.\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "def fill_up_weights(up: nn.ConvTranspose2d) -> None:\n",
    "    \"\"\"Initialize ConvTranspose2d weights to perform bilinear upsampling.\"\"\"\n",
    "    w = up.weight.data\n",
    "    f = math.ceil(w.size(2) / 2)\n",
    "    c = (2 * f - 1 - f % 2) / (2.0 * f)\n",
    "    for i in range(w.size(2)):\n",
    "        for j in range(w.size(3)):\n",
    "            w[0, 0, i, j] = (1 - abs(i / f - c)) * (1 - abs(j / f - c))\n",
    "    for ch in range(1, w.size(0)):\n",
    "        w[ch, 0, :, :] = w[0, 0, :, :]\n",
    "\n",
    "\n",
    "BatchNorm = nn.BatchNorm2d  # keep same notation as original\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ðŸ”¹ Basic Blocks\n",
    "# ------------------------------------------------------------\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Standard residual block.\"\"\"\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=dilation,\n",
    "                               bias=False, dilation=dilation)\n",
    "        self.bn1 = BatchNorm(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=dilation,\n",
    "                               bias=False, dilation=dilation)\n",
    "        self.bn2 = BatchNorm(planes)\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x, residual=None):\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \"\"\"Bottleneck residual block.\"\"\"\n",
    "    expansion = 2\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        bottle_planes = planes // self.expansion\n",
    "        self.conv1 = nn.Conv2d(inplanes, bottle_planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm(bottle_planes)\n",
    "        self.conv2 = nn.Conv2d(bottle_planes, bottle_planes, kernel_size=3,\n",
    "                               stride=stride, padding=dilation,\n",
    "                               bias=False, dilation=dilation)\n",
    "        self.bn2 = BatchNorm(bottle_planes)\n",
    "        self.conv3 = nn.Conv2d(bottle_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = BatchNorm(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, residual=None):\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BottleneckX(nn.Module):\n",
    "    \"\"\"Bottleneck with grouped convolutions (ResNeXt style).\"\"\"\n",
    "    expansion = 2\n",
    "    cardinality = 32\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, dilation=1):\n",
    "        super(BottleneckX, self).__init__()\n",
    "        cardinality = BottleneckX.cardinality\n",
    "        bottle_planes = planes * cardinality // 32\n",
    "\n",
    "        self.conv1 = nn.Conv2d(inplanes, bottle_planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = BatchNorm(bottle_planes)\n",
    "        self.conv2 = nn.Conv2d(bottle_planes, bottle_planes, kernel_size=3,\n",
    "                               stride=stride, padding=dilation, bias=False,\n",
    "                               dilation=dilation, groups=cardinality)\n",
    "        self.bn2 = BatchNorm(bottle_planes)\n",
    "        self.conv3 = nn.Conv2d(bottle_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = BatchNorm(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x, residual=None):\n",
    "        if residual is None:\n",
    "            residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ðŸ”¹ Root and Tree (hierarchical aggregation)\n",
    "# ------------------------------------------------------------\n",
    "class Root(nn.Module):\n",
    "    \"\"\"Aggregates multiple feature maps from Tree branches.\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, residual):\n",
    "        super(Root, self).__init__()\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels, out_channels, kernel_size=1,\n",
    "            stride=1, bias=False, padding=(kernel_size - 1) // 2\n",
    "        )\n",
    "        self.bn = BatchNorm(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.residual = residual\n",
    "\n",
    "    def forward(self, *x):\n",
    "        children = x\n",
    "        out = self.conv(torch.cat(x, 1))\n",
    "        out = self.bn(out)\n",
    "        if self.residual:\n",
    "            out += children[0]\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Tree(nn.Module):\n",
    "    \"\"\"Recursive hierarchical feature aggregation.\"\"\"\n",
    "    def __init__(self, levels, block, in_channels, out_channels, stride=1,\n",
    "                 level_root=False, root_dim=0, root_kernel_size=1,\n",
    "                 dilation=1, root_residual=False):\n",
    "        super(Tree, self).__init__()\n",
    "        if root_dim == 0:\n",
    "            root_dim = 2 * out_channels\n",
    "        if level_root:\n",
    "            root_dim += in_channels\n",
    "\n",
    "        if levels == 1:\n",
    "            self.tree1 = block(in_channels, out_channels, stride, dilation=dilation)\n",
    "            self.tree2 = block(out_channels, out_channels, 1, dilation=dilation)\n",
    "        else:\n",
    "            self.tree1 = Tree(levels - 1, block, in_channels, out_channels, stride,\n",
    "                              root_dim=0, root_kernel_size=root_kernel_size,\n",
    "                              dilation=dilation, root_residual=root_residual)\n",
    "            self.tree2 = Tree(levels - 1, block, out_channels, out_channels,\n",
    "                              root_dim=root_dim + out_channels,\n",
    "                              root_kernel_size=root_kernel_size,\n",
    "                              dilation=dilation, root_residual=root_residual)\n",
    "        if levels == 1:\n",
    "            self.root = Root(root_dim, out_channels, root_kernel_size, root_residual)\n",
    "\n",
    "        self.level_root = level_root\n",
    "        self.root_dim = root_dim\n",
    "        self.downsample = None\n",
    "        self.project = None\n",
    "        self.levels = levels\n",
    "\n",
    "        if stride > 1:\n",
    "            self.downsample = nn.MaxPool2d(stride, stride=stride)\n",
    "        if in_channels != out_channels:\n",
    "            self.project = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
    "                BatchNorm(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x, residual=None, children=None):\n",
    "        if children is None:\n",
    "            children = []\n",
    "        bottom = self.downsample(x) if self.downsample else x\n",
    "        residual = self.project(bottom) if self.project else bottom\n",
    "        if self.level_root:\n",
    "            children.append(bottom)\n",
    "        x1 = self.tree1(x, residual)\n",
    "        if self.levels == 1:\n",
    "            x2 = self.tree2(x1)\n",
    "            out = self.root(x2, x1, *children)\n",
    "        else:\n",
    "            children.append(x1)\n",
    "            out = self.tree2(x1, children=children)\n",
    "        return out\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ðŸ”¹ DLA (Encoder)\n",
    "# ------------------------------------------------------------\n",
    "class DLA(nn.Module):\n",
    "    \"\"\"Deep Layer Aggregation backbone.\"\"\"\n",
    "    def __init__(self, levels, channels, block=BasicBlock,\n",
    "                 residual_root=False, return_levels=False):\n",
    "        super(DLA, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.return_levels = return_levels\n",
    "\n",
    "        self.base_layer = nn.Sequential(\n",
    "            nn.Conv2d(3, channels[0], kernel_size=7, stride=1, padding=3, bias=False),\n",
    "            BatchNorm(channels[0]),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.level0 = self._make_conv_level(channels[0], channels[0], levels[0])\n",
    "        self.level1 = self._make_conv_level(channels[0], channels[1], levels[1], stride=2)\n",
    "        self.level2 = Tree(levels[2], block, channels[1], channels[2], 2,\n",
    "                           level_root=False, root_residual=residual_root)\n",
    "        self.level3 = Tree(levels[3], block, channels[2], channels[3], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "        self.level4 = Tree(levels[4], block, channels[3], channels[4], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "        self.level5 = Tree(levels[5], block, channels[4], channels[5], 2,\n",
    "                           level_root=True, root_residual=residual_root)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, BatchNorm):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_conv_level(self, inplanes, planes, convs, stride=1, dilation=1):\n",
    "        modules = []\n",
    "        for i in range(convs):\n",
    "            modules.extend([\n",
    "                nn.Conv2d(inplanes, planes, kernel_size=3,\n",
    "                          stride=stride if i == 0 else 1,\n",
    "                          padding=dilation, bias=False, dilation=dilation),\n",
    "                BatchNorm(planes),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ])\n",
    "            inplanes = planes\n",
    "        return nn.Sequential(*modules)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = []\n",
    "        x = self.base_layer(x)\n",
    "        for i in range(6):\n",
    "            x = getattr(self, f\"level{i}\")(x)\n",
    "            y.append(x)\n",
    "        return y if self.return_levels else x\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ðŸ”¹ IDAUp (Iterative Deep Aggregation Upsampling)\n",
    "# ------------------------------------------------------------\n",
    "class IDAUp(nn.Module):\n",
    "    \"\"\"Iterative Deep Aggregation for upsampling feature maps.\"\"\"\n",
    "    def __init__(self, node_kernel, out_dim, channels, up_factors):\n",
    "        super(IDAUp, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.out_dim = out_dim\n",
    "        for i, c in enumerate(channels):\n",
    "            if c == out_dim:\n",
    "                proj = Identity()\n",
    "            else:\n",
    "                proj = nn.Sequential(\n",
    "                    nn.Conv2d(c, out_dim, kernel_size=1, stride=1, bias=False),\n",
    "                    BatchNorm(out_dim),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                )\n",
    "            f = int(up_factors[i])\n",
    "            if f == 1:\n",
    "                up = Identity()\n",
    "            else:\n",
    "                up = nn.ConvTranspose2d(\n",
    "                    out_dim, out_dim, f * 2, stride=f, padding=f // 2,\n",
    "                    output_padding=0, groups=out_dim, bias=False\n",
    "                )\n",
    "                fill_up_weights(up)\n",
    "            setattr(self, f\"proj_{i}\", proj)\n",
    "            setattr(self, f\"up_{i}\", up)\n",
    "\n",
    "        for i in range(1, len(channels)):\n",
    "            node = nn.Sequential(\n",
    "                nn.Conv2d(out_dim * 2, out_dim, kernel_size=node_kernel,\n",
    "                          stride=1, padding=node_kernel // 2, bias=False),\n",
    "                BatchNorm(out_dim),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )\n",
    "            setattr(self, f\"node_{i}\", node)\n",
    "\n",
    "    def forward(self, layers):\n",
    "        assert len(self.channels) == len(layers), f\"{len(self.channels)} vs {len(layers)} layers\"\n",
    "        layers = list(layers)\n",
    "        for i, l in enumerate(layers):\n",
    "            upsample = getattr(self, f\"up_{i}\")\n",
    "            project = getattr(self, f\"proj_{i}\")\n",
    "            layers[i] = upsample(project(l))\n",
    "        x = layers[0]\n",
    "        y = []\n",
    "        for i in range(1, len(layers)):\n",
    "            node = getattr(self, f\"node_{i}\")\n",
    "            x = node(torch.cat([x, layers[i]], 1))\n",
    "            y.append(x)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ðŸ”¹ DLAUp (Full multi-scale upsampling)\n",
    "# ------------------------------------------------------------\n",
    "class DLAUp(nn.Module):\n",
    "    \"\"\"Combines multiple DLA feature maps into a high-resolution output.\"\"\"\n",
    "    def __init__(self, channels, scales=(1, 2, 4, 8, 16), in_channels=None):\n",
    "        super(DLAUp, self).__init__()\n",
    "        if in_channels is None:\n",
    "            in_channels = channels\n",
    "        self.channels = channels\n",
    "        channels = list(channels)\n",
    "        scales = np.array(scales, dtype=int)\n",
    "\n",
    "        for i in range(len(channels) - 1):\n",
    "            j = -i - 2\n",
    "            setattr(self, f\"ida_{i}\",\n",
    "                    IDAUp(3, channels[j], in_channels[j:],\n",
    "                          scales[j:] // scales[j]))\n",
    "            scales[j + 1:] = scales[j]\n",
    "            in_channels[j + 1:] = [channels[j] for _ in channels[j + 1:]]\n",
    "\n",
    "    def forward(self, layers):\n",
    "        layers = list(layers)\n",
    "        assert len(layers) > 1\n",
    "        for i in range(len(layers) - 1):\n",
    "            ida = getattr(self, f\"ida_{i}\")\n",
    "            x, y = ida(layers[-i - 2:])\n",
    "            layers[-i - 1:] = y\n",
    "        return x\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# ðŸ”¹ Factory (dla34)\n",
    "# ------------------------------------------------------------\n",
    "def dla34(pretrained=False, return_levels=True):\n",
    "    \"\"\"Constructs DLA-34 architecture.\"\"\"\n",
    "    model = DLA([1, 1, 1, 2, 2, 1],\n",
    "                [16, 32, 64, 128, 256, 512],\n",
    "                block=BasicBlock,\n",
    "                residual_root=False,\n",
    "                return_levels=return_levels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d2a238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§  HERDNET ARCHITECTURE - FROM SCRATCH REIMPLEMENTATION\n",
    "# ============================================================\n",
    "# Faithful reimplementation of HerdNet v0.2.1 (Delplanque, 2024)\n",
    "# Compatible with the custom DLA + DLAUp backbone defined above.\n",
    "# No external dependencies or registration mechanisms.\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class HerdNet(nn.Module):\n",
    "    \"\"\"\n",
    "    HerdNet architecture\n",
    "    --------------------\n",
    "    Reimplementation of the model introduced by Alexandre Delplanque (v0.2.1),\n",
    "    designed for density-based localization and classification from aerial images.\n",
    "\n",
    "    The model uses a DLA encoder and DLAUp decoder to produce:\n",
    "        - heatmap: localization density map (Sigmoid)\n",
    "        - clsmap : classification map over object categories\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_layers : int\n",
    "        Number of DLA layers. Default = 34.\n",
    "    num_classes : int\n",
    "        Number of output classes (including background). Default = 2.\n",
    "    pretrained : bool\n",
    "        Whether to use pretrained DLA weights. Default = True (ignored in this reimplementation).\n",
    "    down_ratio : int\n",
    "        Downsample ratio (1, 2, 4, 8, 16). Defines starting level in DLA. Default = 2.\n",
    "    head_conv : int\n",
    "        Number of convolutional filters in the head layers. Default = 64.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int = 34,\n",
    "        num_classes: int = 2,\n",
    "        pretrained: bool = True,\n",
    "        down_ratio: int = 2,\n",
    "        head_conv: int = 64\n",
    "    ):\n",
    "        super(HerdNet, self).__init__()\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Sanity check for down_ratio\n",
    "        # --------------------------------------------------------\n",
    "        assert down_ratio in [1, 2, 4, 8, 16], \\\n",
    "            f\"Invalid down_ratio={down_ratio}. Must be one of [1, 2, 4, 8, 16].\"\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.pretrained = pretrained\n",
    "        self.down_ratio = down_ratio\n",
    "        self.head_conv = head_conv\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Determine the level index for decoding\n",
    "        # --------------------------------------------------------\n",
    "        self.first_level = int(np.log2(down_ratio))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Select appropriate DLA backbone\n",
    "        # --------------------------------------------------------\n",
    "        if num_layers == 34:\n",
    "            self.base_0 = dla34(pretrained=pretrained, return_levels=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported DLA depth: {num_layers}\")\n",
    "\n",
    "        self.channels_0 = self.base_0.channels\n",
    "        channels = self.channels_0\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ DLAUp Decoder (multi-scale feature aggregation)\n",
    "        # --------------------------------------------------------\n",
    "        scales = [2 ** i for i in range(len(channels[self.first_level:]))]\n",
    "        self.dla_up = DLAUp(channels[self.first_level:], scales=scales)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Bottleneck convolution\n",
    "        # --------------------------------------------------------\n",
    "        self.bottleneck_conv = nn.Conv2d(\n",
    "            channels[-1], channels[-1],\n",
    "            kernel_size=1, stride=1, padding=0, bias=True\n",
    "        )\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Localization head (density map)\n",
    "        # --------------------------------------------------------\n",
    "        self.loc_head = nn.Sequential(\n",
    "            nn.Conv2d(channels[self.first_level], head_conv,\n",
    "                      kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(head_conv, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.loc_head[-2].bias.data.fill_(0.00)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Classification head (category map)\n",
    "        # --------------------------------------------------------\n",
    "        self.cls_head = nn.Sequential(\n",
    "            nn.Conv2d(channels[-1], head_conv,\n",
    "                      kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(head_conv, num_classes,\n",
    "                      kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        )\n",
    "        self.cls_head[-1].bias.data.fill_(0.00)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Device configuration (auto-detect GPU)\n",
    "        # --------------------------------------------------------\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    # ============================================================\n",
    "    # ðŸ”¹ Forward pass\n",
    "    # ============================================================\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Forward propagation of HerdNet.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Input image tensor of shape (B, 3, H, W).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        heatmap : torch.Tensor\n",
    "            Localization map (1, H', W').\n",
    "        clsmap : torch.Tensor\n",
    "            Classification map (num_classes, h/32, w/32).\n",
    "        \"\"\"\n",
    "        x = x.to(self.device)\n",
    "\n",
    "        # Encoder\n",
    "        encode = self.base_0(x)\n",
    "\n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck_conv(encode[-1])\n",
    "        encode[-1] = bottleneck\n",
    "\n",
    "        # Decoder (multi-scale upsampling)\n",
    "        decode_hm = self.dla_up(encode[self.first_level:])\n",
    "\n",
    "        # Heads\n",
    "        heatmap = self.loc_head(decode_hm)\n",
    "        clsmap = self.cls_head(bottleneck)\n",
    "\n",
    "        return heatmap, clsmap\n",
    "\n",
    "    # ============================================================\n",
    "    # ðŸ”¹ Layer freezing utilities\n",
    "    # ============================================================\n",
    "    def freeze(self, layers: list) -> None:\n",
    "        \"\"\"Freeze all layers mentioned in the input list.\"\"\"\n",
    "        for layer in layers:\n",
    "            self._freeze_layer(layer)\n",
    "\n",
    "    def _freeze_layer(self, layer_name: str) -> None:\n",
    "        for param in getattr(self, layer_name).parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # ============================================================\n",
    "    # ðŸ”¹ Adapt class head\n",
    "    # ============================================================\n",
    "    def reshape_classes(self, num_classes: int) -> None:\n",
    "        \"\"\"Reshape classification head to match a new number of classes.\"\"\"\n",
    "        self.cls_head[-1] = nn.Conv2d(\n",
    "            self.head_conv, num_classes,\n",
    "            kernel_size=1, stride=1, padding=0, bias=True\n",
    "        )\n",
    "        self.cls_head[-1].bias.data.fill_(0.00)\n",
    "        self.num_classes = num_classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0c7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§© SEMSEG-DLA (Semantic Segmentation Variant)\n",
    "# ============================================================\n",
    "# Faithful reimplementation of the original SemSegDLA (Delplanque, 2024)\n",
    "# Standalone, compatible with our reimplemented DLA and DLAUp modules.\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SemSegDLA(nn.Module):\n",
    "    \"\"\"\n",
    "    Semantic Segmentation version of DLA with multi-channel output.\n",
    "\n",
    "    This architecture is a simplified variant of HerdNet focused only\n",
    "    on producing dense localization heatmaps (no classification head).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_layers : int\n",
    "        Number of DLA layers. Default = 34.\n",
    "    num_classes : int\n",
    "        Number of output classes (background included). Default = 2.\n",
    "    pretrained : bool\n",
    "        Whether to use pretrained DLA weights. Default = True (ignored here).\n",
    "    down_ratio : int\n",
    "        Downsampling ratio (1, 2, 4, 8, or 16). Default = 2.\n",
    "    head_conv : int\n",
    "        Number of channels in the head convolution layers. Default = 64.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers: int = 34,\n",
    "        num_classes: int = 2,\n",
    "        pretrained: bool = True,\n",
    "        down_ratio: int = 2,\n",
    "        head_conv: int = 64\n",
    "    ):\n",
    "        super(SemSegDLA, self).__init__()\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Sanity check for down_ratio\n",
    "        # --------------------------------------------------------\n",
    "        assert down_ratio in [1, 2, 4, 8, 16], \\\n",
    "            f\"Downsample ratio must be one of [1, 2, 4, 8, 16], got {down_ratio}.\"\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.down_ratio = down_ratio\n",
    "        self.head_conv = head_conv\n",
    "        self.pretrained = pretrained\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Compute first level from down_ratio\n",
    "        # --------------------------------------------------------\n",
    "        self.first_level = int(np.log2(down_ratio))\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Select appropriate DLA backbone\n",
    "        # --------------------------------------------------------\n",
    "        if num_layers == 34:\n",
    "            self.base = dla34(pretrained=pretrained, return_levels=True)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported DLA depth: {num_layers}\")\n",
    "\n",
    "        channels = self.base.channels\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Multi-scale decoder\n",
    "        # --------------------------------------------------------\n",
    "        scales = [2 ** i for i in range(len(channels[self.first_level:]))]\n",
    "        self.dla_up = DLAUp(channels[self.first_level:], scales=scales)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Heatmap head (Sigmoid output)\n",
    "        # --------------------------------------------------------\n",
    "        self.hm_head = nn.Sequential(\n",
    "            nn.Conv2d(channels[self.first_level], head_conv,\n",
    "                      kernel_size=3, padding=1, bias=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(head_conv, num_classes - 1,\n",
    "                      kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Optional: initialize last conv bias\n",
    "        # self.hm_head[-2].bias.data.fill_(0.00)\n",
    "\n",
    "        # --------------------------------------------------------\n",
    "        # ðŸ”¹ Device configuration (auto-detect GPU)\n",
    "        # --------------------------------------------------------\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.to(self.device)\n",
    "\n",
    "    # ============================================================\n",
    "    # ðŸ”¹ Forward pass\n",
    "    # ============================================================\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"Forward propagation.\"\"\"\n",
    "        x = x.to(self.device)\n",
    "        encode = self.base(x)\n",
    "        decode_hm = self.dla_up(encode[self.first_level:])\n",
    "        heatmap = self.hm_head(decode_hm)\n",
    "        return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a49a18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# âš™ï¸ MODEL UTILITIES AND LOSS WRAPPER - FROM SCRATCH\n",
    "# ============================================================\n",
    "# Faithful reimplementation of load_model, count_parameters,\n",
    "# and LossWrapper (Delplanque, 2024) for standalone use.\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "from typing import Union, Tuple, List, Optional\n",
    "\n",
    "\n",
    "def load_model(model: torch.nn.Module, pth_path: str) -> torch.nn.Module:\n",
    "    \"\"\"\n",
    "    Load model parameters from a .pth checkpoint file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The model whose state_dict will be updated.\n",
    "    pth_path : str\n",
    "        Path to the checkpoint (.pth) file.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    torch.nn.Module\n",
    "        Model with loaded parameters.\n",
    "    \"\"\"\n",
    "    map_location = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    checkpoint = torch.load(pth_path, map_location=map_location)\n",
    "\n",
    "    if \"model_state_dict\" in checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    else:\n",
    "        model.load_state_dict(checkpoint)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def count_parameters(model: torch.nn.Module) -> Tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Compute and print the number of trainable and total parameters in the model.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The model to inspect.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (trainable_params, total_params) : tuple of int\n",
    "    \"\"\"\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "    print(f\"TRAINABLE PARAMETERS: {trainable_params}\")\n",
    "    print(f\"TOTAL PARAMETERS: {total_params}\")\n",
    "\n",
    "    return trainable_params, total_params\n",
    "\n",
    "\n",
    "class LossWrapper(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    nn.Module wrapper to integrate loss computation directly within a model.\n",
    "\n",
    "    This wrapper allows any model to output both predictions and corresponding\n",
    "    loss values, depending on the selected mode.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        The model to wrap.\n",
    "    losses : list of dict\n",
    "        List of dictionaries containing:\n",
    "            - 'idx': index of model output to use,\n",
    "            - 'idy': index of target tensor to use,\n",
    "            - 'name': name of the loss term,\n",
    "            - 'lambda': regularization multiplier,\n",
    "            - 'loss': torch.nn.Module loss function.\n",
    "    mode : str\n",
    "        Output mode. Must be one of:\n",
    "            - 'loss_only' : return only the loss dictionary.\n",
    "            - 'preds_only': return only model predictions.\n",
    "            - 'both'      : return both predictions and loss dict.\n",
    "            - 'module'    : during training â†’ return loss dict;\n",
    "                            during eval â†’ return both outputs.\n",
    "        Default = 'module'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        losses: List[dict],\n",
    "        mode: str = \"module\"\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        assert isinstance(losses, list), \"losses must be a list of dictionaries.\"\n",
    "        assert mode in [\"loss_only\", \"preds_only\", \"both\", \"module\"], (\n",
    "            f\"Invalid mode '{mode}'. Expected one of \"\n",
    "            \"['loss_only', 'preds_only', 'both', 'module'].\"\n",
    "        )\n",
    "\n",
    "        self.model = model\n",
    "        self.losses = losses\n",
    "        self.output_mode = mode\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        target: Optional[Union[torch.Tensor, List[torch.Tensor]]] = None\n",
    "    ) -> Union[Tuple[torch.Tensor, dict], dict, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Forward propagation with optional loss computation.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Model input.\n",
    "        target : torch.Tensor or list of torch.Tensor, optional\n",
    "            Ground truth data for computing loss terms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Depends on mode:\n",
    "            - 'loss_only'  â†’ loss dict\n",
    "            - 'preds_only' â†’ model predictions\n",
    "            - 'both'       â†’ (preds, loss dict)\n",
    "            - 'module'     â†’ loss dict (train mode) or (preds, loss dict) (eval mode)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            output = self.model(x)\n",
    "        except ValueError:\n",
    "            # Some models expect target in forward (rare case)\n",
    "            output = self.model(x, target)\n",
    "\n",
    "        # Ensure output and target are lists\n",
    "        outputs_used = output if isinstance(output, (list, tuple)) else [output]\n",
    "        targets_used = target if isinstance(target, (list, tuple)) else [target]\n",
    "\n",
    "        # Compute individual losses\n",
    "        loss_dict = {}\n",
    "        if target is not None:\n",
    "            for loss_def in self.losses:\n",
    "                i = loss_def[\"idx\"]\n",
    "                j = loss_def[\"idy\"]\n",
    "                reg = loss_def[\"lambda\"]\n",
    "                loss_fn = loss_def[\"loss\"]\n",
    "                loss_val = loss_fn(outputs_used[i], targets_used[j])\n",
    "                loss_dict[loss_def[\"name\"]] = reg * loss_val\n",
    "\n",
    "        # Output logic according to mode\n",
    "        if self.output_mode == \"module\":\n",
    "            if self.training:\n",
    "                # Training: only loss dict\n",
    "                if not loss_dict:\n",
    "                    loss_dict = output\n",
    "                return loss_dict\n",
    "            else:\n",
    "                # Evaluation: predictions and loss dict\n",
    "                return output, loss_dict\n",
    "\n",
    "        elif self.output_mode == \"loss_only\":\n",
    "            return loss_dict\n",
    "\n",
    "        elif self.output_mode == \"preds_only\":\n",
    "            return output\n",
    "\n",
    "        elif self.output_mode == \"both\":\n",
    "            return output, loss_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "503cc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸŽ² RANDOMNESS & REPRODUCIBILITY UTILITIES\n",
    "# ============================================================\n",
    "# Faithful reimplementation of set_seed and seed_worker\n",
    "# (Delplanque, 2024). Ensures deterministic training behavior\n",
    "# across CPU, GPU, NumPy, and DataLoader workers.\n",
    "# ============================================================\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Set global random seed for reproducibility across libraries.\n",
    "\n",
    "    This function initializes deterministic states for Python,\n",
    "    NumPy, and PyTorch (CPU and GPU), helping to ensure consistent\n",
    "    behavior across runs.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Perfect reproducibility is not guaranteed due to inherent\n",
    "    non-determinism in some CUDA operations.\n",
    "    See: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Random seed to set globally.\n",
    "    \"\"\"\n",
    "    # Python random\n",
    "    random.seed(seed)\n",
    "\n",
    "    # NumPy random\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    # PyTorch (CPU)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # PyTorch (GPU)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    # Deterministic behavior configuration\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def seed_worker(worker_id: int) -> None:\n",
    "    \"\"\"\n",
    "    Set deterministic seed for PyTorch DataLoader workers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    worker_id : int\n",
    "        The worker ID provided automatically by DataLoader.\n",
    "    \"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2 ** 32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9b2e6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# âš™ï¸ ADALOSS MODULE - FROM SCRATCH\n",
    "# ============================================================\n",
    "# Faithful reimplementation of Adaloss (Delplanque, 2024).\n",
    "# Adaptive loss weighting for dynamic end-transform parameters.\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class Adaloss:\n",
    "    \"\"\"\n",
    "    Adaptive Loss Optimizer (Adaloss)\n",
    "    ---------------------------------\n",
    "    Adjusts a scalar dataset parameter dynamically during training\n",
    "    based on the variance ratio of recent loss windows.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    param : torch.Tensor\n",
    "        Parameter tensor to adapt (e.g., end-transform weight).\n",
    "    w : int\n",
    "        Sliding window size for variance estimation. Default = 3.\n",
    "    rho : float\n",
    "        Adaptation rate (0â€“1). Default = 0.9.\n",
    "    delta_max : float\n",
    "        Maximum allowed update step magnitude. Default = 5.0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        param: torch.Tensor,\n",
    "        w: int = 3,\n",
    "        rho: float = 0.9,\n",
    "        delta_max: float = 5.0\n",
    "    ) -> None:\n",
    "\n",
    "        assert isinstance(param, torch.Tensor), \\\n",
    "            f\"param must be a torch.Tensor, got {type(param)}\"\n",
    "\n",
    "        assert isinstance(w, int) and w > 0, \\\n",
    "            \"w must be a positive integer\"\n",
    "\n",
    "        assert 0.0 <= rho <= 1.0, \\\n",
    "            f\"rho must be between 0.0 and 1.0, got {rho}\"\n",
    "\n",
    "        self.param = param\n",
    "        self.w = w\n",
    "        self.rho = rho\n",
    "        self.delta_max = delta_max\n",
    "\n",
    "        self._step = 1\n",
    "        self._losses = []\n",
    "        self.loss_history = []\n",
    "        self.var_history = []\n",
    "        self.param_tracker = []\n",
    "\n",
    "    def step(self) -> None:\n",
    "        \"\"\"Perform one Adaloss adaptation step.\"\"\"\n",
    "        self._update_losses()\n",
    "        self._update_vars()\n",
    "\n",
    "        if self._step > self.w:\n",
    "            delta = self._compute_delta()\n",
    "            delta_clamped = torch.clamp(delta, -self.delta_max, self.delta_max)\n",
    "            self.param.add_(delta_clamped)\n",
    "\n",
    "        self._step += 1\n",
    "        self.param_tracker.append(torch.clone(self.param))\n",
    "\n",
    "    def feed(self, loss: torch.Tensor) -> None:\n",
    "        \"\"\"Feed the current loss value for tracking.\"\"\"\n",
    "        self._losses.append(loss.detach())\n",
    "\n",
    "    def _update_losses(self) -> None:\n",
    "        \"\"\"Update rolling window of losses.\"\"\"\n",
    "        self.loss_history.append(torch.stack(self._losses))\n",
    "        self._losses = []\n",
    "\n",
    "    def _update_vars(self) -> None:\n",
    "        \"\"\"Compute and store loss variance for current window.\"\"\"\n",
    "        if self._step >= self.w:\n",
    "            window_losses = torch.cat(self.loss_history[self._step - self.w:self._step])\n",
    "            variance = torch.var(window_losses)\n",
    "            self.var_history.append(variance)\n",
    "\n",
    "    def _compute_delta(self) -> torch.Tensor:\n",
    "        \"\"\"Compute adaptive delta from variance ratio.\"\"\"\n",
    "        if len(self.var_history) < 2:\n",
    "            return torch.tensor(0.0)\n",
    "        ratio = self.var_history[-2] / (self.var_history[-1] + 1e-8)\n",
    "        return self.rho * (1.0 - ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643334f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# âš™ï¸ TRAINER MODULE - FULL STANDALONE VERSION\n",
    "# ============================================================\n",
    "# Faithful reimplementation of Trainer and FasterRCNNTrainer\n",
    "# (Delplanque, 2024), stripped of animaloc dependencies.\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque, defaultdict\n",
    "from typing import Any, List, Optional, Union, Callable\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”§ UTILS: SmoothedValue\n",
    "# ============================================================\n",
    "class SmoothedValue:\n",
    "    \"\"\"Track a series of values and provide smoothed averages.\"\"\"\n",
    "\n",
    "    def __init__(self, window_size: int = 20, fmt: str = \"{median:.4f} ({global_avg:.4f})\"):\n",
    "        self.deque = deque(maxlen=window_size)\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "        self.fmt = fmt\n",
    "\n",
    "    def update(self, value: float, n: int = 1):\n",
    "        self.deque.append(value)\n",
    "        self.count += n\n",
    "        self.total += value * n\n",
    "\n",
    "    @property\n",
    "    def median(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.median().item() if len(d) > 0 else 0.0\n",
    "\n",
    "    @property\n",
    "    def avg(self):\n",
    "        d = torch.tensor(list(self.deque))\n",
    "        return d.mean().item() if len(d) > 0 else 0.0\n",
    "\n",
    "    @property\n",
    "    def global_avg(self):\n",
    "        return self.total / max(1, self.count)\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.fmt.format(median=self.median, global_avg=self.global_avg)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”§ UTILS: reduce_dict (monoprocess replacement)\n",
    "# ============================================================\n",
    "def reduce_dict(input_dict):\n",
    "    \"\"\"Return same dict (for single process execution).\"\"\"\n",
    "    return input_dict\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”§ UTILS: CustomLogger\n",
    "# ============================================================\n",
    "class CustomLogger:\n",
    "    \"\"\"\n",
    "    Minimal logger replicating Delplanque's behavior.\n",
    "    Tracks metrics and prints progress with defined frequency.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, delimiter=\" \", filename=None, work_dir=\".\", csv=False):\n",
    "        self.meters = defaultdict(SmoothedValue)\n",
    "        self.delimiter = delimiter\n",
    "        self.filename = filename\n",
    "        self.work_dir = work_dir\n",
    "        self.csv = csv\n",
    "        self.filepath = None\n",
    "        if csv and filename:\n",
    "            self.filepath = os.path.join(work_dir, f\"{filename}.csv\")\n",
    "            with open(self.filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(\"step,loss\\n\")\n",
    "\n",
    "    def update(self, **kwargs):\n",
    "        for k, v in kwargs.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                v = v.item()\n",
    "            self.meters[k].update(v)\n",
    "\n",
    "    def __str__(self):\n",
    "        metrics = [f\"{k}: {v}\" for k, v in self.meters.items()]\n",
    "        return self.delimiter.join(metrics)\n",
    "\n",
    "    def log_every(self, iterable, print_freq, header=\"\"):\n",
    "        i = 0\n",
    "        start_time = time.time()\n",
    "        for obj in iterable:\n",
    "            yield obj\n",
    "            if i % print_freq == 0:\n",
    "                print(f\"{header} [{i}/{len(iterable)}] {self}\")\n",
    "            i += 1\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"{header} Total time: {total_time:.2f}s\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§  TRAINER BASE CLASS\n",
    "# ============================================================\n",
    "class Trainer:\n",
    "    \"\"\"Base class for supervised training of models.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        train_dataloader: torch.utils.data.DataLoader,\n",
    "        optimizer: torch.optim.Optimizer,\n",
    "        num_epochs: int,\n",
    "        lr_milestones: Optional[List[int]] = None,\n",
    "        auto_lr: Union[bool, dict] = False,\n",
    "        adaloss: Optional[Any] = None,\n",
    "        val_dataloader: Optional[torch.utils.data.DataLoader] = None,\n",
    "        evaluator: Optional[Any] = None,\n",
    "        vizual_fn: Optional[Callable] = None,\n",
    "        work_dir: Optional[str] = None,\n",
    "        device_name: str = \"cuda\",\n",
    "        print_freq: int = 50,\n",
    "        valid_freq: int = 1,\n",
    "        csv_logger: bool = False\n",
    "    ):\n",
    "\n",
    "        self.device = torch.device(device_name if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = model.to(self.device)\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = num_epochs\n",
    "        self.lr_milestones = lr_milestones\n",
    "        self.auto_lr = auto_lr\n",
    "        self.auto_lr_flag = bool(auto_lr)\n",
    "        self.adaloss = adaloss\n",
    "        self.evaluator = evaluator\n",
    "        self.vizual_fn = vizual_fn\n",
    "        self.print_freq = print_freq\n",
    "        self.valid_freq = valid_freq\n",
    "        self.work_dir = work_dir or os.getcwd()\n",
    "        self.csv_logger = csv_logger\n",
    "\n",
    "        # local loggers\n",
    "        self.train_logger = CustomLogger(delimiter=\" \", filename=\"training\", work_dir=self.work_dir, csv=csv_logger)\n",
    "        self.val_logger = CustomLogger(delimiter=\" \", filename=\"validation\", work_dir=self.work_dir, csv=csv_logger)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def prepare_data(self, images, targets):\n",
    "        \"\"\"Prepare tensors for GPU.\"\"\"\n",
    "        images = images.to(self.device)\n",
    "        if isinstance(targets, (list, tuple)):\n",
    "            targets = [t.to(self.device) for t in targets]\n",
    "        else:\n",
    "            targets = targets.to(self.device)\n",
    "        return images, targets\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def _lr_scheduler(self):\n",
    "        \"\"\"Build learning rate scheduler.\"\"\"\n",
    "        if self.auto_lr is True:\n",
    "            return torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer)\n",
    "        elif isinstance(self.auto_lr, dict):\n",
    "            return torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, **self.auto_lr)\n",
    "        elif self.lr_milestones:\n",
    "            return torch.optim.lr_scheduler.MultiStepLR(self.optimizer, self.lr_milestones)\n",
    "        return None\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def _warmup_lr_scheduler(self, warmup_iters, warmup_factor):\n",
    "        \"\"\"Gradual warmup scheduler.\"\"\"\n",
    "        def warmup_func(x):\n",
    "            if x >= warmup_iters:\n",
    "                return 1\n",
    "            alpha = float(x) / warmup_iters\n",
    "            return warmup_factor * (1 - alpha) + alpha\n",
    "        return torch.optim.lr_scheduler.LambdaLR(self.optimizer, warmup_func)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def _is_best(self, val_output, mode=\"min\"):\n",
    "        \"\"\"Check if current epoch is best.\"\"\"\n",
    "        if not hasattr(self, \"best_val\"):\n",
    "            self.best_val = float(\"inf\") if mode == \"min\" else 0\n",
    "        if (mode == \"min\" and val_output < self.best_val) or (mode == \"max\" and val_output > self.best_val):\n",
    "            self.best_val = val_output\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def _save_checkpoint(self, epoch, mode):\n",
    "        \"\"\"Save checkpoint.\"\"\"\n",
    "        os.makedirs(self.work_dir, exist_ok=True)\n",
    "        if mode == \"all\":\n",
    "            outpath = os.path.join(self.work_dir, f\"epoch_{epoch}.pth\")\n",
    "        elif mode == \"best\":\n",
    "            outpath = os.path.join(self.work_dir, \"best_model.pth\")\n",
    "        else:\n",
    "            outpath = os.path.join(self.work_dir, \"latest_model.pth\")\n",
    "\n",
    "        torch.save({\n",
    "            \"epoch\": epoch,\n",
    "            \"model_state_dict\": self.model.state_dict(),\n",
    "            \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "            \"best_val\": getattr(self, \"best_val\", None)\n",
    "        }, outpath)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def _vizual(self, image, target, output):\n",
    "        return self.vizual_fn(image=image, target=target, output=output)\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def evaluate(self, epoch, reduction=\"mean\", wandb_flag=False, returns=\"all\"):\n",
    "        \"\"\"Validation loop.\"\"\"\n",
    "        self.model.eval()\n",
    "        header = f\"[VALIDATION] - Epoch: [{epoch}]\"\n",
    "        batch_losses = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, (images, targets) in enumerate(self.val_logger.log_every(self.val_dataloader, self.print_freq, header)):\n",
    "                images, targets = self.prepare_data(images, targets)\n",
    "                output, loss_dict = self.model(images, targets)\n",
    "                losses = sum(loss for loss in loss_dict.values()) if returns == \"all\" else loss_dict[returns]\n",
    "                batch_losses.append(losses.detach())\n",
    "\n",
    "                if wandb_flag and self.vizual_fn and i % self.print_freq == 0:\n",
    "                    fig = self._vizual(images, targets, output)\n",
    "                    wandb.log({\"validation_viz\": fig})\n",
    "\n",
    "        batch_losses = torch.stack(batch_losses)\n",
    "        val_loss = torch.mean(batch_losses).item() if reduction == \"mean\" else torch.sum(batch_losses).item()\n",
    "        print(f\"{header} {reduction} loss: {val_loss:.4f}\")\n",
    "        return val_loss\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def _train(self, epoch, warmup_iters=None, wandb_flag=False):\n",
    "        \"\"\"Training loop.\"\"\"\n",
    "        self.model.train()\n",
    "        self.train_logger.add_meter(\"lr\", SmoothedValue(window_size=1, fmt=\"{value:.6f}\"))\n",
    "        header = f\"[TRAINING] - Epoch: [{epoch}]\"\n",
    "\n",
    "        if warmup_iters and epoch == 1:\n",
    "            self.start_lr_scheduler = self._warmup_lr_scheduler(\n",
    "                min(warmup_iters, len(self.train_dataloader) - 1),\n",
    "                1.0 / warmup_iters\n",
    "            )\n",
    "\n",
    "        batch_losses = []\n",
    "\n",
    "        for images, targets in self.train_logger.log_every(self.train_dataloader, self.print_freq, header):\n",
    "            images, targets = self.prepare_data(images, targets)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss_dict = self.model(images, targets)\n",
    "            loss_total = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            if not math.isfinite(loss_total.item()):\n",
    "                print(\"Loss is NaN or Inf. Stopping.\")\n",
    "                sys.exit(1)\n",
    "\n",
    "            loss_total.backward()\n",
    "            self.optimizer.step()\n",
    "            if self.adaloss:\n",
    "                self.adaloss.feed(loss_total)\n",
    "\n",
    "            if warmup_iters and epoch == 1:\n",
    "                self.start_lr_scheduler.step()\n",
    "\n",
    "            batch_losses.append(loss_total.detach())\n",
    "\n",
    "        mean_loss = torch.mean(torch.stack(batch_losses)).item()\n",
    "        print(f\"{header} mean loss: {mean_loss:.4f}\")\n",
    "        return mean_loss\n",
    "\n",
    "    # ----------------------------------------------------------\n",
    "    def start(self, warmup_iters=None, checkpoints=\"best\", select=\"min\", validate_on=\"all\", wandb_flag=False):\n",
    "        \"\"\"Start full training.\"\"\"\n",
    "        lr_scheduler = self._lr_scheduler()\n",
    "        if select == \"min\":\n",
    "            self.best_val = float(\"inf\")\n",
    "        else:\n",
    "            self.best_val = 0\n",
    "\n",
    "        for epoch in range(1, self.epochs + 1):\n",
    "            train_loss = self._train(epoch, warmup_iters, wandb_flag)\n",
    "            val_loss = None\n",
    "\n",
    "            if self.val_dataloader and (epoch % self.valid_freq == 0 or epoch in [1, self.epochs]):\n",
    "                val_loss = self.evaluate(epoch, wandb_flag=wandb_flag, returns=validate_on)\n",
    "\n",
    "                if checkpoints == \"all\" or self._is_best(val_loss, select):\n",
    "                    self._save_checkpoint(epoch, checkpoints if checkpoints == \"all\" else \"best\")\n",
    "\n",
    "            self._save_checkpoint(epoch, \"latest\")\n",
    "\n",
    "            if lr_scheduler:\n",
    "                if self.auto_lr_flag and val_loss is not None:\n",
    "                    lr_scheduler.step(val_loss)\n",
    "                else:\n",
    "                    lr_scheduler.step()\n",
    "\n",
    "            if self.adaloss:\n",
    "                self.adaloss.step()\n",
    "\n",
    "        return self.model\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ¦‹ FASTER-RCNN TRAINER SUBCLASS\n",
    "# ============================================================\n",
    "class FasterRCNNTrainer(Trainer):\n",
    "    \"\"\"Trainer subclass for object detection tasks.\"\"\"\n",
    "\n",
    "    def prepare_data(self, images, targets):\n",
    "        images = [img.to(self.device) for img in images]\n",
    "        targets = [{k: v.to(self.device) for k, v in t.items() if torch.is_tensor(v)} for t in targets]\n",
    "        return images, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c429c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§© CORE UTILITIES FOR HERDNET REBUILD\n",
    "# ============================================================\n",
    "# This block restores the missing low-level structures from\n",
    "# the original animaloc framework:\n",
    "# - Registry\n",
    "# - Geometry classes (Point, BoundingBox, processors)\n",
    "# - Image patch utilities\n",
    "# - Logger compatible with Evaluator\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from typing import Any, Callable, Dict, List, Tuple, Optional\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“¦ 1. REGISTRY SYSTEM\n",
    "# ============================================================\n",
    "class Registry:\n",
    "    \"\"\"\n",
    "    Lightweight registry to store callable modules (e.g. models, evaluators, metrics).\n",
    "    Mimics animaloc.utils.registry.Registry.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, module_key: str = None):\n",
    "        self.name = name\n",
    "        self.module_key = module_key\n",
    "        self._registry = {}\n",
    "\n",
    "    def register(self, name: Optional[str] = None):\n",
    "        \"\"\"\n",
    "        Decorator to register classes or functions into the registry.\n",
    "        \"\"\"\n",
    "        def decorator(obj):\n",
    "            key = name or obj.__name__\n",
    "            if key in self._registry:\n",
    "                raise ValueError(f\"{key} already registered in {self.name}\")\n",
    "            self._registry[key] = obj\n",
    "            return obj\n",
    "        return decorator\n",
    "\n",
    "    def get(self, name: str):\n",
    "        return self._registry.get(name)\n",
    "\n",
    "    @property\n",
    "    def registry_names(self):\n",
    "        return list(self._registry.keys())\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self._registry[key]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Registry({self.name}, {len(self._registry)} items)\"\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ“ 2. GEOMETRY CLASSES\n",
    "# ============================================================\n",
    "class Point:\n",
    "    \"\"\"Simple point in (x, y) coordinates.\"\"\"\n",
    "\n",
    "    def __init__(self, x: float, y: float):\n",
    "        self.x = float(x)\n",
    "        self.y = float(y)\n",
    "\n",
    "    def __iter__(self):\n",
    "        yield self.x\n",
    "        yield self.y\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Point(x={self.x:.2f}, y={self.y:.2f})\"\n",
    "\n",
    "\n",
    "class BoundingBox:\n",
    "    \"\"\"Simple bounding box defined by (x_min, y_min, x_max, y_max).\"\"\"\n",
    "\n",
    "    def __init__(self, x_min: float, y_min: float, x_max: float, y_max: float):\n",
    "        self.x_min = float(x_min)\n",
    "        self.y_min = float(y_min)\n",
    "        self.x_max = float(x_max)\n",
    "        self.y_max = float(y_max)\n",
    "        self._validate()\n",
    "\n",
    "    def _validate(self):\n",
    "        assert self.x_max >= self.x_min, \"x_max must be >= x_min\"\n",
    "        assert self.y_max >= self.y_min, \"y_max must be >= y_min\"\n",
    "\n",
    "    @property\n",
    "    def width(self):\n",
    "        return self.x_max - self.x_min\n",
    "\n",
    "    @property\n",
    "    def height(self):\n",
    "        return self.y_max - self.y_min\n",
    "\n",
    "    @property\n",
    "    def area(self):\n",
    "        return self.width * self.height\n",
    "\n",
    "    def intersect(self, other: \"BoundingBox\") -> \"BoundingBox\":\n",
    "        \"\"\"Return the intersection box of two bounding boxes.\"\"\"\n",
    "        x_min = max(self.x_min, other.x_min)\n",
    "        y_min = max(self.y_min, other.y_min)\n",
    "        x_max = min(self.x_max, other.x_max)\n",
    "        y_max = min(self.y_max, other.y_max)\n",
    "        if x_max < x_min or y_max < y_min:\n",
    "            return BoundingBox(0, 0, 0, 0)\n",
    "        return BoundingBox(x_min, y_min, x_max, y_max)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"BBox({self.x_min:.2f},{self.y_min:.2f},{self.x_max:.2f},{self.y_max:.2f})\"\n",
    "\n",
    "\n",
    "class PointProcessor:\n",
    "    \"\"\"Compute distances between points.\"\"\"\n",
    "\n",
    "    def __init__(self, point: Point):\n",
    "        self.point = point\n",
    "\n",
    "    def dist(self, other: Point) -> float:\n",
    "        return math.sqrt((self.point.x - other.x) ** 2 + (self.point.y - other.y) ** 2)\n",
    "\n",
    "\n",
    "class BboxProcessor:\n",
    "    \"\"\"Bounding box processing: intersection and distance.\"\"\"\n",
    "\n",
    "    def __init__(self, bbox: BoundingBox):\n",
    "        self.bbox = bbox\n",
    "\n",
    "    def intersect(self, other: BoundingBox) -> BoundingBox:\n",
    "        return self.bbox.intersect(other)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§© 3. IMAGE TO PATCHES (FOR STITCHER)\n",
    "# ============================================================\n",
    "class ImageToPatches:\n",
    "    \"\"\"\n",
    "    Utility to split an image tensor [C,H,W] into overlapping patches\n",
    "    of fixed size (height, width) with specified overlap (pixels).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, image: torch.Tensor, size: Tuple[int, int], overlap: int):\n",
    "        self.image = image\n",
    "        self.size = np.array(size)\n",
    "        self.overlap = overlap\n",
    "        self._ncol = math.ceil((image.shape[1] - overlap) / (size[0] - overlap))\n",
    "        self._nrow = math.ceil((image.shape[2] - overlap) / (size[1] - overlap))\n",
    "\n",
    "    def make_patches(self) -> torch.Tensor:\n",
    "        \"\"\"Return list of image patches as tensor [N,C,H,W].\"\"\"\n",
    "        C, H, W = self.image.shape\n",
    "        h, w = self.size\n",
    "        stride_h, stride_w = h - self.overlap, w - self.overlap\n",
    "        patches = []\n",
    "\n",
    "        for y in range(0, H - h + 1, stride_h):\n",
    "            for x in range(0, W - w + 1, stride_w):\n",
    "                patch = self.image[:, y:y+h, x:x+w]\n",
    "                patches.append(patch.unsqueeze(0))\n",
    "        return torch.cat(patches, dim=0)\n",
    "\n",
    "    def get_limits(self) -> Dict[int, BoundingBox]:\n",
    "        \"\"\"Return coordinates of each patch as BoundingBox objects.\"\"\"\n",
    "        limits = {}\n",
    "        h, w = self.size\n",
    "        stride_h, stride_w = h - self.overlap, w - self.overlap\n",
    "        idx = 0\n",
    "        for y in range(0, self.image.shape[1] - h + 1, stride_h):\n",
    "            for x in range(0, self.image.shape[2] - w + 1, stride_w):\n",
    "                limits[idx] = BoundingBox(x, y, x+w, y+h)\n",
    "                idx += 1\n",
    "        return limits\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸªµ 4. EXTENDED CUSTOM LOGGER\n",
    "# ============================================================\n",
    "class CustomLogger:\n",
    "    \"\"\"\n",
    "    Minimal logging utility compatible with Evaluator and Trainer.\n",
    "    Supports add_meter(), log_every(), and persistent output file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, delimiter: str = \" \", filename: str = \"log\", work_dir: Optional[str] = None):\n",
    "        self.delimiter = delimiter\n",
    "        self.meters = defaultdict(list)\n",
    "        self.work_dir = work_dir or os.getcwd()\n",
    "        self.log_path = os.path.join(self.work_dir, f\"{filename}.txt\")\n",
    "        os.makedirs(self.work_dir, exist_ok=True)\n",
    "        self.logger = logging.getLogger(filename)\n",
    "        self.logger.setLevel(logging.INFO)\n",
    "        handler = logging.FileHandler(self.log_path, mode=\"a\", encoding=\"utf-8\")\n",
    "        formatter = logging.Formatter(\"[%(asctime)s] %(message)s\", datefmt=\"%H:%M:%S\")\n",
    "        handler.setFormatter(formatter)\n",
    "        if not self.logger.handlers:\n",
    "            self.logger.addHandler(handler)\n",
    "\n",
    "    def log_every(self, iterable, print_freq: int, header: Optional[str] = None):\n",
    "        \"\"\"Iterate and print progress every print_freq iterations.\"\"\"\n",
    "        header = header or \"\"\n",
    "        for i, obj in enumerate(iterable):\n",
    "            if i % print_freq == 0 or i == len(iterable) - 1:\n",
    "                msg = self._get_meter_summary()\n",
    "                print(f\"{header} [{i+1}/{len(iterable)}]{self.delimiter}{msg}\")\n",
    "                self.logger.info(f\"{header} [{i+1}/{len(iterable)}]{self.delimiter}{msg}\")\n",
    "            yield obj\n",
    "\n",
    "    def add_meter(self, name: str, value: Any):\n",
    "        \"\"\"Add a metric value to the logger.\"\"\"\n",
    "        self.meters[name].append(value)\n",
    "\n",
    "    def _get_meter_summary(self) -> str:\n",
    "        \"\"\"Summarize meters as mean values.\"\"\"\n",
    "        parts = []\n",
    "        for k, v in self.meters.items():\n",
    "            if isinstance(v, (list, tuple)) and len(v) > 0:\n",
    "                parts.append(f\"{k}: {np.mean(v):.3f}\")\n",
    "        return self.delimiter.join(parts)\n",
    "\n",
    "    def save_csv(self):\n",
    "        \"\"\"Optional: save meters as CSV for analysis.\"\"\"\n",
    "        import pandas as pd\n",
    "        df = pd.DataFrame(dict([(k, v) for k, v in self.meters.items()]))\n",
    "        csv_path = self.log_path.replace(\".txt\", \".csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"Saved meters to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be60e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ“œ LOGGER.PY â€” Console & File Logging Utility\n",
    "# ============================================================\n",
    "# Compatible con entrenamiento y evaluaciÃ³n.\n",
    "# Registra mÃ©tricas en consola y CSV (.txt), con timestamp.\n",
    "# Inspirado en animaloc.utils.logger (Alexandre Delplanque, 2024)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import errno\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class CustomLogger:\n",
    "    \"\"\"\n",
    "    CustomLogger\n",
    "    ------------\n",
    "    Simple and robust logger for training/evaluation progress.\n",
    "\n",
    "    Features:\n",
    "    - Console + file logging\n",
    "    - CSV-friendly output\n",
    "    - Compatible with MetricLogger.add_meter()\n",
    "    - Timestamped filenames (YYYYMMDD-HHMMSS)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, delimiter: str = \"\\t\", filename: str = \"log\", work_dir: str = None):\n",
    "        self.delimiter = delimiter\n",
    "        self.meters = defaultdict(list)\n",
    "        self.header = None\n",
    "\n",
    "        # Prepare output directory\n",
    "        self.work_dir = work_dir or os.getcwd()\n",
    "        if not os.path.exists(self.work_dir):\n",
    "            try:\n",
    "                os.makedirs(self.work_dir)\n",
    "            except OSError as e:\n",
    "                if e.errno != errno.EEXIST:\n",
    "                    raise\n",
    "\n",
    "        # Timestamp for unique file\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.filename_txt = os.path.join(self.work_dir, f\"{filename}_{timestamp}.txt\")\n",
    "        self.filename_csv = os.path.join(self.work_dir, f\"{filename}_{timestamp}.csv\")\n",
    "\n",
    "        # Open file handles\n",
    "        self.txt_file = open(self.filename_txt, \"w\", encoding=\"utf-8\", buffering=1)\n",
    "        self.csv_file = open(self.filename_csv, \"w\", newline=\"\", encoding=\"utf-8\")\n",
    "        self.csv_writer = None\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # BASIC LOGGING METHODS\n",
    "    # --------------------------------------------------------\n",
    "    def add_meter(self, name: str, value: float):\n",
    "        \"\"\"Add a scalar meter value.\"\"\"\n",
    "        self.meters[name].append(value)\n",
    "\n",
    "    def write(self, msg: str):\n",
    "        \"\"\"Write to both console and file.\"\"\"\n",
    "        print(msg)\n",
    "        self.txt_file.write(msg + \"\\n\")\n",
    "\n",
    "    def log(self, **kwargs):\n",
    "        \"\"\"Log a full row of key-value pairs (e.g. loss, acc, etc.).\"\"\"\n",
    "        timestamp = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "        entry = {\"time\": timestamp, **kwargs}\n",
    "        self._write_row(entry)\n",
    "\n",
    "    def _write_row(self, row: dict):\n",
    "        \"\"\"Internal CSV-safe write with header detection.\"\"\"\n",
    "        if self.csv_writer is None:\n",
    "            fieldnames = list(row.keys())\n",
    "            self.csv_writer = csv.DictWriter(self.csv_file, fieldnames=fieldnames)\n",
    "            self.csv_writer.writeheader()\n",
    "        self.csv_writer.writerow(row)\n",
    "        self.csv_file.flush()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ITERABLE LOGGING (for dataloaders)\n",
    "    # --------------------------------------------------------\n",
    "    def log_every(self, iterable, print_freq: int = 10, header: str = None):\n",
    "        \"\"\"\n",
    "        Iterate over an iterable and print running logs periodically.\n",
    "        Mimics torch.utils MetricLogger behavior.\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        end = time.time()\n",
    "        total = len(iterable)\n",
    "        header = header or \"\"\n",
    "\n",
    "        for i, obj in enumerate(iterable):\n",
    "            yield obj\n",
    "            if i % print_freq == 0 or i == total - 1:\n",
    "                eta_seconds = (time.time() - end) * (total - i)\n",
    "                eta_string = str(datetime.timedelta(seconds=int(eta_seconds)))\n",
    "                log_line = f\"[{i:>{len(str(total))}}/{total}] ETA: {eta_string}\"\n",
    "                self.write(f\"{header} {log_line}\")\n",
    "            end = time.time()\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
    "        self.write(f\"{header} Total time: {total_time_str} ({total_time / total:.4f} s/it)\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # SHUTDOWN\n",
    "    # --------------------------------------------------------\n",
    "    def close(self):\n",
    "        \"\"\"Close log files cleanly.\"\"\"\n",
    "        self.txt_file.close()\n",
    "        self.csv_file.close()\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # STRING REPRESENTATION\n",
    "    # --------------------------------------------------------\n",
    "    def __str__(self):\n",
    "        parts = [f\"{k}: {v[-1]:.4f}\" for k, v in self.meters.items() if len(v) > 0]\n",
    "        return self.delimiter.join(parts)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ”§ UTILITY HELPERS\n",
    "# ============================================================\n",
    "\n",
    "def mkdir(path):\n",
    "    \"\"\"Create directories recursively.\"\"\"\n",
    "    try:\n",
    "        os.makedirs(path)\n",
    "    except OSError as e:\n",
    "        if e.errno != errno.EEXIST:\n",
    "            raise\n",
    "\n",
    "\n",
    "def current_date():\n",
    "    \"\"\"Return current date in YYYYMMDD format.\"\"\"\n",
    "    return datetime.date.today().strftime(\"%Y%m%d\")\n",
    "\n",
    "\n",
    "def get_date_time():\n",
    "    \"\"\"Return current date and time as (date_str, time_str).\"\"\"\n",
    "    today = datetime.date.today().strftime(\"%d/%m/%Y\")\n",
    "    now = datetime.datetime.now().strftime(\"%H:%M:%S\")\n",
    "    return today, now\n",
    "\n",
    "\n",
    "def vdir(obj):\n",
    "    \"\"\"Return object attributes without dunder methods.\"\"\"\n",
    "    return [m for m in dir(obj) if not m.startswith(\"__\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62458cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸŽ¯ FOCAL LOSS - Clean Reimplementation (HerdNet v0.2.1)\n",
    "# ============================================================\n",
    "# Self-contained version of Delplanqueâ€™s focal loss used in HerdNet.\n",
    "# Preserves original logic and hyperparameters: alpha, beta,\n",
    "# reduction, weights, density weighting, normalization, and eps.\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Focal Loss module (Delplanque, 2024 - HerdNet v0.2.1)\n",
    "\n",
    "    Implements the modified focal loss used in HerdNet, originally inspired by\n",
    "    the CenterNet implementation:\n",
    "    https://github.com/xingyizhou/CenterNet/blob/master/src/lib/models/losses.py\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha : int, optional\n",
    "        Exponent for modulating factor (1 - p_t). Default = 2.\n",
    "    beta : int, optional\n",
    "        Exponent for weighting negative examples. Default = 4.\n",
    "    reduction : str, optional\n",
    "        Reduction method ('sum' or 'mean'). Default = 'sum'.\n",
    "    weights : torch.Tensor, optional\n",
    "        Optional per-channel weighting tensor.\n",
    "    density_weight : str, optional\n",
    "        If set to 'linear', 'squared' or 'cubic', scales loss per sample\n",
    "        by number of positive locations to account for density.\n",
    "    normalize : bool, optional\n",
    "        Normalize loss by number of positive samples. Default = False.\n",
    "    eps : float, optional\n",
    "        Small constant for numerical stability. Default = 1e-6.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        alpha: int = 2,\n",
    "        beta: int = 4,\n",
    "        reduction: str = \"sum\",\n",
    "        weights: torch.Tensor = None,\n",
    "        density_weight: str = None,\n",
    "        normalize: bool = False,\n",
    "        eps: float = 1e-6\n",
    "    ):\n",
    "        super(FocalLoss, self).__init__()\n",
    "\n",
    "        assert reduction in [\"mean\", \"sum\"], \\\n",
    "            f\"Reduction must be 'mean' or 'sum', got {reduction}\"\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.reduction = reduction\n",
    "        self.weights = weights\n",
    "        self.density_weight = density_weight\n",
    "        self.normalize = normalize\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the focal loss between prediction and target.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        output : torch.Tensor\n",
    "            Predicted heatmap tensor [B, C, H, W].\n",
    "        target : torch.Tensor\n",
    "            Ground truth heatmap tensor [B, C, H, W].\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Computed loss value.\n",
    "        \"\"\"\n",
    "        return self._neg_loss(output, target)\n",
    "\n",
    "    def _neg_loss(self, output: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Core focal loss computation.\"\"\"\n",
    "        B, C, _, _ = target.shape\n",
    "        device = output.device\n",
    "\n",
    "        if self.weights is not None:\n",
    "            assert self.weights.shape[0] == C, (\n",
    "                f\"Expected {C} channel weights, got {self.weights.shape[0]}\"\n",
    "            )\n",
    "\n",
    "        # Clamp predictions to avoid log(0)\n",
    "        output = torch.clamp(output, min=self.eps, max=1 - self.eps)\n",
    "\n",
    "        # Masks\n",
    "        pos_inds = target.eq(1).float()\n",
    "        neg_inds = target.lt(1).float()\n",
    "        neg_weights = torch.pow(1 - target, self.beta)\n",
    "\n",
    "        # Compute log terms\n",
    "        pos_loss = torch.log(output) * torch.pow(1 - output, self.alpha) * pos_inds\n",
    "        neg_loss = torch.log(1 - output) * torch.pow(output, self.alpha) * neg_weights * neg_inds\n",
    "\n",
    "        # Sum spatially\n",
    "        num_pos = pos_inds.sum(dim=(2, 3))\n",
    "        pos_loss = pos_loss.sum(dim=(2, 3))\n",
    "        neg_loss = neg_loss.sum(dim=(2, 3))\n",
    "\n",
    "        # Initialize total loss tensor\n",
    "        loss = torch.zeros((B, C), device=device)\n",
    "\n",
    "        # Iterate over batch and channels\n",
    "        for b in range(B):\n",
    "            for c in range(C):\n",
    "                density = torch.tensor(1.0, device=device)\n",
    "                if self.density_weight == \"linear\":\n",
    "                    density = num_pos[b][c]\n",
    "                elif self.density_weight == \"squared\":\n",
    "                    density = num_pos[b][c] ** 2\n",
    "                elif self.density_weight == \"cubic\":\n",
    "                    density = num_pos[b][c] ** 3\n",
    "\n",
    "                if num_pos[b][c] == 0:\n",
    "                    loss[b][c] = -neg_loss[b][c]\n",
    "                else:\n",
    "                    total = pos_loss[b][c] + neg_loss[b][c]\n",
    "                    loss[b][c] = density * (-total)\n",
    "                    if self.normalize:\n",
    "                        loss[b][c] = loss[b][c] / (num_pos[b][c] + self.eps)\n",
    "\n",
    "        # Apply per-channel weights\n",
    "        if self.weights is not None:\n",
    "            loss = loss * self.weights.to(device)\n",
    "\n",
    "        # Final reduction\n",
    "        if self.reduction == \"mean\":\n",
    "            return loss.mean()\n",
    "        return loss.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c917d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ“¦ CSVDataset â€” Dataset class for images + CSV annotations\n",
    "# ============================================================\n",
    "# Compatible with:\n",
    "#  - Point annotations (for HerdNet or DensityMap models)\n",
    "#  - Bounding boxes (for FasterRCNN, etc.)\n",
    "#  - Albumentations transforms\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations import Compose\n",
    "\n",
    "# ============================================================\n",
    "# ðŸ§© DATASET CLASS\n",
    "# ============================================================\n",
    "class CSVDataset(Dataset):\n",
    "    \"\"\"\n",
    "    CSVDataset\n",
    "    ----------\n",
    "    Reads image paths and annotations from a CSV file.\n",
    "\n",
    "    Supported annotation types:\n",
    "    - Points (x, y, label)\n",
    "    - Bounding boxes (x_min, y_min, x_max, y_max, label)\n",
    "\n",
    "    The dataset can apply Albumentations transforms and return\n",
    "    tensors ready for model input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file : str\n",
    "        Path to the CSV file containing annotations.\n",
    "    img_dir : str\n",
    "        Directory containing the images.\n",
    "    transforms : albumentations.Compose, optional\n",
    "        Transformation pipeline applied to each sample.\n",
    "    anno_type : str, optional\n",
    "        Type of annotation: 'point' or 'bbox'.\n",
    "        Defaults to 'point'.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, csv_file: str, img_dir: str, transforms: Compose = None, anno_type: str = \"point\") -> None:\n",
    "        assert os.path.exists(csv_file), f\"CSV file not found: {csv_file}\"\n",
    "        assert os.path.exists(img_dir), f\"Image directory not found: {img_dir}\"\n",
    "        assert anno_type in [\"point\", \"bbox\"], f\"Invalid annotation type: {anno_type}\"\n",
    "\n",
    "        self.csv_file = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transforms = transforms\n",
    "        self.anno_type = anno_type\n",
    "\n",
    "        # Read CSV safely\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        if \"image_id\" not in self.df.columns:\n",
    "            raise ValueError(\"CSV must contain 'image_id' column\")\n",
    "\n",
    "        # Unique image names and mapping\n",
    "        self._img_names = sorted(self.df[\"image_id\"].unique())\n",
    "        self.num_samples = len(self._img_names)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ LENGTH\n",
    "    # --------------------------------------------------------\n",
    "    def __len__(self) -> int:\n",
    "        return self.num_samples\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ GET ITEM\n",
    "    # --------------------------------------------------------\n",
    "    def __getitem__(self, idx: int):\n",
    "        \"\"\"Load one sample (image + target).\"\"\"\n",
    "\n",
    "        # 1ï¸âƒ£ Get image path\n",
    "        img_name = self._img_names[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Image not found: {img_path}\")\n",
    "\n",
    "        # 2ï¸âƒ£ Load image (convert BGR â†’ RGB)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to read image: {img_path}\")\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # 3ï¸âƒ£ Subset dataframe\n",
    "        subset = self.df[self.df[\"image_id\"] == img_name]\n",
    "\n",
    "        # 4ï¸âƒ£ Parse annotations\n",
    "        if self.anno_type == \"point\":\n",
    "            target = self._parse_points(subset)\n",
    "        else:\n",
    "            target = self._parse_bboxes(subset)\n",
    "\n",
    "        # 5ï¸âƒ£ Apply Albumentations transforms (if any)\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, **target)\n",
    "            image = transformed[\"image\"]\n",
    "            target = {k: transformed[k] for k in target.keys() if k in transformed}\n",
    "\n",
    "        # 6ï¸âƒ£ Convert to torch.Tensor\n",
    "        image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "        return image, target\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¸ PARSE METHODS\n",
    "    # --------------------------------------------------------\n",
    "    def _parse_points(self, subset: pd.DataFrame) -> dict:\n",
    "        \"\"\"Parse point annotations from a dataframe.\"\"\"\n",
    "        required_cols = {\"x\", \"y\", \"label\"}\n",
    "        if not required_cols.issubset(subset.columns):\n",
    "            raise ValueError(f\"Missing columns for point annotations: {required_cols}\")\n",
    "\n",
    "        points = subset[[\"x\", \"y\"]].values.tolist()\n",
    "        labels = subset[\"label\"].astype(int).tolist()\n",
    "\n",
    "        target = {\n",
    "            \"points\": torch.tensor(points, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.int64),\n",
    "        }\n",
    "        return target\n",
    "\n",
    "    def _parse_bboxes(self, subset: pd.DataFrame) -> dict:\n",
    "        \"\"\"Parse bounding box annotations from a dataframe.\"\"\"\n",
    "        required_cols = {\"x_min\", \"y_min\", \"x_max\", \"y_max\", \"label\"}\n",
    "        if not required_cols.issubset(subset.columns):\n",
    "            raise ValueError(f\"Missing columns for bbox annotations: {required_cols}\")\n",
    "\n",
    "        boxes = subset[[\"x_min\", \"y_min\", \"x_max\", \"y_max\"]].values.tolist()\n",
    "        labels = subset[\"label\"].astype(int).tolist()\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
    "            \"labels\": torch.tensor(labels, dtype=torch.int64),\n",
    "        }\n",
    "        return target\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ IMAGE UTILITIES\n",
    "    # --------------------------------------------------------\n",
    "    def get_image_name(self, idx: int) -> str:\n",
    "        \"\"\"Return image filename by index.\"\"\"\n",
    "        return self._img_names[idx]\n",
    "\n",
    "    def get_image_path(self, idx: int) -> str:\n",
    "        \"\"\"Return absolute image path by index.\"\"\"\n",
    "        return os.path.join(self.img_dir, self._img_names[idx])\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ REPR\n",
    "    # --------------------------------------------------------\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"CSVDataset(n={self.num_samples}, type={self.anno_type}, dir='{self.img_dir}')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127c0db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# âš™ï¸ REGISTRY.PY â€” Dynamic Class Registration System\n",
    "# ============================================================\n",
    "# This module provides a simple registry pattern to dynamically\n",
    "# register and instantiate modules (models, trainers, datasets, etc.)\n",
    "# ============================================================\n",
    "\n",
    "import inspect\n",
    "from typing import Any, Callable, Dict, Optional\n",
    "\n",
    "\n",
    "class Registry:\n",
    "    \"\"\"\n",
    "    Registry\n",
    "    --------\n",
    "    A lightweight class registry system used to register and retrieve\n",
    "    model components (e.g., networks, trainers, transforms).\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    MODELS = Registry(\"models\")\n",
    "\n",
    "    @MODELS.register()\n",
    "    class MyModel:\n",
    "        pass\n",
    "\n",
    "    model = MODELS.build(\"MyModel\")\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, module_key: Optional[str] = None):\n",
    "        self._name = name\n",
    "        self._module_key = module_key or name\n",
    "        self._registry: Dict[str, Any] = {}\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ REGISTRATION\n",
    "    # --------------------------------------------------------\n",
    "    def register(self, name: Optional[str] = None) -> Callable:\n",
    "        \"\"\"\n",
    "        Decorator to register a class or function.\n",
    "\n",
    "        Args:\n",
    "            name (str, optional): Custom registry key name.\n",
    "        \"\"\"\n",
    "\n",
    "        def decorator(obj: Any):\n",
    "            key = name or obj.__name__\n",
    "            if key in self._registry:\n",
    "                raise KeyError(f\"'{key}' is already registered in {self._name}\")\n",
    "            self._registry[key] = obj\n",
    "            return obj\n",
    "\n",
    "        return decorator\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ RETRIEVAL\n",
    "    # --------------------------------------------------------\n",
    "    def get(self, key: str) -> Any:\n",
    "        \"\"\"\n",
    "        Retrieve an object from the registry by its key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The registered name or class name.\n",
    "\n",
    "        Returns:\n",
    "            Registered class or function.\n",
    "        \"\"\"\n",
    "        if key not in self._registry:\n",
    "            raise KeyError(f\"'{key}' is not registered in {self._name}\")\n",
    "        return self._registry[key]\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ BUILD INSTANCE\n",
    "    # --------------------------------------------------------\n",
    "    def build(self, key: str, **kwargs) -> Any:\n",
    "        \"\"\"\n",
    "        Instantiate a registered class or call a registered function.\n",
    "\n",
    "        Args:\n",
    "            key (str): Registered name or class name.\n",
    "            **kwargs: Arguments passed to the constructor.\n",
    "\n",
    "        Returns:\n",
    "            Instantiated object.\n",
    "        \"\"\"\n",
    "        cls_or_func = self.get(key)\n",
    "        if inspect.isclass(cls_or_func):\n",
    "            return cls_or_func(**kwargs)\n",
    "        elif callable(cls_or_func):\n",
    "            return cls_or_func(**kwargs)\n",
    "        else:\n",
    "            raise TypeError(f\"Object '{key}' is not callable in {self._name}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ LIST UTILITIES\n",
    "    # --------------------------------------------------------\n",
    "    @property\n",
    "    def registry_names(self):\n",
    "        \"\"\"Return a sorted list of registered names.\"\"\"\n",
    "        return sorted(list(self._registry.keys()))\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._registry)\n",
    "\n",
    "    def __contains__(self, key: str) -> bool:\n",
    "        return key in self._registry\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return f\"Registry(name='{self._name}', entries={list(self._registry.keys())})\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7bace37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# âš™ï¸ DEFAULT LOSS CONFIGURATION BUILDER\n",
    "# ============================================================\n",
    "# Generates the exact same losses list used in HerdNet training:\n",
    "#   - FocalLoss for localization heatmap\n",
    "#   - CrossEntropyLoss for classification map\n",
    "# Can be passed directly to LossWrapper(model, losses=losses)\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "def build_default_losses(num_classes: int = 4, device: str = None):\n",
    "    \"\"\"\n",
    "    Build the default HerdNet loss configuration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_classes : int, optional\n",
    "        Number of classes used in the classification map.\n",
    "        Default = 4 (as in HerdNet repo: background + 3 animal classes).\n",
    "    device : str, optional\n",
    "        Device to place weight tensors on. If None, auto-detects CUDA.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dict\n",
    "        List compatible with LossWrapper initialization.\n",
    "    \"\"\"\n",
    "    from torch import Tensor\n",
    "\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    # Class weights (repo default)\n",
    "    weight = Tensor([0.1] + [1.0] * (num_classes - 1)).to(device)\n",
    "\n",
    "    # Focal loss for density / localization\n",
    "    focal_loss = FocalLoss(\n",
    "        alpha=2,\n",
    "        beta=4,\n",
    "        reduction=\"mean\",\n",
    "        density_weight=None,\n",
    "        normalize=False\n",
    "    )\n",
    "\n",
    "    # Cross-entropy loss for per-pixel classification\n",
    "    ce_loss = CrossEntropyLoss(\n",
    "        reduction=\"mean\",\n",
    "        weight=weight\n",
    "    )\n",
    "\n",
    "    losses = [\n",
    "        {\"loss\": focal_loss, \"idx\": 0, \"idy\": 0, \"lambda\": 1.0, \"name\": \"focal_loss\"},\n",
    "        {\"loss\": ce_loss, \"idx\": 1, \"idy\": 1, \"lambda\": 1.0, \"name\": \"ce_loss\"},\n",
    "    ]\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ad94ac02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Crear el modelo base\n",
    "herdnet = HerdNet(num_layers=34, num_classes=4, down_ratio=2)\n",
    "\n",
    "# 2. Construir la configuraciÃ³n de pÃ©rdidas\n",
    "losses = build_default_losses(num_classes=4)\n",
    "\n",
    "# 3. Envolver el modelo\n",
    "herdnet = LossWrapper(herdnet, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad18176c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LossWrapper(\n",
       "  (model): HerdNet(\n",
       "    (base_0): DLA(\n",
       "      (base_layer): Sequential(\n",
       "        (0): Conv2d(3, 16, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (level0): Sequential(\n",
       "        (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (level1): Sequential(\n",
       "        (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "      )\n",
       "      (level2): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (level3): Tree(\n",
       "        (tree1): Tree(\n",
       "          (tree1): BasicBlock(\n",
       "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (tree2): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (root): Root(\n",
       "            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (project): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (tree2): Tree(\n",
       "          (tree1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (tree2): BasicBlock(\n",
       "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (root): Root(\n",
       "            (conv): Conv2d(448, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (level4): Tree(\n",
       "        (tree1): Tree(\n",
       "          (tree1): BasicBlock(\n",
       "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (tree2): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (root): Root(\n",
       "            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "          (project): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (tree2): Tree(\n",
       "          (tree1): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (tree2): BasicBlock(\n",
       "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (root): Root(\n",
       "            (conv): Conv2d(896, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (level5): Tree(\n",
       "        (tree1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (tree2): BasicBlock(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (root): Root(\n",
       "          (conv): Conv2d(1280, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (downsample): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "        (project): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (dla_up): DLAUp(\n",
       "      (ida_0): IDAUp(\n",
       "        (proj_0): Identity()\n",
       "        (up_0): Identity()\n",
       "        (proj_1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_1): ConvTranspose2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "        (node_1): Sequential(\n",
       "          (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (ida_1): IDAUp(\n",
       "        (proj_0): Identity()\n",
       "        (up_0): Identity()\n",
       "        (proj_1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_1): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        (proj_2): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_2): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "        (node_1): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (node_2): Sequential(\n",
       "          (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (ida_2): IDAUp(\n",
       "        (proj_0): Identity()\n",
       "        (up_0): Identity()\n",
       "        (proj_1): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_1): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (proj_2): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_2): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (proj_3): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "        (node_1): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (node_2): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (node_3): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (ida_3): IDAUp(\n",
       "        (proj_0): Identity()\n",
       "        (up_0): Identity()\n",
       "        (proj_1): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_1): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (proj_2): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_2): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (proj_3): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (proj_4): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (up_4): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
       "        (node_1): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (node_2): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (node_3): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (node_4): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (bottleneck_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (loc_head): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (3): Sigmoid()\n",
       "    )\n",
       "    (cls_head): Sequential(\n",
       "      (0): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "herdnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28fe997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ðŸ§  HERDNET TRAINER (Faithful Reimplementation)\n",
    "# ============================================================\n",
    "# Rewritten from scratch following the structure of\n",
    "# animaloc.train.trainers (Delplanque, 2024).\n",
    "# Handles training, validation, checkpointing, and metrics.\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class HerdNetTrainer:\n",
    "    \"\"\"\n",
    "    HerdNetTrainer\n",
    "    --------------\n",
    "    Manages full training and validation loops for HerdNet models\n",
    "    wrapped with LossWrapper. Includes checkpoint saving, metric\n",
    "    tracking, and early stopping.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : torch.nn.Module\n",
    "        Wrapped model (LossWrapper(HerdNet, losses)).\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Optimizer instance (e.g., Adam, SGD).\n",
    "    train_loader : torch.utils.data.DataLoader\n",
    "        Training data loader.\n",
    "    val_loader : torch.utils.data.DataLoader\n",
    "        Validation data loader.\n",
    "    device : torch.device\n",
    "        Device for computation.\n",
    "    save_dir : str\n",
    "        Directory where checkpoints and logs will be saved.\n",
    "    save_every : int\n",
    "        Save checkpoint every N epochs.\n",
    "    patience : int\n",
    "        Stop training early if val loss does not improve after N epochs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_loader,\n",
    "        val_loader=None,\n",
    "        device=None,\n",
    "        save_dir=\"checkpoints\",\n",
    "        save_every=5,\n",
    "        patience=10,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.save_dir = save_dir\n",
    "        self.save_every = save_every\n",
    "        self.patience = patience\n",
    "\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ Save checkpoint\n",
    "    # --------------------------------------------------------\n",
    "    def save_checkpoint(self, epoch, val_loss):\n",
    "        checkpoint_path = os.path.join(self.save_dir, f\"herdnet_epoch_{epoch}.pth\")\n",
    "        torch.save(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model_state_dict\": self.model.state_dict(),\n",
    "                \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                \"val_loss\": val_loss,\n",
    "            },\n",
    "            checkpoint_path,\n",
    "        )\n",
    "        print(f\"[CHECKPOINT] Saved: {checkpoint_path}\")\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ Training loop\n",
    "    # --------------------------------------------------------\n",
    "    def train(self, num_epochs):\n",
    "        best_val_loss = float(\"inf\")\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        for epoch in range(1, num_epochs + 1):\n",
    "            print(f\"\\nðŸŸ© Epoch [{epoch}/{num_epochs}]\")\n",
    "\n",
    "            # --------------------------\n",
    "            # Training phase\n",
    "            # --------------------------\n",
    "            self.model.train()\n",
    "            train_loss = 0.0\n",
    "            start_time = time.time()\n",
    "\n",
    "            for batch in tqdm(self.train_loader, desc=\"Training\", leave=False):\n",
    "                images, targets = batch\n",
    "\n",
    "                # Move to device\n",
    "                images = images.to(self.device)\n",
    "                targets = [t.to(self.device) for t in targets] if isinstance(targets, (list, tuple)) else targets.to(self.device)\n",
    "\n",
    "                # Forward + loss\n",
    "                self.optimizer.zero_grad()\n",
    "                loss_dict = self.model(images, targets)\n",
    "                total_loss = sum(loss_dict.values())\n",
    "\n",
    "                total_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_loss += total_loss.item()\n",
    "\n",
    "            train_loss /= len(self.train_loader)\n",
    "            duration = time.time() - start_time\n",
    "            print(f\"[TRAIN] Loss: {train_loss:.4f} | Time: {duration:.1f}s\")\n",
    "\n",
    "            # --------------------------\n",
    "            # Validation phase\n",
    "            # --------------------------\n",
    "            if self.val_loader is not None:\n",
    "                val_loss = self.validate()\n",
    "                print(f\"[VAL]   Loss: {val_loss:.4f}\")\n",
    "\n",
    "                # Check for improvement\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    epochs_no_improve = 0\n",
    "                    self.save_checkpoint(epoch, val_loss)\n",
    "                else:\n",
    "                    epochs_no_improve += 1\n",
    "                    if epochs_no_improve >= self.patience:\n",
    "                        print(\"[EARLY STOPPING] Validation loss did not improve.\")\n",
    "                        break\n",
    "\n",
    "            # Save regular checkpoint\n",
    "            if epoch % self.save_every == 0:\n",
    "                self.save_checkpoint(epoch, best_val_loss)\n",
    "\n",
    "    # --------------------------------------------------------\n",
    "    # ðŸ”¹ Validation loop\n",
    "    # --------------------------------------------------------\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(self.val_loader, desc=\"Validation\", leave=False):\n",
    "                images, targets = batch\n",
    "\n",
    "                images = images.to(self.device)\n",
    "                targets = [t.to(self.device) for t in targets] if isinstance(targets, (list, tuple)) else targets.to(self.device)\n",
    "\n",
    "                _, loss_dict = self.model(images, targets)\n",
    "                total_loss = sum(loss_dict.values())\n",
    "                val_loss += total_loss.item()\n",
    "\n",
    "        val_loss /= len(self.val_loader)\n",
    "        return val_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94dd001",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m      7\u001b[39m optimizer = torch.optim.Adam(wrapped_model.parameters(), lr=\u001b[32m1e-4\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# 3. Instanciar entrenador\u001b[39;00m\n\u001b[32m     10\u001b[39m trainer = HerdNetTrainer(\n\u001b[32m     11\u001b[39m     model=wrapped_model,\n\u001b[32m     12\u001b[39m     optimizer=optimizer,\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     train_loader=\u001b[43mtrain_loader\u001b[49m,\n\u001b[32m     14\u001b[39m     val_loader=val_loader,\n\u001b[32m     15\u001b[39m     save_dir=\u001b[33m\"\u001b[39m\u001b[33mcheckpoints\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     save_every=\u001b[32m2\u001b[39m,\n\u001b[32m     17\u001b[39m     patience=\u001b[32m5\u001b[39m\n\u001b[32m     18\u001b[39m )\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 4. Entrenar\u001b[39;00m\n\u001b[32m     21\u001b[39m trainer.train(num_epochs=\u001b[32m50\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# 1. Crear modelo y pÃ©rdidas\n",
    "herdnet = HerdNet(num_layers=34, num_classes=4, down_ratio=2)\n",
    "losses = build_default_losses(num_classes=4)\n",
    "wrapped_model = LossWrapper(herdnet, losses=losses)\n",
    "\n",
    "# 2. Preparar optimizador\n",
    "optimizer = torch.optim.Adam(wrapped_model.parameters(), lr=1e-4)\n",
    "\n",
    "# 3. Instanciar entrenador\n",
    "trainer = HerdNetTrainer(\n",
    "    model=wrapped_model,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    save_dir=\"checkpoints\",\n",
    "    save_every=2,\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "# 4. Entrenar\n",
    "trainer.train(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fbb597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
