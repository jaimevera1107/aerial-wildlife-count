# ğŸ¦ Wildlife Vision - Sistema de DetecciÃ³n y Conteo de Fauna Africana

<div align="center">

![Wildlife Vision - Interfaz Principal](docs/screenshots/wildlife-vision-main.png)

[![Python 3.10+](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch 2.x](https://img.shields.io/badge/PyTorch-2.x-red.svg)](https://pytorch.org/)
[![Gradio](https://img.shields.io/badge/Gradio-5.x-orange.svg)](https://gradio.app/)
[![Docker](https://img.shields.io/badge/Docker-Ready-blue.svg)](https://www.docker.com/)
[![License: CC BY-NC-SA 4.0](https://img.shields.io/badge/License-CC%20BY--NC--SA%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

**Sistema de inteligencia artificial para detecciÃ³n y conteo automÃ¡tico de mamÃ­feros africanos en imÃ¡genes aÃ©reas**

[ğŸŒ **AplicaciÃ³n Desplegada**](https://wildlife.vision) | [ğŸ“Š **Hugging Face Space**](https://huggingface.co/spaces/jaimevera1107/herdnet-app) | [ğŸ“ **Dataset ULiÃ¨ge-AIR**](https://dataverse.uliege.be/dataset.xhtml?persistentId=doi:10.58119/ULG/MIRUU5)

</div>

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [Construido Con](#-construido-con)
- [Integrantes del Equipo](#-integrantes-del-equipo)
- [Primeros Pasos](#-primeros-pasos)
  - [Prerrequisitos](#prerrequisitos)
  - [InstalaciÃ³n](#instalaciÃ³n)
- [Uso](#-uso)
- [Arquitectura del Sistema](#-arquitectura-del-sistema)
- [Estructura del Repositorio](#-estructura-del-repositorio)
- [ParametrizaciÃ³n](#-parametrizaciÃ³n)
- [GuÃ­a de Despliegue](#-guÃ­a-de-despliegue)
- [MÃ©tricas del Modelo](#-mÃ©tricas-del-modelo)
- [Roadmap](#-roadmap)
- [Contribuir](#-contribuir)
- [DocumentaciÃ³n Adicional](#-documentaciÃ³n-adicional)
- [Licencia](#-licencia)
- [Contacto](#-contacto)
- [Agradecimientos](#-agradecimientos)

---

## ğŸ“– DescripciÃ³n del Proyecto

**Wildlife Vision** es un sistema de visiÃ³n por computadora desarrollado para la detecciÃ³n y conteo automÃ¡tico de mamÃ­feros africanos en imÃ¡genes aÃ©reas capturadas por drones. El proyecto utiliza el modelo **HerdNet**, una arquitectura basada en Feature Pyramid Networks (FPN) con mapas de densidad, entrenado sobre el dataset **ULiÃ¨ge-AIR**.

### Especies Detectables

El sistema puede identificar y contar las siguientes 6 especies de mamÃ­feros africanos:

| Especie | Emoji | DescripciÃ³n |
|---------|-------|-------------|
| Buffalo | ğŸ¦¬ | BÃºfalo africano |
| Elephant | ğŸ˜ | Elefante africano |
| Kob | ğŸ¦Œ | AntÃ­lope Kob |
| Topi | ğŸ« | AntÃ­lope Topi |
| Warthog | ğŸ— | JabalÃ­ verrugoso |
| Waterbuck | ğŸ¦Œ | AntÃ­lope acuÃ¡tico |

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ› ï¸ Construido Con

Este proyecto fue desarrollado utilizando las siguientes tecnologÃ­as y frameworks:

* [![Python][Python-badge]][Python-url]
* [![PyTorch][PyTorch-badge]][PyTorch-url]
* [![Gradio][Gradio-badge]][Gradio-url]
* [![Docker][Docker-badge]][Docker-url]
* [![OpenCV][OpenCV-badge]][OpenCV-url]

[Python-badge]: https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white
[Python-url]: https://www.python.org/
[PyTorch-badge]: https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white
[PyTorch-url]: https://pytorch.org/
[Gradio-badge]: https://img.shields.io/badge/Gradio-FF6F00?style=for-the-badge&logo=gradio&logoColor=white
[Gradio-url]: https://gradio.app/
[Docker-badge]: https://img.shields.io/badge/Docker-2496ED?style=for-the-badge&logo=docker&logoColor=white
[Docker-url]: https://www.docker.com/
[OpenCV-badge]: https://img.shields.io/badge/OpenCV-5C3EE8?style=for-the-badge&logo=opencv&logoColor=white
[OpenCV-url]: https://opencv.org/

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ‘¥ Integrantes del Equipo

**Proyecto Guacamaya (CINFONIA)**  
**MaestrÃ­a en Inteligencia Artificial - Universidad de los Andes**

| Nombre | Rol |
|--------|-----|
| **Jaime A. Vera Jaramillo** | Desarrollo del modelo y pipeline de entrenamiento |
| **JuliÃ¡n F. Cujabante Villamil** | IntegraciÃ³n y documentaciÃ³n |
| **Rafael A. Ortega PabÃ³n** | Infraestructura y despliegue |
| **Uldy D. Paloma Rozo** | AnÃ¡lisis de datos y evaluaciÃ³n |

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## âœ¨ CaracterÃ­sticas Principales

- ğŸ¯ **DetecciÃ³n multi-especie**: Identifica 6 especies de mamÃ­feros africanos simultÃ¡neamente
- ğŸ“Š **Conteo automÃ¡tico**: Genera conteos precisos por especie y totales
- ğŸ–¼ï¸ **VisualizaciÃ³n de resultados**: Imagen anotada con puntos de detecciÃ³n
- ğŸ“¥ **ExportaciÃ³n de datos**: Descarga de resultados en formato CSV
- ğŸš€ **Interfaz web intuitiva**: AplicaciÃ³n Gradio con diseÃ±o moderno
- ğŸ³ **ContenedorizaciÃ³n Docker**: Despliegue portable y reproducible
- âš¡ **Soporte GPU/CPU**: Optimizado para ambos entornos
- ğŸ“± **DiseÃ±o responsive**: Funciona en dispositivos mÃ³viles y desktop

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸš€ Primeros Pasos

A continuaciÃ³n se describen los pasos para configurar el proyecto localmente.

### Prerrequisitos

AsegÃºrese de tener instalado lo siguiente:

* **Python 3.10+**
  ```bash
  python --version
  ```
* **pip** (gestor de paquetes)
  ```bash
  pip --version
  ```
* **Git**
  ```bash
  git --version
  ```
* **DVC** (para descargar datos y modelos)
  ```bash
  pip install dvc
  ```
* **Docker** (opcional, para despliegue containerizado)

### Dependencias Principales

Las siguientes son las dependencias principales del proyecto (versiones en `requirements.txt`):

| Paquete | VersiÃ³n | DescripciÃ³n |
|---------|---------|-------------|
| torch | 2.9.0 | Framework de deep learning |
| torchvision | 0.24.0 | Utilidades de visiÃ³n para PyTorch |
| gradio | 5.49.1 | Framework para interfaces web |
| albumentations | 2.0.8 | AumentaciÃ³n de imÃ¡genes |
| opencv-python-headless | 4.12.0.88 | Procesamiento de imÃ¡genes |
| pandas | 2.3.3 | ManipulaciÃ³n de datos |
| numpy | 2.2.6 | ComputaciÃ³n numÃ©rica |
| scikit-learn | 1.7.2 | Machine learning |
| animaloc | 0.2.1 | HerdNet (desde GitHub) |
| wandb | 0.22.3 | Logging de experimentos |

### InstalaciÃ³n

1. **Clonar el repositorio**
   ```bash
   git clone https://github.com/jaimevera1107/aerial-wildlife-count.git
   cd aerial-wildlife-count
   ```

2. **Crear y activar entorno virtual**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/Mac
   # o
   .\venv\Scripts\activate   # Windows
   ```

3. **Instalar dependencias**
   ```bash
   pip install -r requirements.txt
   ```

4. **Descargar datos y modelos con DVC**
   ```bash
   # Descargar el modelo (requerido)
   dvc pull modelos/herdnet_best.pth.dvc
   dvc pull resources/models/herdnet_best.pth.dvc
   
   # Opcional: Descargar dataset completo (~33 GB)
   dvc pull
   ```

5. **Ejecutar la aplicaciÃ³n**
   ```bash
   python app.py
   ```

6. **Abrir en el navegador**
   ```
   http://localhost:7860
   ```

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ—ï¸ Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        WILDLIFE VISION                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Gradio    â”‚â”€â”€â”€â–¶â”‚  HerdNet     â”‚â”€â”€â”€â–¶â”‚  Postproceso    â”‚    â”‚
â”‚  â”‚   Frontend  â”‚    â”‚  Inference   â”‚    â”‚  & ExportaciÃ³n  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                  â”‚                     â”‚              â”‚
â”‚         â–¼                  â–¼                     â–¼              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Upload    â”‚    â”‚   Sliding    â”‚    â”‚   CSV + Image   â”‚    â”‚
â”‚  â”‚   Image     â”‚    â”‚   Window     â”‚    â”‚   Annotated     â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Pipeline de Inferencia

1. **Preprocesamiento**: NormalizaciÃ³n y divisiÃ³n en parches (sliding window)
2. **Inferencia**: PredicciÃ³n con HerdNet + FPN
3. **Stitching**: ReconstrucciÃ³n de detecciones globales con NMS
4. **Postprocesamiento**: Conteo por especie y anotaciÃ³n visual

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ“ Estructura del Repositorio

```
aerial-wildlife-count-main/
â”‚
â”œâ”€â”€ ğŸ“‚ notebooks/                    # Cuadernos de anÃ¡lisis y entrenamiento
â”‚   â”œâ”€â”€ full_herdnet_maia.ipynb     # Entrenamiento completo HerdNet
â”‚   â”œâ”€â”€ full_herdnet_maia_plus.ipynb # Fine-tuning avanzado
â”‚   â”œâ”€â”€ full_YOLO_maia.ipynb        # Comparativa con YOLOv11
â”‚   â”œâ”€â”€ demo-training-testing-herdnet.ipynb
â”‚   â”œâ”€â”€ augment.ipynb               # AumentaciÃ³n de datos
â”‚   â”œâ”€â”€ quality.ipynb               # AnÃ¡lisis de calidad
â”‚   â””â”€â”€ train_scratch.ipynb         # Entrenamiento desde cero
â”‚
â”œâ”€â”€ ğŸ“‚ modelos/                      # Modelos entrenados
â”‚   â”œâ”€â”€ herdnet_best.pth            # Modelo HerdNet final (PyTorch)
â”‚   â””â”€â”€ herdnet_best.pth.dvc        # Versionado con DVC
â”‚
â”œâ”€â”€ ğŸ“‚ datos/                        # Muestras del dataset
â”‚   â”œâ”€â”€ train/                      # ImÃ¡genes de entrenamiento
â”‚   â”œâ”€â”€ val/                        # ImÃ¡genes de validaciÃ³n
â”‚   â”œâ”€â”€ test/                       # ImÃ¡genes de prueba
â”‚   â”œâ”€â”€ train_patches/              # Parches de entrenamiento
â”‚   â”œâ”€â”€ val_patches/                # Parches de validaciÃ³n
â”‚   â”œâ”€â”€ train.csv                   # Anotaciones de entrenamiento
â”‚   â”œâ”€â”€ val.csv                     # Anotaciones de validaciÃ³n
â”‚   â”œâ”€â”€ test.csv                    # Anotaciones de prueba
â”‚   â””â”€â”€ detections.csv              # Ejemplo de salida de detecciones
â”‚
â”œâ”€â”€ ğŸ“‚ inference/                    # MÃ³dulos de inferencia
â”‚   â”œâ”€â”€ herdnet_infer.py            # Motor de inferencia HerdNet
â”‚   â”œâ”€â”€ preprocessing.py            # Preprocesamiento de imÃ¡genes
â”‚   â”œâ”€â”€ postprocessing.py           # Postprocesamiento y visualizaciÃ³n
â”‚   â””â”€â”€ utils_io.py                 # Utilidades de entrada/salida
â”‚
â”œâ”€â”€ ğŸ“‚ resources/                    # Recursos y configuraciones
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â””â”€â”€ default.yaml            # ConfiguraciÃ³n por defecto
â”‚   â”œâ”€â”€ models/                     # Modelos (copia de modelos/)
â”‚   â”œâ”€â”€ logs/                       # Logs de inferencia
â”‚   â””â”€â”€ outputs/                    # Resultados de inferencia
â”‚
â”œâ”€â”€ ğŸ“‚ tools/                        # Herramientas adicionales
â”‚   â””â”€â”€ infer_optimized.py          # Inferencia optimizada
â”‚
â”œâ”€â”€ ğŸ“„ app.py                        # AplicaciÃ³n principal Gradio
â”œâ”€â”€ ğŸ“„ api_server.py                 # API REST (FastAPI)
â”œâ”€â”€ ğŸ“„ Dockerfile                    # Imagen Docker (CUDA)
â”œâ”€â”€ ğŸ“„ Dockerfile.arm64              # Imagen Docker (ARM64)
â”œâ”€â”€ ğŸ“„ requirements.txt              # Dependencias Python
â”œâ”€â”€ ğŸ“„ README.md                     # Este archivo
â””â”€â”€ ğŸ“„ README_DVC.md                 # DocumentaciÃ³n DVC
```

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ”§ ParametrizaciÃ³n

El sistema permite ajustar parÃ¡metros de funcionamiento mediante archivos de configuraciÃ³n YAML y variables de entorno.

### Archivo de ConfiguraciÃ³n Principal

**`resources/configs/default.yaml`**

```yaml
# ===========================================
# ConfiguraciÃ³n del Modelo HerdNet
# ===========================================
model:
  name: "herdnet_fase1_best"
  path: "resources/models/herdnet_best.pth"  # Ruta al modelo
  device: "cuda"           # "cuda" para GPU, "cpu" para CPU
  patch_size: 512          # TamaÃ±o del parche en pÃ­xeles
  overlap: 160             # Solapamiento entre parches
  down_ratio: 2            # Ratio de reducciÃ³n

# ===========================================
# Rutas de Directorios
# ===========================================
paths:
  uploads_dir: "resources/uploads"   # Directorio de subidas
  outputs_dir: "resources/outputs"   # Directorio de salidas
  logs_dir: "resources/logs"         # Directorio de logs

# ===========================================
# Opciones de Inferencia
# ===========================================
inference:
  save_plots: true         # Guardar visualizaciones
  save_csv: true           # Guardar resultados en CSV
  save_thumbnails: false   # Guardar miniaturas de detecciones
  verbose: true            # Mostrar logs detallados
```

### Variables de Entorno

| Variable | DescripciÃ³n | Valor por Defecto |
|----------|-------------|-------------------|
| `GRADIO_SERVER_NAME` | DirecciÃ³n del servidor Gradio | `0.0.0.0` |
| `GRADIO_SERVER_PORT` | Puerto del servidor | `7860` |
| `MPLCONFIGDIR` | Directorio de configuraciÃ³n Matplotlib | `/tmp/matplotlib` |
| `CUDA_VISIBLE_DEVICES` | GPUs a utilizar | `0` |

### Ejemplo de ConfiguraciÃ³n Personalizada

```bash
# Ejecutar con GPU especÃ­fica
CUDA_VISIBLE_DEVICES=1 python app.py

# Ejecutar en puerto diferente
GRADIO_SERVER_PORT=8080 python app.py

# Ejecutar solo en CPU
python -c "
import yaml
with open('resources/configs/default.yaml', 'r') as f:
    cfg = yaml.safe_load(f)
cfg['model']['device'] = 'cpu'
with open('resources/configs/default.yaml', 'w') as f:
    yaml.dump(cfg, f)
" && python app.py
```

> ğŸ“– Para documentaciÃ³n completa de configuraciÃ³n, consulte [docs/CONFIGURACION.md](docs/CONFIGURACION.md)

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸš€ GuÃ­a de Despliegue

### OpciÃ³n 1: EjecuciÃ³n Local (Desarrollo)

```bash
# 1. Clonar repositorio
git clone https://github.com/jaimevera1107/aerial-wildlife-count.git
cd aerial-wildlife-count

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar aplicaciÃ³n
python app.py

# 4. Abrir navegador
# http://localhost:7860
```

### OpciÃ³n 2: Docker (ProducciÃ³n)

#### ConstrucciÃ³n de la Imagen

```bash
# Para sistemas con GPU NVIDIA (x86_64)
docker build -t wildlife-detector .

# Para Apple Silicon (ARM64)
docker build -f Dockerfile.arm64 -t wildlife-detector .
```

#### EjecuciÃ³n con GPU

```bash
docker run --gpus all -p 7860:7860 wildlife-detector
```

#### EjecuciÃ³n sin GPU (CPU)

```bash
docker run -p 7860:7860 wildlife-detector
```

#### Docker Compose (Opcional)

```yaml
# docker-compose.yml
version: '3.8'
services:
  wildlife-vision:
    build: .
    ports:
      - "7860:7860"
    environment:
      - GRADIO_SERVER_NAME=0.0.0.0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

```bash
docker-compose up -d
```

### OpciÃ³n 3: Hugging Face Spaces

1. Crear un nuevo Space en [Hugging Face](https://huggingface.co/new-space)
2. Seleccionar **Docker** como SDK
3. Subir los siguientes archivos:
   - `Dockerfile`
   - `app.py`
   - `requirements.txt`
   - `resources/` (carpeta completa)
   - `modelos/` (carpeta completa)
   - `inference/` (carpeta completa)
4. Activar GPU si es necesario
5. La aplicaciÃ³n se desplegarÃ¡ automÃ¡ticamente

### VerificaciÃ³n del Despliegue

```bash
# Verificar que el servidor estÃ¡ corriendo
curl http://localhost:7860

# Verificar salud de la API
curl http://localhost:7860/api/health
```

> ğŸ“– Para instrucciones detalladas de despliegue, consulte el [Manual de Despliegue](docs/MANUAL_DESPLIEGUE.md)

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ“ Uso

_Para mÃ¡s ejemplos y documentaciÃ³n detallada, consulte el [Manual de Usuario](docs/MANUAL_USUARIO.md)_

### Uso de la Interfaz Web

1. **Acceder a la aplicaciÃ³n**: Navegar a [https://wildlife.vision](https://wildlife.vision)
2. **Subir imagen**: Arrastrar o hacer clic para seleccionar una imagen aÃ©rea
3. **Ejecutar detecciÃ³n**: Presionar el botÃ³n "â–¶ Ejecutar DetecciÃ³n"
4. **Ver resultados**: 
   - Imagen anotada con puntos de detecciÃ³n
   - Conteo por especie con barras de progreso
   - Total de animales detectados
5. **Descargar datos**: Exportar conteos y detecciones en CSV

#### Capturas de Pantalla

<details>
<summary>ğŸ“¸ Ver interfaz principal</summary>

![Interfaz Principal](docs/screenshots/wildlife-vision-main.png)

</details>

<details>
<summary>ğŸ“¸ Ver informaciÃ³n del modelo</summary>

![InformaciÃ³n del Modelo](docs/screenshots/wildlife-vision-model-info.png)

</details>

> ğŸ“– Para instrucciones detalladas, consulte el [Manual de Usuario](docs/MANUAL_USUARIO.md)

### Uso ProgramÃ¡tico (Python)

```python
from PIL import Image
from inference.herdnet_infer import HerdNetInference

# Inicializar motor de inferencia
engine = HerdNetInference("resources/configs/default.yaml")

# Cargar imagen
image = Image.open("mi_imagen_aerea.jpg")

# Ejecutar inferencia
annotated_image, counts = engine.infer_single(image)

# Mostrar resultados
print("Conteo por especie:")
for species, count in counts.items():
    print(f"  {species}: {count}")

# Guardar imagen anotada
annotated_image.save("resultado_deteccion.jpg")
```

### Uso con API REST

```bash
# Subir imagen para detecciÃ³n
curl -X POST "http://localhost:7860/api/detect" \
  -F "image=@mi_imagen.jpg" \
  -o resultado.json
```

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ“Š MÃ©tricas del Modelo

### DesempeÃ±o General (Fine-Tuning Oficial)

| MÃ©trica | Valor |
|---------|-------|
| **F1-score** | 0.8405 |
| **Precision** | 0.8407 |
| **Recall** | 0.8404 |
| **MAE** | 1.8023 |
| **RMSE** | 3.4892 |

### Matriz de ConfusiÃ³n (Normalizada)

| Real \ Predicha | buffalo | elephant | kob | topi | warthog | waterbuck |
|-----------------|---------|----------|-----|------|---------|-----------|
| **buffalo** | 0.94 | 0.00 | 0.05 | 0.01 | 0.00 | 0.00 |
| **elephant** | 0.01 | 0.91 | 0.00 | 0.07 | 0.01 | 0.00 |
| **kob** | 0.08 | 0.00 | 0.92 | 0.00 | 0.00 | 0.00 |
| **topi** | 0.03 | 0.00 | 0.00 | 0.94 | 0.03 | 0.00 |
| **warthog** | 0.06 | 0.06 | 0.06 | 0.00 | 0.81 | 0.00 |
| **waterbuck** | 0.00 | 0.00 | 0.00 | 0.00 | 0.00 | 1.00 |

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ—ºï¸ Roadmap

- [x] Entrenamiento del modelo HerdNet con dataset ULiÃ¨ge-AIR
- [x] ImplementaciÃ³n de interfaz web con Gradio
- [x] Despliegue en Hugging Face Spaces
- [x] ContenedorizaciÃ³n con Docker
- [x] Despliegue en producciÃ³n (wildlife.vision)
- [x] DocumentaciÃ³n completa del proyecto
- [ ] Soporte para mÃ¡s especies de fauna
- [ ] API REST documentada con Swagger
- [ ] Procesamiento por lotes de mÃºltiples imÃ¡genes
- [ ] IntegraciÃ³n con sistemas de drones en tiempo real
- [ ] Modelo optimizado para edge devices (ONNX/TensorRT)

Consulte los [issues abiertos](https://github.com/jaimevera1107/aerial-wildlife-count/issues) para ver la lista completa de caracterÃ­sticas propuestas y problemas conocidos.

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ¤ Contribuir

Las contribuciones son lo que hace que la comunidad de cÃ³digo abierto sea un lugar increÃ­ble para aprender, inspirar y crear. Cualquier contribuciÃ³n que hagas serÃ¡ **muy apreciada**.

Si tienes una sugerencia para mejorar esto, por favor haz un fork del repositorio y crea un pull request. TambiÃ©n puedes simplemente abrir un issue con la etiqueta "enhancement".

1. Haz Fork del Proyecto
2. Crea tu Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Haz Commit de tus Cambios (`git commit -m 'Add some AmazingFeature'`)
4. Haz Push a la Branch (`git push origin feature/AmazingFeature`)
5. Abre un Pull Request

### GuÃ­as de ContribuciÃ³n

- Sigue el estilo de cÃ³digo existente (PEP 8 para Python)
- Documenta las nuevas funcionalidades
- AÃ±ade tests cuando sea posible
- Actualiza la documentaciÃ³n si es necesario

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ“š Artefactos y Recursos

### Enlaces Importantes

| Recurso | URL |
|---------|-----|
| ğŸŒ **AplicaciÃ³n ProducciÃ³n** | [https://wildlife.vision](https://wildlife.vision) |
| ğŸ¤— **Hugging Face Space** | [jaimevera1107/herdnet-app](https://huggingface.co/spaces/jaimevera1107/herdnet-app) |
| ğŸ“Š **Dataset ULiÃ¨ge-AIR** | [DOI: 10.58119/ULG/MIRUU5](https://dataverse.uliege.be/dataset.xhtml?persistentId=doi:10.58119/ULG/MIRUU5) |
| ğŸ“ **Artefactos (Drive)** | [Google Drive](https://drive.google.com/drive/folders/1oD3-ZtvEfPJtfDrBbefJ2JLMIWksVBK6) |
| ğŸ”¬ **HerdNet Original** | [GitHub - Alexandre-Delplanque/HerdNet](https://github.com/Alexandre-Delplanque/HerdNet) |

### Modelos Disponibles

| Modelo | Formato | TamaÃ±o | DescripciÃ³n |
|--------|---------|--------|-------------|
| `herdnet_best.pth` | PyTorch | ~200 MB | Modelo fine-tuned final |

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ“š DocumentaciÃ³n Adicional

| Documento | DescripciÃ³n |
|-----------|-------------|
| [ğŸš€ Manual de Despliegue](docs/MANUAL_DESPLIEGUE.md) | GuÃ­a completa para desplegar en diferentes entornos |
| [ğŸ“– Manual de Usuario](docs/MANUAL_USUARIO.md) | GuÃ­a paso a paso para usar la aplicaciÃ³n |
| [ğŸ”§ GuÃ­a de ConfiguraciÃ³n](docs/CONFIGURACION.md) | DocumentaciÃ³n detallada de parÃ¡metros y variables |
| [ğŸ“Š README DVC](README_DVC.md) | Instrucciones para versionado de datos con DVC |

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ“„ Licencia

Este proyecto estÃ¡ licenciado bajo **Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)**.

[![License: CC BY-NC-SA 4.0](https://licensebuttons.net/l/by-nc-sa/4.0/88x31.png)](https://creativecommons.org/licenses/by-nc-sa/4.0/)

### TÃ©rminos Principales

- âœ… **AtribuciÃ³n**: Debe dar crÃ©dito apropiado
- âŒ **No Comercial**: No puede usar el material con fines comerciales
- ğŸ”„ **Compartir Igual**: Si remezcla, transforma o crea a partir del material, debe distribuir sus contribuciones bajo la misma licencia

Consulte `LICENSE` para mÃ¡s informaciÃ³n.

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ“§ Contacto

**Proyecto Guacamaya (CINFONIA)** - Universidad de los Andes

| Integrante | Email | LinkedIn |
|------------|-------|----------|
| Jaime A. Vera Jaramillo | ja.vera@uniandes.edu.co | [LinkedIn](https://linkedin.com) |
| JuliÃ¡n F. Cujabante Villamil | jf.cujabante@uniandes.edu.co | [LinkedIn](https://linkedin.com) |
| Rafael A. Ortega PabÃ³n | ra.ortegap@uniandes.edu.co | [LinkedIn](https://linkedin.com) |
| Uldy D. Paloma Rozo | ud.paloma@uniandes.edu.co | [LinkedIn](https://linkedin.com) |

**Enlace del Proyecto**: [https://github.com/jaimevera1107/aerial-wildlife-count](https://github.com/jaimevera1107/aerial-wildlife-count)

**AplicaciÃ³n Desplegada**: [https://wildlife.vision](https://wildlife.vision)

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

## ğŸ™ Agradecimientos

Recursos y personas que hicieron posible este proyecto:

- [Universidad de los Andes](https://uniandes.edu.co) - MaestrÃ­a en Inteligencia Artificial
- [Alexandre Delplanque et al.](https://github.com/Alexandre-Delplanque/HerdNet) - Por el modelo HerdNet original
- [ULiÃ¨ge](https://www.uliege.be/) - Por el dataset ULiÃ¨ge-AIR
- [Hugging Face](https://huggingface.co/) - Por la infraestructura de despliegue
- [Best-README-Template](https://github.com/othneildrew/Best-README-Template) - Por el template de README
- [Shields.io](https://shields.io/) - Por los badges
- [Gradio](https://gradio.app/) - Por el framework de interfaz de usuario

<p align="right">(<a href="#-tabla-de-contenidos">volver arriba</a>)</p>

---

<div align="center">

**ğŸ¦ Wildlife Vision - Proyecto Guacamaya (CINFONIA)**

*Universidad de los Andes - MaestrÃ­a en Inteligencia Artificial*

Â© 2025 - Todos los derechos reservados

</div>
